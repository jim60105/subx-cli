# Bug #11.2: 並行處理配置實作

## 問題描述

目前系統已定義了完整的並行處理配置項目，但 `TaskScheduler` 實作中未使用這些配置，導致使用者無法透過配置檔案調整並行處理行為。

## 當前狀況分析

### 已定義但未使用的配置

| 配置項目 | 類型 | 預設值 | 當前狀態 |
|---------|------|---------|----------|
| `cpu_intensive_limit` | usize | 2 | ⚠️ 未使用 |
| `io_intensive_limit` | usize | 8 | ⚠️ 未使用 |
| `task_queue_size` | usize | 100 | ⚠️ 未使用 |
| `enable_task_priorities` | bool | true | ⚠️ 有邏輯但不讀取配置 |
| `auto_balance_workers` | bool | true | ⚠️ 功能未實作 |

### 當前 TaskScheduler 實作分析

```rust
// src/core/parallel/scheduler.rs
impl TaskScheduler {
    pub fn new() -> Result<Self> {
        let config = load_config()?;
        // ❌ 只使用了 max_concurrent_jobs，忽略了所有其他並行配置
        let max_workers = config.general.max_concurrent_jobs;
        // ...
    }
}
```

## 技術設計

### 配置結構重新設計

```rust
// src/core/parallel/config.rs (新檔案)
#[derive(Debug, Clone)]
pub struct ParallelConfig {
    pub max_concurrent_jobs: usize,
    pub cpu_intensive_limit: usize,
    pub io_intensive_limit: usize,
    pub task_queue_size: usize,
    pub enable_task_priorities: bool,
    pub auto_balance_workers: bool,
}

impl ParallelConfig {
    pub fn from_app_config(config: &Config) -> Self {
        Self {
            max_concurrent_jobs: config.general.max_concurrent_jobs,
            cpu_intensive_limit: config.parallel.cpu_intensive_limit,
            io_intensive_limit: config.parallel.io_intensive_limit,
            task_queue_size: config.parallel.task_queue_size,
            enable_task_priorities: config.parallel.enable_task_priorities,
            auto_balance_workers: config.parallel.auto_balance_workers,
        }
    }
}
```

### TaskScheduler 重構設計

```rust
// src/core/parallel/scheduler.rs
pub struct TaskScheduler {
    config: ParallelConfig,
    cpu_pool: ThreadPool,           // CPU 密集型任務執行緒池
    io_pool: ThreadPool,            // I/O 密集型任務執行緒池
    task_queue: VecDeque<PrioritizedTask>,
    load_balancer: Option<LoadBalancer>,
}

#[derive(Debug, Clone)]
pub struct PrioritizedTask {
    pub task: Task,
    pub priority: TaskPriority,
    pub task_type: TaskType,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum TaskPriority {
    Low = 1,
    Normal = 2,
    High = 3,
    Critical = 4,
}

#[derive(Debug, Clone, Copy)]
pub enum TaskType {
    CpuIntensive,
    IoIntensive,
    Mixed,
}
```

## 實作計劃

### Phase 1: 配置整合與基礎重構（3-4 小時）

#### 步驟 1: 建立並行配置模組

```rust
// src/core/parallel/config.rs
pub struct ParallelConfig {
    // 配置欄位定義
}

impl ParallelConfig {
    pub fn from_app_config(config: &Config) -> Self {
        // 從主配置載入並行設定
    }
    
    pub fn validate(&self) -> Result<()> {
        // 驗證配置合理性
        if self.cpu_intensive_limit == 0 {
            return Err(SubXError::config("CPU密集型任務限制不能為0"));
        }
        // 更多驗證邏輯...
        Ok(())
    }
}
```

#### 步驟 2: 重構 TaskScheduler 建構子

```rust
impl TaskScheduler {
    pub fn new() -> Result<Self> {
        let app_config = load_config()?;
        let config = ParallelConfig::from_app_config(&app_config);
        config.validate()?;
        
        let cpu_pool = ThreadPoolBuilder::new()
            .num_threads(config.cpu_intensive_limit)
            .thread_name(|i| format!("cpu-worker-{}", i))
            .build()
            .map_err(|e| SubXError::parallel(format!("建立CPU執行緒池失敗: {}", e)))?;
            
        let io_pool = ThreadPoolBuilder::new()
            .num_threads(config.io_intensive_limit)
            .thread_name(|i| format!("io-worker-{}", i))
            .build()
            .map_err(|e| SubXError::parallel(format!("建立I/O執行緒池失敗: {}", e)))?;
        
        let task_queue = VecDeque::with_capacity(config.task_queue_size);
        
        let load_balancer = if config.auto_balance_workers {
            Some(LoadBalancer::new())
        } else {
            None
        };
        
        Ok(Self {
            config,
            cpu_pool,
            io_pool,
            task_queue,
            load_balancer,
        })
    }
}
```

### Phase 2: 任務優先級系統實作（2-3 小時）

#### 步驟 1: 任務分類和優先級

```rust
impl Task {
    pub fn get_task_type(&self) -> TaskType {
        match self {
            Task::FileProcessing(FileProcessingTask { operation, .. }) => {
                match operation {
                    ProcessingOperation::Read => TaskType::IoIntensive,
                    ProcessingOperation::AIAnalysis => TaskType::CpuIntensive,
                    ProcessingOperation::Write => TaskType::IoIntensive,
                    ProcessingOperation::Transform => TaskType::Mixed,
                }
            }
        }
    }
    
    pub fn get_priority(&self) -> TaskPriority {
        match self {
            Task::FileProcessing(task) if task.is_critical() => TaskPriority::Critical,
            Task::FileProcessing(_) => TaskPriority::Normal,
        }
    }
}
```

#### 步驟 2: 優先級佇列實作

```rust
impl TaskScheduler {
    pub async fn schedule_task(&mut self, task: Task) -> Result<TaskResult> {
        let prioritized_task = PrioritizedTask {
            task_type: task.get_task_type(),
            priority: task.get_priority(),
            task,
        };
        
        if self.config.enable_task_priorities {
            self.enqueue_with_priority(prioritized_task).await
        } else {
            self.enqueue_fifo(prioritized_task).await
        }
    }
    
    async fn enqueue_with_priority(&mut self, task: PrioritizedTask) -> Result<TaskResult> {
        // 根據優先級插入任務
        let insert_pos = self.task_queue
            .iter()
            .position(|existing| existing.priority < task.priority)
            .unwrap_or(self.task_queue.len());
            
        self.task_queue.insert(insert_pos, task);
        self.execute_next_task().await
    }
}
```

### Phase 3: 負載平衡實作（2-3 小時）

#### 步驟 1: 負載監控

```rust
// src/core/parallel/load_balancer.rs (新檔案)
pub struct LoadBalancer {
    cpu_load_history: VecDeque<f64>,
    io_load_history: VecDeque<f64>,
    last_balance_time: Instant,
    balance_interval: Duration,
}

impl LoadBalancer {
    pub fn new() -> Self {
        Self {
            cpu_load_history: VecDeque::with_capacity(10),
            io_load_history: VecDeque::with_capacity(10),
            last_balance_time: Instant::now(),
            balance_interval: Duration::from_secs(30),
        }
    }
    
    pub fn should_rebalance(&self) -> bool {
        self.last_balance_time.elapsed() > self.balance_interval
    }
    
    pub fn calculate_optimal_distribution(&self) -> (usize, usize) {
        let cpu_load = self.cpu_load_history.iter().sum::<f64>() / self.cpu_load_history.len() as f64;
        let io_load = self.io_load_history.iter().sum::<f64>() / self.io_load_history.len() as f64;
        
        // 根據負載歷史調整執行緒分配
        if cpu_load > 0.8 && io_load < 0.5 {
            (cpu_workers + 1, io_workers.saturating_sub(1))
        } else if io_load > 0.8 && cpu_load < 0.5 {
            (cpu_workers.saturating_sub(1), io_workers + 1)
        } else {
            (cpu_workers, io_workers) // 保持現狀
        }
    }
}
```

#### 步驟 2: 動態調整機制

```rust
impl TaskScheduler {
    async fn maybe_rebalance(&mut self) -> Result<()> {
        if let Some(ref mut balancer) = self.load_balancer {
            if balancer.should_rebalance() {
                let (new_cpu_limit, new_io_limit) = balancer.calculate_optimal_distribution();
                self.adjust_thread_pools(new_cpu_limit, new_io_limit).await?;
            }
        }
        Ok(())
    }
    
    async fn adjust_thread_pools(&mut self, cpu_limit: usize, io_limit: usize) -> Result<()> {
        // 調整執行緒池大小的實作
        // 注意：rayon 的 ThreadPool 不支援動態調整，可能需要重新建立或使用其他方案
        log::info!("調整執行緒池: CPU={}, I/O={}", cpu_limit, io_limit);
        Ok(())
    }
}
```

### Phase 4: 佇列大小限制實作（1 小時）

```rust
impl TaskScheduler {
    async fn enqueue_with_limit(&mut self, task: PrioritizedTask) -> Result<TaskResult> {
        // 檢查佇列大小限制
        if self.task_queue.len() >= self.config.task_queue_size {
            // 實作背壓處理策略
            match self.config.queue_overflow_strategy {
                OverflowStrategy::Block => {
                    // 等待佇列有空間
                    while self.task_queue.len() >= self.config.task_queue_size {
                        tokio::time::sleep(Duration::from_millis(10)).await;
                    }
                }
                OverflowStrategy::DropOldest => {
                    // 丟棄最舊的低優先級任務
                    if let Some(pos) = self.find_droppable_task() {
                        self.task_queue.remove(pos);
                    }
                }
                OverflowStrategy::Reject => {
                    return Err(SubXError::parallel("任務佇列已滿"));
                }
            }
        }
        
        self.task_queue.push_back(task);
        self.execute_next_task().await
    }
}
```

## 測試策略

### 單元測試

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_parallel_config_validation() {
        let config = ParallelConfig {
            cpu_intensive_limit: 0, // 無效值
            ..Default::default()
        };
        assert!(config.validate().is_err());
    }
    
    #[test]
    fn test_task_priority_ordering() {
        let mut queue = VecDeque::new();
        // 測試優先級排序邏輯
    }
    
    #[tokio::test]
    async fn test_load_balancer() {
        let mut balancer = LoadBalancer::new();
        // 測試負載平衡邏輯
    }
}
```

### 整合測試

```rust
#[tokio::test]
async fn test_parallel_config_integration() {
    // 建立測試配置
    let config = Config {
        parallel: ParallelConfig {
            cpu_intensive_limit: 2,
            io_intensive_limit: 4,
            task_queue_size: 10,
            enable_task_priorities: true,
            auto_balance_workers: true,
        },
        ..Default::default()
    };
    
    // 測試 TaskScheduler 是否正確使用配置
    let scheduler = TaskScheduler::new().unwrap();
    assert_eq!(scheduler.config.cpu_intensive_limit, 2);
}
```

### 效能測試

```rust
#[tokio::test]
async fn test_throughput_with_different_configs() {
    // 測試不同配置下的處理量
    // 比較啟用/停用優先級的效能差異
    // 測試負載平衡的效果
}
```

## 驗收標準

### 功能性要求

- [ ] 所有並行配置項目被正確讀取和使用
- [ ] 任務優先級系統正常運作
- [ ] 負載平衡機制能夠動態調整
- [ ] 佇列大小限制有效防止記憶體溢出
- [ ] 配置驗證能捕獲無效設定

### 效能要求

- [ ] 新實作不影響現有功能的效能
- [ ] 負載平衡帶來實際的效能改善
- [ ] 記憶體使用量在可控範圍內

### 可靠性要求

- [ ] 系統在高負載下保持穩定
- [ ] 錯誤處理機制完善
- [ ] 執行緒安全性得到保證

## 風險評估

### 技術風險

1. **執行緒池管理複雜性**: 動態調整執行緒池可能引入競爭條件
2. **效能回歸**: 新增的複雜度可能影響效能
3. **記憶體使用**: 負載監控可能增加記憶體消耗

### 緩解策略

1. **漸進式實作**: 分階段實作，每階段充分測試
2. **效能基準測試**: 建立基準並持續監控
3. **資源限制**: 設定合理的預設值和上限

## 相關檔案

### 新建檔案

- `src/core/parallel/config.rs` - 並行配置模組
- `src/core/parallel/load_balancer.rs` - 負載平衡器
- `src/core/parallel/priority.rs` - 優先級相關類型

### 修改檔案

- `src/core/parallel/scheduler.rs` - 主要重構目標
- `src/core/parallel/mod.rs` - 模組匯出更新
- `src/commands/match_command.rs` - 可能需要調整任務提交邏輯

### 測試檔案

- `tests/parallel_processing_integration_tests.rs` - 已存在，需要更新
- `src/core/parallel/scheduler.rs` - 新增單元測試

## 後續影響

完成此實作後：
1. 使用者可以精細調整並行處理行為
2. 系統在不同工作負載下的效能得到優化
3. 為未來更進階的並行處理功能奠定基礎
4. 系統資源使用更加高效和可控
