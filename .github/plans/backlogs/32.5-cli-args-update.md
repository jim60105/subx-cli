# Backlog 32.5: CLI 參數更新

## 概覽

更新 sync 指令的 CLI 參數介面，以支援新的多方法同步架構。新增方法選擇參數、配置覆蓋選項，並移除舊的不再相關的參數。確保 CLI 介面直觀易用，同時保持向後兼容性。這是 [Backlog 32](./32-redesign-sync-command-architecture.md) 的第五個子任務。

## 目標

1. 新增同步方法選擇參數 (`--method`)
2. 新增分析時間窗口參數 (`--window`)
3. 新增 Whisper 特定參數（模型、語言等）
4. 新增 VAD 特定參數（敏感度等）
5. 移除舊的不相關參數
6. 更新幫助文本和範例
7. 確保參數驗證和錯誤處理

## 技術規格

### 新的 CLI 參數結構

```rust
#[derive(Parser, Debug)]
#[command(
    name = "sync",
    about = "Synchronize subtitles with video audio using AI-powered methods",
    long_about = "Advanced subtitle synchronization using multiple detection methods:\n\
                  • OpenAI Whisper API for high-accuracy cloud-based transcription\n\
                  • Local Voice Activity Detection (VAD) for fast, private processing\n\
                  • Automatic method selection with intelligent fallback"
)]
pub struct SyncArgs {
    /// Video file path
    #[arg(value_name = "VIDEO")]
    pub video: PathBuf,

    /// Subtitle file path
    #[arg(value_name = "SUBTITLE")]
    pub subtitle: PathBuf,

    /// Manual time offset in seconds (positive = delay subtitles, negative = advance)
    #[arg(short, long, conflicts_with_all = ["method", "window"])]
    pub offset: Option<f32>,

    /// Synchronization method to use
    #[arg(
        short, 
        long, 
        value_enum,
        help = "Synchronization method",
        long_help = "Choose the synchronization method:\n\
                     • whisper: Use OpenAI Whisper API with intelligent VAD fallback\n\
                     • vad: Use local Voice Activity Detection only\n\
                     • manual: Apply manual offset (use with --offset)"
    )]
    pub method: Option<SyncMethodArg>,

    /// Analysis time window in seconds (audio around first subtitle)
    #[arg(
        short = 'w',
        long,
        value_name = "SECONDS",
        default_value = "30",
        help = "Time window in seconds to analyze around the first subtitle"
    )]
    pub window: u32,

    /// Enable batch processing mode
    #[arg(short, long)]
    pub batch: bool,

    // === Whisper API specific options ===
    /// Whisper model to use
    #[arg(
        long,
        value_name = "MODEL",
        help = "Whisper model (whisper-1, etc.)",
        requires = "method"
    )]
    pub whisper_model: Option<String>,

    /// Language for Whisper transcription
    #[arg(
        long,
        value_name = "LANG",
        help = "Language code for Whisper (auto, en, zh, etc.)",
        requires = "method"
    )]
    pub whisper_language: Option<String>,

    /// Whisper API temperature
    #[arg(
        long,
        value_name = "TEMP",
        help = "Whisper API temperature (0.0-1.0)",
        requires = "method"
    )]
    pub whisper_temperature: Option<f32>,

    // === VAD specific options ===
    /// VAD sensitivity threshold
    #[arg(
        long,
        value_name = "THRESHOLD",
        help = "VAD sensitivity (0.0-1.0, higher = more sensitive)",
        requires = "method"
    )]
    pub vad_sensitivity: Option<f32>,

    /// VAD chunk size
    #[arg(
        long,
        value_name = "SIZE",
        help = "VAD chunk size in samples (256, 512, 1024, etc.)",
        requires = "method"
    )]
    pub vad_chunk_size: Option<usize>,

    // === Legacy options (deprecated) ===
    /// Maximum offset search range (deprecated, use config file)
    #[arg(long, hide = true)]
    #[deprecated(note = "Use configuration file instead")]
    pub range: Option<f32>,

    /// Minimum correlation threshold (deprecated, use config file)
    #[arg(long, hide = true)]
    #[deprecated(note = "Use configuration file instead")]
    pub threshold: Option<f32>,

    // === Output options ===
    /// Output file path (default: input_synced.ext)
    #[arg(short = 'o', long, value_name = "PATH")]
    pub output: Option<PathBuf>,

    /// Verbose output
    #[arg(short, long)]
    pub verbose: bool,

    /// Dry run - analyze only, don't save result
    #[arg(long)]
    pub dry_run: bool,
}

#[derive(ValueEnum, Clone, Debug)]
pub enum SyncMethodArg {
    /// Use OpenAI Whisper API with intelligent VAD fallback
    Whisper, 
    /// Use local Voice Activity Detection only
    Vad,
    /// Apply manual offset (requires --offset)
    Manual,
}

impl From<SyncMethodArg> for crate::core::sync::SyncMethod {
    fn from(arg: SyncMethodArg) -> Self {
        match arg {
            SyncMethodArg::Whisper => Self::WhisperApi,
            SyncMethodArg::Vad => Self::LocalVad,
            SyncMethodArg::Manual => Self::Manual,
        }
    }
}
```

## 實作步驟

### 步驟 1: 更新 SyncArgs 結構

**檔案**: `src/cli/sync_args.rs`

```rust
//! 重構後的同步指令 CLI 參數定義
//!
//! 支援多種同步方法：OpenAI Whisper API、本地 VAD、自動選擇和手動偏移。
//! 提供細緻的參數控制和智能預設值。

use clap::{Parser, ValueEnum};
use std::path::PathBuf;

#[derive(Parser, Debug)]
#[command(
    name = "sync",
    about = "Synchronize subtitles with video audio using AI-powered methods",
    long_about = "Advanced subtitle synchronization supporting multiple detection methods:\n\n\
    METHODS:\n  \
    • whisper  - OpenAI Whisper API with intelligent VAD fallback\n  \
    • vad      - Local Voice Activity Detection (privacy-focused)\n  \
    • manual   - Apply manual time offset\n\n\
    EXAMPLES:\n  \
    # Default Whisper method with fallback\n  \
    subx sync video.mp4 subtitle.srt\n\n  \
    # Use Whisper API with specific model\n  \
    subx sync --method whisper --whisper-model whisper-1 video.mp4 subtitle.srt\n\n  \
    # Local VAD only (no cloud services)\n  \
    subx sync --method vad --vad-sensitivity 0.8 video.mp4 subtitle.srt\n\n  \
    # Manual offset\n  \
    subx sync --offset 2.5 video.mp4 subtitle.srt"
)]
pub struct SyncArgs {
    /// Video file containing the audio track
    #[arg(
        value_name = "VIDEO",
        help = "Path to video file (MP4, MKV, AVI, etc.)"
    )]
    pub video: PathBuf,

    /// Subtitle file to synchronize
    #[arg(
        value_name = "SUBTITLE", 
        help = "Path to subtitle file (SRT, VTT, ASS, etc.)"
    )]
    pub subtitle: PathBuf,

    /// Manual time offset in seconds
    #[arg(
        short,
        long,
        value_name = "SECONDS",
        help = "Manual offset in seconds (positive delays subtitles)",
        long_help = "Apply a manual time offset to all subtitle entries.\n\
                     Positive values delay subtitles (subtitles appear later).\n\
                     Negative values advance subtitles (subtitles appear earlier).\n\
                     Cannot be used with automatic detection methods.",
        conflicts_with_all = ["method", "window", "whisper_model", "whisper_language", "vad_sensitivity"]
    )]
    pub offset: Option<f32>,

    /// Synchronization method
    #[arg(
        short,
        long,
        value_enum,
        help = "Synchronization method to use",
        long_help = "Select the synchronization method:\n\
                     • whisper (default): Use OpenAI Whisper API with intelligent VAD fallback\n\
                     • vad: Use local Voice Activity Detection only\n\
                     • manual: Apply manual offset (requires --offset)"
    )]
    pub method: Option<SyncMethodArg>,

    /// Analysis time window
    #[arg(
        short = 'w',
        long,
        value_name = "SECONDS",
        default_value = "30",
        help = "Time window to analyze around first subtitle (10-300 seconds)",
        value_parser = clap::value_parser!(u32).range(10..=300)
    )]
    pub window: u32,

    // === Whisper API Options ===
    /// Whisper model
    #[arg(
        long,
        value_name = "MODEL",
        help = "Whisper model to use",
        long_help = "Specify the Whisper model:\n\
                     • whisper-1 (default): Latest Whisper model\n\
                     Note: Model availability depends on your OpenAI subscription."
    )]
    pub whisper_model: Option<String>,

    /// Whisper language
    #[arg(
        long,
        value_name = "LANG",
        help = "Language for Whisper transcription",
        long_help = "Specify the language for Whisper transcription:\n\
                     • auto (default): Automatic language detection\n\
                     • en: English\n\
                     • zh: Chinese\n\
                     • ja: Japanese\n\
                     • ko: Korean\n\
                     • ... (any ISO 639-1 language code)"
    )]
    pub whisper_language: Option<String>,

    /// Whisper temperature
    #[arg(
        long,
        value_name = "TEMP",
        help = "Whisper API temperature (0.0-1.0)",
        long_help = "Control randomness in Whisper transcription:\n\
                     • 0.0 (default): Most deterministic\n\
                     • 1.0: Most creative/random\n\
                     Lower values are recommended for synchronization.",
        value_parser = clap::value_parser!(f32).range(0.0..=1.0)
    )]
    pub whisper_temperature: Option<f32>,

    // === VAD Options ===
    /// VAD sensitivity
    #[arg(
        long,
        value_name = "SENSITIVITY",
        help = "VAD sensitivity threshold (0.0-1.0)",
        long_help = "Voice Activity Detection sensitivity:\n\
                     • 0.5-0.7: Less sensitive, fewer false positives\n\
                     • 0.75 (default): Balanced\n\
                     • 0.8-0.9: More sensitive, may catch quiet speech",
        value_parser = clap::value_parser!(f32).range(0.0..=1.0)
    )]
    pub vad_sensitivity: Option<f32>,

    /// VAD chunk size
    #[arg(
        long,
        value_name = "SIZE",
        help = "VAD chunk size in samples",
        long_help = "Audio chunk size for VAD processing:\n\
                     • 256: Faster, less accurate\n\
                     • 512 (default): Balanced\n\
                     • 1024: Slower, more accurate\n\
                     Must be a power of 2.",
        value_parser = validate_chunk_size
    )]
    pub vad_chunk_size: Option<usize>,

    // === Output Options ===
    /// Output file path
    #[arg(
        short = 'o',
        long,
        value_name = "PATH",
        help = "Output file path (default: input_synced.ext)"
    )]
    pub output: Option<PathBuf>,

    /// Enable batch processing
    #[arg(
        short,
        long,
        help = "Enable batch processing mode",
        long_help = "Process multiple subtitle files in the same directory.\n\
                     The video argument should be a directory path."
    )]
    pub batch: bool,

    /// Verbose output
    #[arg(
        short,
        long,
        help = "Enable verbose output with detailed progress information"
    )]
    pub verbose: bool,

    /// Dry run mode
    #[arg(
        long,
        help = "Analyze and show results without saving output file"
    )]
    pub dry_run: bool,

    /// Force overwrite existing output files
    #[arg(
        long,
        help = "Overwrite existing output files without confirmation"
    )]
    pub force: bool,

    // === Legacy/Hidden Options ===
    #[arg(long, hide = true)]
    #[allow(deprecated)]
    pub range: Option<f32>,

    #[arg(long, hide = true)]
    #[allow(deprecated)]
    pub threshold: Option<f32>,
}

#[derive(ValueEnum, Clone, Debug, PartialEq)]
pub enum SyncMethodArg {
    /// Use OpenAI Whisper API with intelligent VAD fallback
    Whisper,
    /// Use local Voice Activity Detection only
    Vad,
    /// Apply manual time offset
    Manual,
}

impl From<SyncMethodArg> for crate::core::sync::SyncMethod {
    fn from(arg: SyncMethodArg) -> Self {
        match arg {
            SyncMethodArg::Whisper => Self::WhisperApi,
            SyncMethodArg::Vad => Self::LocalVad,
            SyncMethodArg::Manual => Self::Manual,
        }
        }
    }
}

impl SyncArgs {
    /// 驗證參數組合的有效性
    pub fn validate(&self) -> Result<(), String> {
        // 檢查 offset 和 method 的衝突
        if self.offset.is_some() && self.method.is_some() {
            return Err("Cannot use --offset with --method. Use --method manual for manual offsets.".to_string());
        }

        // 檢查 manual 方法是否有 offset
        if let Some(SyncMethodArg::Manual) = &self.method {
            if self.offset.is_none() {
                return Err("Manual method requires --offset parameter.".to_string());
            }
        }

        // 檢查 Whisper 參數
        if self.whisper_model.is_some() || self.whisper_language.is_some() || self.whisper_temperature.is_some() {
            match &self.method {
                Some(SyncMethodArg::Whisper) | None => {},
                _ => return Err("Whisper options can only be used with --method whisper.".to_string()),
            }
        }

        // 檢查 VAD 參數
        if self.vad_sensitivity.is_some() || self.vad_chunk_size.is_some() {
            match &self.method {
                Some(SyncMethodArg::Vad) => {},
                _ => return Err("VAD options can only be used with --method vad.".to_string()),
            }
        }

        // 檢查檔案路徑
        if !self.video.exists() {
            return Err(format!("Video file not found: {}", self.video.display()));
        }

        if !self.subtitle.exists() {
            return Err(format!("Subtitle file not found: {}", self.subtitle.display()));
        }

        Ok(())
    }

    /// 建立輸出檔案路徑
    pub fn get_output_path(&self) -> PathBuf {
        if let Some(ref output) = self.output {
            output.clone()
        } else {
            create_default_output_path(&self.subtitle)
        }
    }

    /// 檢查是否為手動模式
    pub fn is_manual_mode(&self) -> bool {
        self.offset.is_some() || matches!(self.method, Some(SyncMethodArg::Manual))
    }
}

// 輔助函式
fn validate_chunk_size(s: &str) -> Result<usize, String> {
    let size: usize = s.parse().map_err(|_| "Invalid chunk size")?;
    
    if size < 256 || size > 2048 {
        return Err("Chunk size must be between 256 and 2048".to_string());
    }
    
    if !size.is_power_of_two() {
        return Err("Chunk size must be a power of 2".to_string());
    }
    
    Ok(size)
}

fn create_default_output_path(input: &PathBuf) -> PathBuf {
    let mut output = input.clone();
    
    if let Some(stem) = input.file_stem().and_then(|s| s.to_str()) {
        if let Some(extension) = input.extension().and_then(|s| s.to_str()) {
            let new_filename = format!("{}_synced.{}", stem, extension);
            output.set_file_name(new_filename);
        }
    }
    
    output
}
```

### 步驟 2: 更新參數處理邏輯

**檔案**: `src/commands/sync_command.rs`

```rust
//! 更新後的同步指令實作，支援新的 CLI 參數

use std::path::Path;
use crate::cli::SyncArgs;
use crate::config::{ConfigService, SyncConfig, WhisperConfig, VadConfig};
use crate::core::formats::manager::FormatManager;
use crate::core::sync::{SyncEngine, SyncMethod};
use crate::{Result, error::SubXError};

/// 執行同步指令
pub async fn execute(args: SyncArgs, config_service: &dyn ConfigService) -> Result<()> {
    // 驗證參數
    if let Err(msg) = args.validate() {
        return Err(SubXError::cli(msg));
    }

    // 如果有舊的已棄用參數，顯示警告
    if args.range.is_some() || args.threshold.is_some() {
        eprintln!("⚠️  Warning: --range and --threshold options are deprecated.");
        eprintln!("   Please use the configuration file to set these values.");
    }

    // 建立動態配置（結合檔案配置和 CLI 參數）
    let mut config = config_service.get_config()?.clone();
    apply_cli_overrides(&mut config, &args)?;

    // 建立同步引擎
    let sync_engine = SyncEngine::new(config.sync.clone(), config_service).await?;
    
    // 載入字幕檔案
    let format_manager = FormatManager::new();
    let mut subtitle = format_manager.load_subtitle(&args.subtitle)?;

    if args.verbose {
        println!("📁 Loaded subtitle: {} entries", subtitle.entries.len());
        if !subtitle.entries.is_empty() {
            let first = &subtitle.entries[0];
            println!("   First entry: {:.2}s - {:.2}s", 
                first.start_time.as_secs_f64(), 
                first.end_time.as_secs_f64());
        }
    }

    // 執行同步
    let sync_result = if args.is_manual_mode() {
        // 手動偏移模式
        let offset = args.offset.unwrap_or(0.0);
        if args.verbose {
            println!("🔧 Applying manual offset: {:.3}s", offset);
        }
        sync_engine.apply_manual_offset(&mut subtitle, offset)?
    } else {
        // 自動同步模式
        let method = args.method.map(|m| m.into()).unwrap_or(SyncMethod::WhisperApi);
        
        if args.verbose {
            println!("🔍 Starting synchronization analysis...");
            println!("   Method: {:?}", method);
            println!("   Analysis window: {}s", args.window);
        }
        
        let result = sync_engine.detect_sync_offset(&args.video, &subtitle, Some(method)).await?;
        
        if args.verbose {
            println!("✅ Analysis complete:");
            println!("   Detected offset: {:.3}s", result.offset_seconds);
            println!("   Confidence: {:.1}%", result.confidence * 100.0);
            println!("   Processing time: {:?}", result.processing_duration);
        }

        // 應用檢測到的偏移
        if !args.dry_run {
            sync_engine.apply_manual_offset(&mut subtitle, result.offset_seconds)?;
        }
        
        result
    };

    // 顯示結果
    display_sync_result(&sync_result, args.verbose);

    // 儲存結果（除非是 dry run）
    if !args.dry_run {
        let output_path = args.get_output_path();
        
        // 檢查檔案是否存在且沒有 force 標記
        if output_path.exists() && !args.force {
            return Err(SubXError::io(format!(
                "Output file already exists: {}. Use --force to overwrite.",
                output_path.display()
            )));
        }
        
        format_manager.save_subtitle(&subtitle, &output_path)?;
        println!("💾 Synchronized subtitle saved to: {}", output_path.display());
    } else {
        println!("🏃 Dry run completed - no files were modified");
    }

    Ok(())
}

/// 將 CLI 參數應用到配置中
fn apply_cli_overrides(config: &mut crate::config::Config, args: &SyncArgs) -> Result<()> {
    // 更新分析時間窗口
    config.sync.analysis_window_seconds = args.window;

    // 應用 Whisper 參數覆蓋
    if let Some(ref model) = args.whisper_model {
        config.sync.whisper.model = model.clone();
    }
    if let Some(ref language) = args.whisper_language {
        config.sync.whisper.language = language.clone();
    }
    if let Some(temperature) = args.whisper_temperature {
        config.sync.whisper.temperature = temperature;
    }

    // 應用 VAD 參數覆蓋
    if let Some(sensitivity) = args.vad_sensitivity {
        config.sync.vad.sensitivity = sensitivity;
    }
    if let Some(chunk_size) = args.vad_chunk_size {
        config.sync.vad.chunk_size = chunk_size;
    }

    // 根據選擇的方法啟用/停用檢測器
    match &args.method {
        Some(crate::cli::SyncMethodArg::Whisper) => {
            config.sync.whisper.enabled = true;
            config.sync.vad.enabled = false;
        },
        Some(crate::cli::SyncMethodArg::Vad) => {
            config.sync.whisper.enabled = false;
            config.sync.vad.enabled = true;
        },
        Some(crate::cli::SyncMethodArg::Manual) => {
            config.sync.whisper.enabled = false;
            config.sync.vad.enabled = false;
        },
        Some(crate::cli::SyncMethodArg::Whisper) | None => {
            // Whisper 模式（預設），保持配置檔案中的設定
        },
        Some(crate::cli::SyncMethodArg::Vad) => {
            // VAD 只模式，禁用 Whisper
            config.sync.whisper.enabled = false;
        },
    }

    Ok(())
}

fn display_sync_result(result: &crate::core::sync::SyncResult, verbose: bool) {
    println!("\n=== Synchronization Result ===");
    
    match result.method_used {
        crate::core::sync::SyncMethod::Manual => {
            println!("📝 Method: Manual offset");
        },
        crate::core::sync::SyncMethod::WhisperApi => {
            println!("🤖 Method: OpenAI Whisper API");
        },
        crate::core::sync::SyncMethod::LocalVad => {
            println!("🔊 Method: Local Voice Activity Detection");
        },
                });
        },
    }
    
    println!("⏱️  Detected offset: {:.3} seconds", result.offset_seconds);
    
    if result.offset_seconds > 0.0 {
        println!("   → Subtitles will be delayed by {:.3}s", result.offset_seconds);
    } else if result.offset_seconds < 0.0 {
        println!("   → Subtitles will be advanced by {:.3}s", -result.offset_seconds);
    } else {
        println!("   → No timing adjustment needed");
    }
    
    println!("📊 Confidence: {:.1}%", result.confidence * 100.0);
    
    if verbose {
        println!("⏲️  Processing time: {:?}", result.processing_duration);
        
        if !result.warnings.is_empty() {
            println!("\n⚠️  Warnings:");
            for warning in &result.warnings {
                println!("   • {}", warning);
            }
        }
        
        if let Some(info) = &result.additional_info {
            println!("\n📋 Additional Details:");
            if let Ok(pretty_info) = serde_json::to_string_pretty(info) {
                for line in pretty_info.lines() {
                    println!("   {}", line);
                }
            }
        }
    }
    
    println!();
}
```

### 步驟 3: 更新幫助和 UI 顯示

**檔案**: `src/cli/ui.rs`

```rust
//! CLI 使用者介面和幫助文本

use crate::cli::SyncArgs;
use clap::CommandFactory;

/// 顯示 sync 指令的詳細幫助
pub fn show_sync_help() {
    let mut app = SyncArgs::command();
    app.print_help().unwrap();
}

/// 顯示 sync 指令的使用範例
pub fn show_sync_examples() {
    println!(r#"
SYNC COMMAND EXAMPLES

Basic automatic synchronization:
  subx sync video.mp4 subtitle.srt

Use specific method:
  subx sync --method whisper video.mp4 subtitle.srt
  subx sync --method vad video.mp4 subtitle.srt

Custom analysis window:
  subx sync --window 45 video.mp4 subtitle.srt

Whisper API with custom settings:
  subx sync --method whisper \
            --whisper-model whisper-1 \
            --whisper-language en \
            --whisper-temperature 0.0 \
            video.mp4 subtitle.srt

Local VAD with custom sensitivity:
  subx sync --method vad \
            --vad-sensitivity 0.8 \
            --vad-chunk-size 1024 \
            video.mp4 subtitle.srt

Manual offset:
  subx sync --offset 2.5 video.mp4 subtitle.srt
  subx sync --offset -1.2 video.mp4 subtitle.srt

Dry run (analyze only):
  subx sync --dry-run --verbose video.mp4 subtitle.srt

Batch processing:
  subx sync --batch --method vad videos_dir/ subtitles_dir/

Output to specific file:
  subx sync --output synced_subtitle.srt video.mp4 subtitle.srt

Verbose output with details:
  subx sync --verbose video.mp4 subtitle.srt
"#);
}

/// 顯示方法比較資訊
pub fn show_method_comparison() {
    println!(r#"
SYNCHRONIZATION METHODS COMPARISON

┌─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐
│   Method    │  Accuracy   │    Speed    │   Privacy   │   Requires  │
├─────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│ Whisper API │    High     │   Medium    │    Low*     │  API Key    │
│ Local VAD   │   Medium    │    Fast     │    High     │   Nothing   │
│ Auto        │    High     │   Medium    │   Mixed     │  Optional   │
│ Manual      │ User-depend │   Instant   │    High     │   Nothing   │
└─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘

* Whisper API sends audio data to OpenAI servers

RECOMMENDATIONS:
• Use 'auto' for best results with intelligent fallback
• Use 'whisper' for highest accuracy when API key is available
• Use 'vad' for fast, private processing without external dependencies
• Use 'manual' when you know the exact offset needed

CONFIGURATION:
You can set default preferences in ~/.config/subx/config.toml:

[sync]
default_method = "auto"
analysis_window_seconds = 30

[sync.whisper]
enabled = true
model = "whisper-1"
language = "auto"

[sync.vad]
enabled = true
sensitivity = 0.75
chunk_size = 512
"#);
}
```

### 步驟 4: 更新參數驗證

**檔案**: `src/cli/validation.rs`

```rust
//! CLI 參數驗證邏輯

use crate::cli::SyncArgs;
use crate::{Result, error::SubXError};
use std::path::Path;

/// 驗證 sync 指令參數的完整性
pub fn validate_sync_args(args: &SyncArgs) -> Result<()> {
    // 基本檔案存在性檢查
    validate_file_paths(args)?;
    
    // 參數組合邏輯檢查
    validate_parameter_combinations(args)?;
    
    // 參數值範圍檢查
    validate_parameter_ranges(args)?;
    
    // 配置依賴檢查
    validate_configuration_dependencies(args)?;
    
    Ok(())
}

fn validate_file_paths(args: &SyncArgs) -> Result<()> {
    if !args.video.exists() {
        return Err(SubXError::cli(format!(
            "Video file not found: {}", 
            args.video.display()
        )));
    }

    if !args.subtitle.exists() {
        return Err(SubXError::cli(format!(
            "Subtitle file not found: {}", 
            args.subtitle.display()
        )));
    }

    // 檢查檔案是否為目錄（batch mode 特殊處理）
    if args.batch {
        if !args.video.is_dir() {
            return Err(SubXError::cli(
                "Batch mode requires video path to be a directory"
            ));
        }
    } else {
        if args.video.is_dir() {
            return Err(SubXError::cli(
                "Video path cannot be a directory in single file mode. Use --batch for directory processing."
            ));
        }
    }

    Ok(())
}

fn validate_parameter_combinations(args: &SyncArgs) -> Result<()> {
    use crate::cli::SyncMethodArg;

    // 手動模式驗證
    if let Some(SyncMethodArg::Manual) = &args.method {
        if args.offset.is_none() {
            return Err(SubXError::cli(
                "Manual method requires --offset parameter"
            ));
        }
    }

    // offset 與其他參數的衝突
    if args.offset.is_some() {
        if args.method.is_some() && !matches!(args.method, Some(SyncMethodArg::Manual)) {
            return Err(SubXError::cli(
                "Cannot use --offset with automatic detection methods. Use --method manual for manual offsets."
            ));
        }
        
        if args.window != 30 {
            return Err(SubXError::cli(
                "Cannot use --window with manual offset mode"
            ));
        }
    }

    // Whisper 參數驗證
    let has_whisper_args = args.whisper_model.is_some() 
        || args.whisper_language.is_some() 
        || args.whisper_temperature.is_some();
    
    if has_whisper_args {
        match &args.method {
            Some(SyncMethodArg::Vad) | Some(SyncMethodArg::Manual) => {
                return Err(SubXError::cli(
                    "Whisper options cannot be used with VAD or manual methods"
                ));
            },
            _ => {} // Auto, Whisper, or None are OK
        }
    }

    // VAD 參數驗證
    let has_vad_args = args.vad_sensitivity.is_some() || args.vad_chunk_size.is_some();
    
    if has_vad_args {
        match &args.method {
            Some(SyncMethodArg::Whisper) | Some(SyncMethodArg::Manual) => {
                return Err(SubXError::cli(
                    "VAD options cannot be used with Whisper or manual methods"
                ));
            },
            _ => {} // Auto, VAD, or None are OK
        }
    }

    Ok(())
}

fn validate_parameter_ranges(args: &SyncArgs) -> Result<()> {
    // offset 範圍檢查
    if let Some(offset) = args.offset {
        if offset.abs() > 3600.0 {
            return Err(SubXError::cli(
                "Offset must be between -3600 and 3600 seconds"
            ));
        }
    }

    // window 範圍檢查（已在 clap 中定義，但再次檢查）
    if args.window < 10 || args.window > 300 {
        return Err(SubXError::cli(
            "Analysis window must be between 10 and 300 seconds"
        ));
    }

    // Whisper temperature 檢查
    if let Some(temp) = args.whisper_temperature {
        if !(0.0..=1.0).contains(&temp) {
            return Err(SubXError::cli(
                "Whisper temperature must be between 0.0 and 1.0"
            ));
        }
    }

    // VAD sensitivity 檢查
    if let Some(sensitivity) = args.vad_sensitivity {
        if !(0.0..=1.0).contains(&sensitivity) {
            return Err(SubXError::cli(
                "VAD sensitivity must be between 0.0 and 1.0"
            ));
        }
    }

    // VAD chunk size 檢查
    if let Some(chunk_size) = args.vad_chunk_size {
        if chunk_size < 256 || chunk_size > 2048 || !chunk_size.is_power_of_two() {
            return Err(SubXError::cli(
                "VAD chunk size must be a power of 2 between 256 and 2048"
            ));
        }
    }

    Ok(())
}

fn validate_configuration_dependencies(args: &SyncArgs) -> Result<()> {
    use crate::cli::SyncMethodArg;
    
    // 檢查特定方法的配置需求（這些在實際執行時會再次檢查，但可以提前警告）
    match &args.method {
        Some(SyncMethodArg::Whisper) => {
            // 檢查是否可能有 API 金鑰（但不強制要求，因為可能在環境變數中）
            if std::env::var("OPENAI_API_KEY").is_err() {
                eprintln!("⚠️  Warning: OPENAI_API_KEY environment variable not set.");
                eprintln!("   Make sure you have configured your OpenAI API key.");
            }
        },
        _ => {}
    }

    Ok(())
}

/// 提供參數建議和提示
pub fn suggest_parameter_improvements(args: &SyncArgs) {
    let mut suggestions = Vec::new();

    // 根據不同情況提供建議
    if args.method.is_none() && args.offset.is_none() {
        suggestions.push("💡 Tip: Use --method to explicitly choose synchronization method");
    }

    if args.window == 30 && args.method.is_some() {
        suggestions.push("💡 Tip: Try --window 45 or 60 for better accuracy with longer audio");
    }

    if matches!(args.method, Some(crate::cli::SyncMethodArg::Vad)) && args.vad_sensitivity.is_none() {
        suggestions.push("💡 Tip: Adjust --vad-sensitivity (0.6-0.9) if detection is too sensitive/insensitive");
    }

    if !args.verbose && args.method != Some(crate::cli::SyncMethodArg::Manual) {
        suggestions.push("💡 Tip: Use --verbose for detailed analysis information");
    }

    if !suggestions.is_empty() {
        println!();
        for suggestion in suggestions {
            println!("{}", suggestion);
        }
        println!();
    }
}
```

## 測試策略

### 單元測試

**檔案**: `src/cli/sync_args.rs`

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use clap::Parser;

    #[test]
    fn test_basic_sync_args_parsing() {
        let args = SyncArgs::try_parse_from([
            "sync", "video.mp4", "subtitle.srt"
        ]).unwrap();
        
        assert_eq!(args.video, PathBuf::from("video.mp4"));
        assert_eq!(args.subtitle, PathBuf::from("subtitle.srt"));
        assert_eq!(args.window, 30);
        assert!(args.method.is_none());
        assert!(args.offset.is_none());
    }

    #[test]
    fn test_method_selection() {
        let test_cases = vec![
            (vec!["sync", "--method", "auto", "video.mp4", "subtitle.srt"], SyncMethodArg::Auto),
            (vec!["sync", "--method", "whisper", "video.mp4", "subtitle.srt"], SyncMethodArg::Whisper),
            (vec!["sync", "--method", "vad", "video.mp4", "subtitle.srt"], SyncMethodArg::Vad),
            (vec!["sync", "--method", "manual", "--offset", "2.5", "video.mp4", "subtitle.srt"], SyncMethodArg::Manual),
        ];

        for (args, expected_method) in test_cases {
            let parsed = SyncArgs::try_parse_from(args).unwrap();
            assert_eq!(parsed.method.unwrap(), expected_method);
        }
    }

    #[test]
    fn test_whisper_options() {
        let args = SyncArgs::try_parse_from([
            "sync", 
            "--method", "whisper",
            "--whisper-model", "whisper-1",
            "--whisper-language", "en", 
            "--whisper-temperature", "0.2",
            "video.mp4", "subtitle.srt"
        ]).unwrap();

        assert_eq!(args.whisper_model, Some("whisper-1".to_string()));
        assert_eq!(args.whisper_language, Some("en".to_string()));
        assert_eq!(args.whisper_temperature, Some(0.2));
    }

    #[test]
    fn test_vad_options() {
        let args = SyncArgs::try_parse_from([
            "sync",
            "--method", "vad",
            "--vad-sensitivity", "0.8",
            "--vad-chunk-size", "1024",
            "video.mp4", "subtitle.srt"
        ]).unwrap();

        assert_eq!(args.vad_sensitivity, Some(0.8));
        assert_eq!(args.vad_chunk_size, Some(1024));
    }

    #[test]
    fn test_manual_offset() {
        let args = SyncArgs::try_parse_from([
            "sync", "--offset", "2.5", "video.mp4", "subtitle.srt"
        ]).unwrap();

        assert_eq!(args.offset, Some(2.5));
        assert!(args.is_manual_mode());
    }

    #[test]
    fn test_parameter_conflicts() {
        // offset 與 method 衝突
        assert!(SyncArgs::try_parse_from([
            "sync", "--offset", "2.5", "--method", "whisper", "video.mp4", "subtitle.srt"
        ]).is_err());

        // offset 與 window 衝突
        assert!(SyncArgs::try_parse_from([
            "sync", "--offset", "2.5", "--window", "45", "video.mp4", "subtitle.srt"  
        ]).is_err());
    }

    #[test]
    fn test_validation() {
        use std::fs::File;
        use tempfile::TempDir;

        let temp_dir = TempDir::new().unwrap();
        let video_path = temp_dir.path().join("video.mp4");
        let subtitle_path = temp_dir.path().join("subtitle.srt");

        // 建立測試檔案
        File::create(&video_path).unwrap();
        File::create(&subtitle_path).unwrap();

        let args = SyncArgs {
            video: video_path,
            subtitle: subtitle_path,
            offset: None,
            method: Some(SyncMethodArg::Auto),
            window: 30,
            whisper_model: None,
            whisper_language: None,
            whisper_temperature: None,
            vad_sensitivity: None,
            vad_chunk_size: None,
            output: None,
            batch: false,
            verbose: false,
            dry_run: false,
            force: false,
            range: None,
            threshold: None,
        };

        assert!(args.validate().is_ok());
    }

    #[test]
    fn test_chunk_size_validation() {
        // 有效的 chunk sizes
        assert!(validate_chunk_size("256").is_ok());
        assert!(validate_chunk_size("512").is_ok());
        assert!(validate_chunk_size("1024").is_ok());

        // 無效的 chunk sizes
        assert!(validate_chunk_size("255").is_err()); // 不是 2 的冪次
        assert!(validate_chunk_size("100").is_err()); // 太小
        assert!(validate_chunk_size("4096").is_err()); // 太大
    }

    #[test]
    fn test_default_output_path() {
        let input = PathBuf::from("test.srt");
        let output = create_default_output_path(&input);
        assert_eq!(output, PathBuf::from("test_synced.srt"));

        let input = PathBuf::from("/path/to/subtitle.vtt");
        let output = create_default_output_path(&input);
        assert_eq!(output, PathBuf::from("/path/to/subtitle_synced.vtt"));
    }
}
```

### 整合測試

**檔案**: `tests/sync_cli_integration_tests.rs`

```rust
use subx_cli::cli::SyncArgs;
use clap::Parser;
use std::process::Command;
use tempfile::TempDir;
use std::fs;

#[test]
fn test_sync_command_help() {
    let output = Command::new("cargo")
        .args(["run", "--", "sync", "--help"])
        .output()
        .expect("Failed to execute command");

    let help_text = String::from_utf8(output.stdout).unwrap();
    assert!(help_text.contains("Synchronize subtitles with video audio"));
    assert!(help_text.contains("--method"));
    assert!(help_text.contains("--whisper-model"));
    assert!(help_text.contains("--vad-sensitivity"));
}

#[test]
fn test_sync_command_examples() {
    let test_cases = vec![
        // 基本自動同步
        "subx sync video.mp4 subtitle.srt",
        
        // 指定方法
        "subx sync --method whisper video.mp4 subtitle.srt",
        "subx sync --method vad video.mp4 subtitle.srt",
        
        // 手動偏移
        "subx sync --offset 2.5 video.mp4 subtitle.srt",
        
        // Whisper 選項
        "subx sync --method whisper --whisper-model whisper-1 video.mp4 subtitle.srt",
        
        // VAD 選項
        "subx sync --method vad --vad-sensitivity 0.8 video.mp4 subtitle.srt",
        
        // 輸出選項
        "subx sync --output synced.srt video.mp4 subtitle.srt",
        "subx sync --dry-run --verbose video.mp4 subtitle.srt",
    ];

    for cmd_line in test_cases {
        let parts: Vec<&str> = cmd_line.split_whitespace().collect();
        let args = &parts[2..]; // 跳過 "subx sync"
        
        let result = SyncArgs::try_parse_from(std::iter::once("sync").chain(args.iter().copied()));
        assert!(result.is_ok(), "Failed to parse: {}", cmd_line);
    }
}

#[tokio::test]
async fn test_sync_command_with_real_files() {
    let temp_dir = TempDir::new().unwrap();
    
    // 建立測試檔案
    let video_path = temp_dir.path().join("test.mp4");
    let subtitle_path = temp_dir.path().join("test.srt");
    
    fs::write(&video_path, b"fake video content").unwrap();
    fs::write(&subtitle_path, r#"1
00:00:01,000 --> 00:00:03,000
Test subtitle
"#).unwrap();

    // 測試 dry run 模式
    let args = SyncArgs::try_parse_from([
        "sync",
        "--dry-run",
        "--method", "vad",
        video_path.to_str().unwrap(),
        subtitle_path.to_str().unwrap(),
    ]).unwrap();

    assert!(args.validate().is_ok());
    assert!(args.dry_run);
}
```

## 完成標準

1. ✅ 新的 CLI 參數結構正確定義且支援所有必要選項
2. ✅ 參數驗證邏輯完整且提供清晰的錯誤訊息
3. ✅ 方法選擇參數 (`--method`) 正常運作
4. ✅ Whisper 和 VAD 特定參數正確實作
5. ✅ 參數衝突檢測和處理機制正常
6. ✅ 幫助文本和使用範例完整且準確
7. ✅ 向後兼容性適當處理（deprecated 參數）
8. ✅ 所有單元測試和整合測試通過
9. ✅ CLI 參數與配置檔案正確整合
10. ✅ 錯誤處理和使用者體驗友好

## 使用範例

### 基本使用
```bash
# 自動同步（預設方法）
subx sync video.mp4 subtitle.srt

# 指定方法
subx sync --method whisper video.mp4 subtitle.srt
subx sync --method vad video.mp4 subtitle.srt

# 手動偏移
subx sync --offset 2.5 video.mp4 subtitle.srt
```

### 進階選項
```bash
# Whisper API 自訂設定
subx sync --method whisper \
          --whisper-model whisper-1 \
          --whisper-language zh \
          --whisper-temperature 0.0 \
          video.mp4 subtitle.srt

# 本地 VAD 自訂設定
subx sync --method vad \
          --vad-sensitivity 0.8 \
          --vad-chunk-size 1024 \
          --window 45 \
          video.mp4 subtitle.srt
```

### 實用功能
```bash
# 詳細輸出和乾跑
subx sync --dry-run --verbose video.mp4 subtitle.srt

# 自訂輸出檔案
subx sync --output synced_subtitle.srt video.mp4 subtitle.srt

# 批次處理
subx sync --batch --method vad videos/ subtitles/
```

---

**預估工時**: 4 小時  
**依賴項目**: Backlog 32.1, 32.4 (配置結構和引擎)  
**後續項目**: Backlog 32.6 (文檔和測試更新)
