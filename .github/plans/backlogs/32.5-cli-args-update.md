# Backlog 32.5: CLI åƒæ•¸æ›´æ–°

## æ¦‚è¦½

æ›´æ–° sync æŒ‡ä»¤çš„ CLI åƒæ•¸ä»‹é¢ï¼Œä»¥æ”¯æ´æ–°çš„å¤šæ–¹æ³•åŒæ­¥æ¶æ§‹ã€‚æ–°å¢æ–¹æ³•é¸æ“‡åƒæ•¸ã€é…ç½®è¦†è“‹é¸é …ï¼Œä¸¦ç§»é™¤èˆŠçš„ä¸å†ç›¸é—œçš„åƒæ•¸ã€‚ç¢ºä¿ CLI ä»‹é¢ç›´è§€æ˜“ç”¨ï¼ŒåŒæ™‚ä¿æŒå‘å¾Œå…¼å®¹æ€§ã€‚é€™æ˜¯ [Backlog 32](./32-redesign-sync-command-architecture.md) çš„ç¬¬äº”å€‹å­ä»»å‹™ã€‚

## ç›®æ¨™

1. æ–°å¢åŒæ­¥æ–¹æ³•é¸æ“‡åƒæ•¸ (`--method`)
2. æ–°å¢åˆ†ææ™‚é–“çª—å£åƒæ•¸ (`--window`)
3. æ–°å¢ Whisper ç‰¹å®šåƒæ•¸ï¼ˆæ¨¡å‹ã€èªè¨€ç­‰ï¼‰
4. æ–°å¢ VAD ç‰¹å®šåƒæ•¸ï¼ˆæ•æ„Ÿåº¦ç­‰ï¼‰
5. ç§»é™¤èˆŠçš„ä¸ç›¸é—œåƒæ•¸
6. æ›´æ–°å¹«åŠ©æ–‡æœ¬å’Œç¯„ä¾‹
7. ç¢ºä¿åƒæ•¸é©—è­‰å’ŒéŒ¯èª¤è™•ç†

## æŠ€è¡“è¦æ ¼

### æ–°çš„ CLI åƒæ•¸çµæ§‹

```rust
#[derive(Parser, Debug)]
#[command(
    name = "sync",
    about = "Synchronize subtitles with video audio using AI-powered methods",
    long_about = "Advanced subtitle synchronization using multiple detection methods:\n\
                  â€¢ OpenAI Whisper API for high-accuracy cloud-based transcription\n\
                  â€¢ Local Voice Activity Detection (VAD) for fast, private processing\n\
                  â€¢ Automatic method selection with intelligent fallback"
)]
pub struct SyncArgs {
    /// Video file path
    #[arg(value_name = "VIDEO")]
    pub video: PathBuf,

    /// Subtitle file path
    #[arg(value_name = "SUBTITLE")]
    pub subtitle: PathBuf,

    /// Manual time offset in seconds (positive = delay subtitles, negative = advance)
    #[arg(short, long, conflicts_with_all = ["method", "window"])]
    pub offset: Option<f32>,

    /// Synchronization method to use
    #[arg(
        short, 
        long, 
        value_enum,
        help = "Synchronization method",
        long_help = "Choose the synchronization method:\n\
                     â€¢ whisper: Use OpenAI Whisper API with intelligent VAD fallback\n\
                     â€¢ vad: Use local Voice Activity Detection only\n\
                     â€¢ manual: Apply manual offset (use with --offset)"
    )]
    pub method: Option<SyncMethodArg>,

    /// Analysis time window in seconds (audio around first subtitle)
    #[arg(
        short = 'w',
        long,
        value_name = "SECONDS",
        default_value = "30",
        help = "Time window in seconds to analyze around the first subtitle"
    )]
    pub window: u32,

    /// Enable batch processing mode
    #[arg(short, long)]
    pub batch: bool,

    // === Whisper API specific options ===
    /// Whisper model to use
    #[arg(
        long,
        value_name = "MODEL",
        help = "Whisper model (whisper-1, etc.)",
        requires = "method"
    )]
    pub whisper_model: Option<String>,

    /// Language for Whisper transcription
    #[arg(
        long,
        value_name = "LANG",
        help = "Language code for Whisper (auto, en, zh, etc.)",
        requires = "method"
    )]
    pub whisper_language: Option<String>,

    /// Whisper API temperature
    #[arg(
        long,
        value_name = "TEMP",
        help = "Whisper API temperature (0.0-1.0)",
        requires = "method"
    )]
    pub whisper_temperature: Option<f32>,

    // === VAD specific options ===
    /// VAD sensitivity threshold
    #[arg(
        long,
        value_name = "THRESHOLD",
        help = "VAD sensitivity (0.0-1.0, higher = more sensitive)",
        requires = "method"
    )]
    pub vad_sensitivity: Option<f32>,

    /// VAD chunk size
    #[arg(
        long,
        value_name = "SIZE",
        help = "VAD chunk size in samples (256, 512, 1024, etc.)",
        requires = "method"
    )]
    pub vad_chunk_size: Option<usize>,

    // === Legacy options (deprecated) ===
    /// Maximum offset search range (deprecated, use config file)
    #[arg(long, hide = true)]
    #[deprecated(note = "Use configuration file instead")]
    pub range: Option<f32>,

    /// Minimum correlation threshold (deprecated, use config file)
    #[arg(long, hide = true)]
    #[deprecated(note = "Use configuration file instead")]
    pub threshold: Option<f32>,

    // === Output options ===
    /// Output file path (default: input_synced.ext)
    #[arg(short = 'o', long, value_name = "PATH")]
    pub output: Option<PathBuf>,

    /// Verbose output
    #[arg(short, long)]
    pub verbose: bool,

    /// Dry run - analyze only, don't save result
    #[arg(long)]
    pub dry_run: bool,
}

#[derive(ValueEnum, Clone, Debug)]
pub enum SyncMethodArg {
    /// Use OpenAI Whisper API with intelligent VAD fallback
    Whisper, 
    /// Use local Voice Activity Detection only
    Vad,
    /// Apply manual offset (requires --offset)
    Manual,
}

impl From<SyncMethodArg> for crate::core::sync::SyncMethod {
    fn from(arg: SyncMethodArg) -> Self {
        match arg {
            SyncMethodArg::Whisper => Self::WhisperApi,
            SyncMethodArg::Vad => Self::LocalVad,
            SyncMethodArg::Manual => Self::Manual,
        }
    }
}
```

## å¯¦ä½œæ­¥é©Ÿ

### æ­¥é©Ÿ 1: æ›´æ–° SyncArgs çµæ§‹

**æª”æ¡ˆ**: `src/cli/sync_args.rs`

```rust
//! é‡æ§‹å¾Œçš„åŒæ­¥æŒ‡ä»¤ CLI åƒæ•¸å®šç¾©
//!
//! æ”¯æ´å¤šç¨®åŒæ­¥æ–¹æ³•ï¼šOpenAI Whisper APIã€æœ¬åœ° VADã€è‡ªå‹•é¸æ“‡å’Œæ‰‹å‹•åç§»ã€‚
//! æä¾›ç´°ç·»çš„åƒæ•¸æ§åˆ¶å’Œæ™ºèƒ½é è¨­å€¼ã€‚

use clap::{Parser, ValueEnum};
use std::path::PathBuf;

#[derive(Parser, Debug)]
#[command(
    name = "sync",
    about = "Synchronize subtitles with video audio using AI-powered methods",
    long_about = "Advanced subtitle synchronization supporting multiple detection methods:\n\n\
    METHODS:\n  \
    â€¢ whisper  - OpenAI Whisper API with intelligent VAD fallback\n  \
    â€¢ vad      - Local Voice Activity Detection (privacy-focused)\n  \
    â€¢ manual   - Apply manual time offset\n\n\
    EXAMPLES:\n  \
    # Default Whisper method with fallback\n  \
    subx sync video.mp4 subtitle.srt\n\n  \
    # Use Whisper API with specific model\n  \
    subx sync --method whisper --whisper-model whisper-1 video.mp4 subtitle.srt\n\n  \
    # Local VAD only (no cloud services)\n  \
    subx sync --method vad --vad-sensitivity 0.8 video.mp4 subtitle.srt\n\n  \
    # Manual offset\n  \
    subx sync --offset 2.5 video.mp4 subtitle.srt"
)]
pub struct SyncArgs {
    /// Video file containing the audio track
    #[arg(
        value_name = "VIDEO",
        help = "Path to video file (MP4, MKV, AVI, etc.)"
    )]
    pub video: PathBuf,

    /// Subtitle file to synchronize
    #[arg(
        value_name = "SUBTITLE", 
        help = "Path to subtitle file (SRT, VTT, ASS, etc.)"
    )]
    pub subtitle: PathBuf,

    /// Manual time offset in seconds
    #[arg(
        short,
        long,
        value_name = "SECONDS",
        help = "Manual offset in seconds (positive delays subtitles)",
        long_help = "Apply a manual time offset to all subtitle entries.\n\
                     Positive values delay subtitles (subtitles appear later).\n\
                     Negative values advance subtitles (subtitles appear earlier).\n\
                     Cannot be used with automatic detection methods.",
        conflicts_with_all = ["method", "window", "whisper_model", "whisper_language", "vad_sensitivity"]
    )]
    pub offset: Option<f32>,

    /// Synchronization method
    #[arg(
        short,
        long,
        value_enum,
        help = "Synchronization method to use",
        long_help = "Select the synchronization method:\n\
                     â€¢ whisper (default): Use OpenAI Whisper API with intelligent VAD fallback\n\
                     â€¢ vad: Use local Voice Activity Detection only\n\
                     â€¢ manual: Apply manual offset (requires --offset)"
    )]
    pub method: Option<SyncMethodArg>,

    /// Analysis time window
    #[arg(
        short = 'w',
        long,
        value_name = "SECONDS",
        default_value = "30",
        help = "Time window to analyze around first subtitle (10-300 seconds)",
        value_parser = clap::value_parser!(u32).range(10..=300)
    )]
    pub window: u32,

    // === Whisper API Options ===
    /// Whisper model
    #[arg(
        long,
        value_name = "MODEL",
        help = "Whisper model to use",
        long_help = "Specify the Whisper model:\n\
                     â€¢ whisper-1 (default): Latest Whisper model\n\
                     Note: Model availability depends on your OpenAI subscription."
    )]
    pub whisper_model: Option<String>,

    /// Whisper language
    #[arg(
        long,
        value_name = "LANG",
        help = "Language for Whisper transcription",
        long_help = "Specify the language for Whisper transcription:\n\
                     â€¢ auto (default): Automatic language detection\n\
                     â€¢ en: English\n\
                     â€¢ zh: Chinese\n\
                     â€¢ ja: Japanese\n\
                     â€¢ ko: Korean\n\
                     â€¢ ... (any ISO 639-1 language code)"
    )]
    pub whisper_language: Option<String>,

    /// Whisper temperature
    #[arg(
        long,
        value_name = "TEMP",
        help = "Whisper API temperature (0.0-1.0)",
        long_help = "Control randomness in Whisper transcription:\n\
                     â€¢ 0.0 (default): Most deterministic\n\
                     â€¢ 1.0: Most creative/random\n\
                     Lower values are recommended for synchronization.",
        value_parser = clap::value_parser!(f32).range(0.0..=1.0)
    )]
    pub whisper_temperature: Option<f32>,

    // === VAD Options ===
    /// VAD sensitivity
    #[arg(
        long,
        value_name = "SENSITIVITY",
        help = "VAD sensitivity threshold (0.0-1.0)",
        long_help = "Voice Activity Detection sensitivity:\n\
                     â€¢ 0.5-0.7: Less sensitive, fewer false positives\n\
                     â€¢ 0.75 (default): Balanced\n\
                     â€¢ 0.8-0.9: More sensitive, may catch quiet speech",
        value_parser = clap::value_parser!(f32).range(0.0..=1.0)
    )]
    pub vad_sensitivity: Option<f32>,

    /// VAD chunk size
    #[arg(
        long,
        value_name = "SIZE",
        help = "VAD chunk size in samples",
        long_help = "Audio chunk size for VAD processing:\n\
                     â€¢ 256: Faster, less accurate\n\
                     â€¢ 512 (default): Balanced\n\
                     â€¢ 1024: Slower, more accurate\n\
                     Must be a power of 2.",
        value_parser = validate_chunk_size
    )]
    pub vad_chunk_size: Option<usize>,

    // === Output Options ===
    /// Output file path
    #[arg(
        short = 'o',
        long,
        value_name = "PATH",
        help = "Output file path (default: input_synced.ext)"
    )]
    pub output: Option<PathBuf>,

    /// Enable batch processing
    #[arg(
        short,
        long,
        help = "Enable batch processing mode",
        long_help = "Process multiple subtitle files in the same directory.\n\
                     The video argument should be a directory path."
    )]
    pub batch: bool,

    /// Verbose output
    #[arg(
        short,
        long,
        help = "Enable verbose output with detailed progress information"
    )]
    pub verbose: bool,

    /// Dry run mode
    #[arg(
        long,
        help = "Analyze and show results without saving output file"
    )]
    pub dry_run: bool,

    /// Force overwrite existing output files
    #[arg(
        long,
        help = "Overwrite existing output files without confirmation"
    )]
    pub force: bool,

    // === Legacy/Hidden Options ===
    #[arg(long, hide = true)]
    #[allow(deprecated)]
    pub range: Option<f32>,

    #[arg(long, hide = true)]
    #[allow(deprecated)]
    pub threshold: Option<f32>,
}

#[derive(ValueEnum, Clone, Debug, PartialEq)]
pub enum SyncMethodArg {
    /// Use OpenAI Whisper API with intelligent VAD fallback
    Whisper,
    /// Use local Voice Activity Detection only
    Vad,
    /// Apply manual time offset
    Manual,
}

impl From<SyncMethodArg> for crate::core::sync::SyncMethod {
    fn from(arg: SyncMethodArg) -> Self {
        match arg {
            SyncMethodArg::Whisper => Self::WhisperApi,
            SyncMethodArg::Vad => Self::LocalVad,
            SyncMethodArg::Manual => Self::Manual,
        }
        }
    }
}

impl SyncArgs {
    /// é©—è­‰åƒæ•¸çµ„åˆçš„æœ‰æ•ˆæ€§
    pub fn validate(&self) -> Result<(), String> {
        // æª¢æŸ¥ offset å’Œ method çš„è¡çª
        if self.offset.is_some() && self.method.is_some() {
            return Err("Cannot use --offset with --method. Use --method manual for manual offsets.".to_string());
        }

        // æª¢æŸ¥ manual æ–¹æ³•æ˜¯å¦æœ‰ offset
        if let Some(SyncMethodArg::Manual) = &self.method {
            if self.offset.is_none() {
                return Err("Manual method requires --offset parameter.".to_string());
            }
        }

        // æª¢æŸ¥ Whisper åƒæ•¸
        if self.whisper_model.is_some() || self.whisper_language.is_some() || self.whisper_temperature.is_some() {
            match &self.method {
                Some(SyncMethodArg::Whisper) | None => {},
                _ => return Err("Whisper options can only be used with --method whisper.".to_string()),
            }
        }

        // æª¢æŸ¥ VAD åƒæ•¸
        if self.vad_sensitivity.is_some() || self.vad_chunk_size.is_some() {
            match &self.method {
                Some(SyncMethodArg::Vad) => {},
                _ => return Err("VAD options can only be used with --method vad.".to_string()),
            }
        }

        // æª¢æŸ¥æª”æ¡ˆè·¯å¾‘
        if !self.video.exists() {
            return Err(format!("Video file not found: {}", self.video.display()));
        }

        if !self.subtitle.exists() {
            return Err(format!("Subtitle file not found: {}", self.subtitle.display()));
        }

        Ok(())
    }

    /// å»ºç«‹è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    pub fn get_output_path(&self) -> PathBuf {
        if let Some(ref output) = self.output {
            output.clone()
        } else {
            create_default_output_path(&self.subtitle)
        }
    }

    /// æª¢æŸ¥æ˜¯å¦ç‚ºæ‰‹å‹•æ¨¡å¼
    pub fn is_manual_mode(&self) -> bool {
        self.offset.is_some() || matches!(self.method, Some(SyncMethodArg::Manual))
    }
}

// è¼”åŠ©å‡½å¼
fn validate_chunk_size(s: &str) -> Result<usize, String> {
    let size: usize = s.parse().map_err(|_| "Invalid chunk size")?;
    
    if size < 256 || size > 2048 {
        return Err("Chunk size must be between 256 and 2048".to_string());
    }
    
    if !size.is_power_of_two() {
        return Err("Chunk size must be a power of 2".to_string());
    }
    
    Ok(size)
}

fn create_default_output_path(input: &PathBuf) -> PathBuf {
    let mut output = input.clone();
    
    if let Some(stem) = input.file_stem().and_then(|s| s.to_str()) {
        if let Some(extension) = input.extension().and_then(|s| s.to_str()) {
            let new_filename = format!("{}_synced.{}", stem, extension);
            output.set_file_name(new_filename);
        }
    }
    
    output
}
```

### æ­¥é©Ÿ 2: æ›´æ–°åƒæ•¸è™•ç†é‚è¼¯

**æª”æ¡ˆ**: `src/commands/sync_command.rs`

```rust
//! æ›´æ–°å¾Œçš„åŒæ­¥æŒ‡ä»¤å¯¦ä½œï¼Œæ”¯æ´æ–°çš„ CLI åƒæ•¸

use std::path::Path;
use crate::cli::SyncArgs;
use crate::config::{ConfigService, SyncConfig, WhisperConfig, VadConfig};
use crate::core::formats::manager::FormatManager;
use crate::core::sync::{SyncEngine, SyncMethod};
use crate::{Result, error::SubXError};

/// åŸ·è¡ŒåŒæ­¥æŒ‡ä»¤
pub async fn execute(args: SyncArgs, config_service: &dyn ConfigService) -> Result<()> {
    // é©—è­‰åƒæ•¸
    if let Err(msg) = args.validate() {
        return Err(SubXError::cli(msg));
    }

    // å¦‚æœæœ‰èˆŠçš„å·²æ£„ç”¨åƒæ•¸ï¼Œé¡¯ç¤ºè­¦å‘Š
    if args.range.is_some() || args.threshold.is_some() {
        eprintln!("âš ï¸  Warning: --range and --threshold options are deprecated.");
        eprintln!("   Please use the configuration file to set these values.");
    }

    // å»ºç«‹å‹•æ…‹é…ç½®ï¼ˆçµåˆæª”æ¡ˆé…ç½®å’Œ CLI åƒæ•¸ï¼‰
    let mut config = config_service.get_config()?.clone();
    apply_cli_overrides(&mut config, &args)?;

    // å»ºç«‹åŒæ­¥å¼•æ“
    let sync_engine = SyncEngine::new(config.sync.clone(), config_service).await?;
    
    // è¼‰å…¥å­—å¹•æª”æ¡ˆ
    let format_manager = FormatManager::new();
    let mut subtitle = format_manager.load_subtitle(&args.subtitle)?;

    if args.verbose {
        println!("ğŸ“ Loaded subtitle: {} entries", subtitle.entries.len());
        if !subtitle.entries.is_empty() {
            let first = &subtitle.entries[0];
            println!("   First entry: {:.2}s - {:.2}s", 
                first.start_time.as_secs_f64(), 
                first.end_time.as_secs_f64());
        }
    }

    // åŸ·è¡ŒåŒæ­¥
    let sync_result = if args.is_manual_mode() {
        // æ‰‹å‹•åç§»æ¨¡å¼
        let offset = args.offset.unwrap_or(0.0);
        if args.verbose {
            println!("ğŸ”§ Applying manual offset: {:.3}s", offset);
        }
        sync_engine.apply_manual_offset(&mut subtitle, offset)?
    } else {
        // è‡ªå‹•åŒæ­¥æ¨¡å¼
        let method = args.method.map(|m| m.into()).unwrap_or(SyncMethod::WhisperApi);
        
        if args.verbose {
            println!("ğŸ” Starting synchronization analysis...");
            println!("   Method: {:?}", method);
            println!("   Analysis window: {}s", args.window);
        }
        
        let result = sync_engine.detect_sync_offset(&args.video, &subtitle, Some(method)).await?;
        
        if args.verbose {
            println!("âœ… Analysis complete:");
            println!("   Detected offset: {:.3}s", result.offset_seconds);
            println!("   Confidence: {:.1}%", result.confidence * 100.0);
            println!("   Processing time: {:?}", result.processing_duration);
        }

        // æ‡‰ç”¨æª¢æ¸¬åˆ°çš„åç§»
        if !args.dry_run {
            sync_engine.apply_manual_offset(&mut subtitle, result.offset_seconds)?;
        }
        
        result
    };

    // é¡¯ç¤ºçµæœ
    display_sync_result(&sync_result, args.verbose);

    // å„²å­˜çµæœï¼ˆé™¤éæ˜¯ dry runï¼‰
    if !args.dry_run {
        let output_path = args.get_output_path();
        
        // æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”æ²’æœ‰ force æ¨™è¨˜
        if output_path.exists() && !args.force {
            return Err(SubXError::io(format!(
                "Output file already exists: {}. Use --force to overwrite.",
                output_path.display()
            )));
        }
        
        format_manager.save_subtitle(&subtitle, &output_path)?;
        println!("ğŸ’¾ Synchronized subtitle saved to: {}", output_path.display());
    } else {
        println!("ğŸƒ Dry run completed - no files were modified");
    }

    Ok(())
}

/// å°‡ CLI åƒæ•¸æ‡‰ç”¨åˆ°é…ç½®ä¸­
fn apply_cli_overrides(config: &mut crate::config::Config, args: &SyncArgs) -> Result<()> {
    // æ›´æ–°åˆ†ææ™‚é–“çª—å£
    config.sync.analysis_window_seconds = args.window;

    // æ‡‰ç”¨ Whisper åƒæ•¸è¦†è“‹
    if let Some(ref model) = args.whisper_model {
        config.sync.whisper.model = model.clone();
    }
    if let Some(ref language) = args.whisper_language {
        config.sync.whisper.language = language.clone();
    }
    if let Some(temperature) = args.whisper_temperature {
        config.sync.whisper.temperature = temperature;
    }

    // æ‡‰ç”¨ VAD åƒæ•¸è¦†è“‹
    if let Some(sensitivity) = args.vad_sensitivity {
        config.sync.vad.sensitivity = sensitivity;
    }
    if let Some(chunk_size) = args.vad_chunk_size {
        config.sync.vad.chunk_size = chunk_size;
    }

    // æ ¹æ“šé¸æ“‡çš„æ–¹æ³•å•Ÿç”¨/åœç”¨æª¢æ¸¬å™¨
    match &args.method {
        Some(crate::cli::SyncMethodArg::Whisper) => {
            config.sync.whisper.enabled = true;
            config.sync.vad.enabled = false;
        },
        Some(crate::cli::SyncMethodArg::Vad) => {
            config.sync.whisper.enabled = false;
            config.sync.vad.enabled = true;
        },
        Some(crate::cli::SyncMethodArg::Manual) => {
            config.sync.whisper.enabled = false;
            config.sync.vad.enabled = false;
        },
        Some(crate::cli::SyncMethodArg::Whisper) | None => {
            // Whisper æ¨¡å¼ï¼ˆé è¨­ï¼‰ï¼Œä¿æŒé…ç½®æª”æ¡ˆä¸­çš„è¨­å®š
        },
        Some(crate::cli::SyncMethodArg::Vad) => {
            // VAD åªæ¨¡å¼ï¼Œç¦ç”¨ Whisper
            config.sync.whisper.enabled = false;
        },
    }

    Ok(())
}

fn display_sync_result(result: &crate::core::sync::SyncResult, verbose: bool) {
    println!("\n=== Synchronization Result ===");
    
    match result.method_used {
        crate::core::sync::SyncMethod::Manual => {
            println!("ğŸ“ Method: Manual offset");
        },
        crate::core::sync::SyncMethod::WhisperApi => {
            println!("ğŸ¤– Method: OpenAI Whisper API");
        },
        crate::core::sync::SyncMethod::LocalVad => {
            println!("ğŸ”Š Method: Local Voice Activity Detection");
        },
                });
        },
    }
    
    println!("â±ï¸  Detected offset: {:.3} seconds", result.offset_seconds);
    
    if result.offset_seconds > 0.0 {
        println!("   â†’ Subtitles will be delayed by {:.3}s", result.offset_seconds);
    } else if result.offset_seconds < 0.0 {
        println!("   â†’ Subtitles will be advanced by {:.3}s", -result.offset_seconds);
    } else {
        println!("   â†’ No timing adjustment needed");
    }
    
    println!("ğŸ“Š Confidence: {:.1}%", result.confidence * 100.0);
    
    if verbose {
        println!("â²ï¸  Processing time: {:?}", result.processing_duration);
        
        if !result.warnings.is_empty() {
            println!("\nâš ï¸  Warnings:");
            for warning in &result.warnings {
                println!("   â€¢ {}", warning);
            }
        }
        
        if let Some(info) = &result.additional_info {
            println!("\nğŸ“‹ Additional Details:");
            if let Ok(pretty_info) = serde_json::to_string_pretty(info) {
                for line in pretty_info.lines() {
                    println!("   {}", line);
                }
            }
        }
    }
    
    println!();
}
```

### æ­¥é©Ÿ 3: æ›´æ–°å¹«åŠ©å’Œ UI é¡¯ç¤º

**æª”æ¡ˆ**: `src/cli/ui.rs`

```rust
//! CLI ä½¿ç”¨è€…ä»‹é¢å’Œå¹«åŠ©æ–‡æœ¬

use crate::cli::SyncArgs;
use clap::CommandFactory;

/// é¡¯ç¤º sync æŒ‡ä»¤çš„è©³ç´°å¹«åŠ©
pub fn show_sync_help() {
    let mut app = SyncArgs::command();
    app.print_help().unwrap();
}

/// é¡¯ç¤º sync æŒ‡ä»¤çš„ä½¿ç”¨ç¯„ä¾‹
pub fn show_sync_examples() {
    println!(r#"
SYNC COMMAND EXAMPLES

Basic automatic synchronization:
  subx sync video.mp4 subtitle.srt

Use specific method:
  subx sync --method whisper video.mp4 subtitle.srt
  subx sync --method vad video.mp4 subtitle.srt

Custom analysis window:
  subx sync --window 45 video.mp4 subtitle.srt

Whisper API with custom settings:
  subx sync --method whisper \
            --whisper-model whisper-1 \
            --whisper-language en \
            --whisper-temperature 0.0 \
            video.mp4 subtitle.srt

Local VAD with custom sensitivity:
  subx sync --method vad \
            --vad-sensitivity 0.8 \
            --vad-chunk-size 1024 \
            video.mp4 subtitle.srt

Manual offset:
  subx sync --offset 2.5 video.mp4 subtitle.srt
  subx sync --offset -1.2 video.mp4 subtitle.srt

Dry run (analyze only):
  subx sync --dry-run --verbose video.mp4 subtitle.srt

Batch processing:
  subx sync --batch --method vad videos_dir/ subtitles_dir/

Output to specific file:
  subx sync --output synced_subtitle.srt video.mp4 subtitle.srt

Verbose output with details:
  subx sync --verbose video.mp4 subtitle.srt
"#);
}

/// é¡¯ç¤ºæ–¹æ³•æ¯”è¼ƒè³‡è¨Š
pub fn show_method_comparison() {
    println!(r#"
SYNCHRONIZATION METHODS COMPARISON

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Method    â”‚  Accuracy   â”‚    Speed    â”‚   Privacy   â”‚   Requires  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Whisper API â”‚    High     â”‚   Medium    â”‚    Low*     â”‚  API Key    â”‚
â”‚ Local VAD   â”‚   Medium    â”‚    Fast     â”‚    High     â”‚   Nothing   â”‚
â”‚ Auto        â”‚    High     â”‚   Medium    â”‚   Mixed     â”‚  Optional   â”‚
â”‚ Manual      â”‚ User-depend â”‚   Instant   â”‚    High     â”‚   Nothing   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

* Whisper API sends audio data to OpenAI servers

RECOMMENDATIONS:
â€¢ Use 'auto' for best results with intelligent fallback
â€¢ Use 'whisper' for highest accuracy when API key is available
â€¢ Use 'vad' for fast, private processing without external dependencies
â€¢ Use 'manual' when you know the exact offset needed

CONFIGURATION:
You can set default preferences in ~/.config/subx/config.toml:

[sync]
default_method = "auto"
analysis_window_seconds = 30

[sync.whisper]
enabled = true
model = "whisper-1"
language = "auto"

[sync.vad]
enabled = true
sensitivity = 0.75
chunk_size = 512
"#);
}
```

### æ­¥é©Ÿ 4: æ›´æ–°åƒæ•¸é©—è­‰

**æª”æ¡ˆ**: `src/cli/validation.rs`

```rust
//! CLI åƒæ•¸é©—è­‰é‚è¼¯

use crate::cli::SyncArgs;
use crate::{Result, error::SubXError};
use std::path::Path;

/// é©—è­‰ sync æŒ‡ä»¤åƒæ•¸çš„å®Œæ•´æ€§
pub fn validate_sync_args(args: &SyncArgs) -> Result<()> {
    // åŸºæœ¬æª”æ¡ˆå­˜åœ¨æ€§æª¢æŸ¥
    validate_file_paths(args)?;
    
    // åƒæ•¸çµ„åˆé‚è¼¯æª¢æŸ¥
    validate_parameter_combinations(args)?;
    
    // åƒæ•¸å€¼ç¯„åœæª¢æŸ¥
    validate_parameter_ranges(args)?;
    
    // é…ç½®ä¾è³´æª¢æŸ¥
    validate_configuration_dependencies(args)?;
    
    Ok(())
}

fn validate_file_paths(args: &SyncArgs) -> Result<()> {
    if !args.video.exists() {
        return Err(SubXError::cli(format!(
            "Video file not found: {}", 
            args.video.display()
        )));
    }

    if !args.subtitle.exists() {
        return Err(SubXError::cli(format!(
            "Subtitle file not found: {}", 
            args.subtitle.display()
        )));
    }

    // æª¢æŸ¥æª”æ¡ˆæ˜¯å¦ç‚ºç›®éŒ„ï¼ˆbatch mode ç‰¹æ®Šè™•ç†ï¼‰
    if args.batch {
        if !args.video.is_dir() {
            return Err(SubXError::cli(
                "Batch mode requires video path to be a directory"
            ));
        }
    } else {
        if args.video.is_dir() {
            return Err(SubXError::cli(
                "Video path cannot be a directory in single file mode. Use --batch for directory processing."
            ));
        }
    }

    Ok(())
}

fn validate_parameter_combinations(args: &SyncArgs) -> Result<()> {
    use crate::cli::SyncMethodArg;

    // æ‰‹å‹•æ¨¡å¼é©—è­‰
    if let Some(SyncMethodArg::Manual) = &args.method {
        if args.offset.is_none() {
            return Err(SubXError::cli(
                "Manual method requires --offset parameter"
            ));
        }
    }

    // offset èˆ‡å…¶ä»–åƒæ•¸çš„è¡çª
    if args.offset.is_some() {
        if args.method.is_some() && !matches!(args.method, Some(SyncMethodArg::Manual)) {
            return Err(SubXError::cli(
                "Cannot use --offset with automatic detection methods. Use --method manual for manual offsets."
            ));
        }
        
        if args.window != 30 {
            return Err(SubXError::cli(
                "Cannot use --window with manual offset mode"
            ));
        }
    }

    // Whisper åƒæ•¸é©—è­‰
    let has_whisper_args = args.whisper_model.is_some() 
        || args.whisper_language.is_some() 
        || args.whisper_temperature.is_some();
    
    if has_whisper_args {
        match &args.method {
            Some(SyncMethodArg::Vad) | Some(SyncMethodArg::Manual) => {
                return Err(SubXError::cli(
                    "Whisper options cannot be used with VAD or manual methods"
                ));
            },
            _ => {} // Auto, Whisper, or None are OK
        }
    }

    // VAD åƒæ•¸é©—è­‰
    let has_vad_args = args.vad_sensitivity.is_some() || args.vad_chunk_size.is_some();
    
    if has_vad_args {
        match &args.method {
            Some(SyncMethodArg::Whisper) | Some(SyncMethodArg::Manual) => {
                return Err(SubXError::cli(
                    "VAD options cannot be used with Whisper or manual methods"
                ));
            },
            _ => {} // Auto, VAD, or None are OK
        }
    }

    Ok(())
}

fn validate_parameter_ranges(args: &SyncArgs) -> Result<()> {
    // offset ç¯„åœæª¢æŸ¥
    if let Some(offset) = args.offset {
        if offset.abs() > 3600.0 {
            return Err(SubXError::cli(
                "Offset must be between -3600 and 3600 seconds"
            ));
        }
    }

    // window ç¯„åœæª¢æŸ¥ï¼ˆå·²åœ¨ clap ä¸­å®šç¾©ï¼Œä½†å†æ¬¡æª¢æŸ¥ï¼‰
    if args.window < 10 || args.window > 300 {
        return Err(SubXError::cli(
            "Analysis window must be between 10 and 300 seconds"
        ));
    }

    // Whisper temperature æª¢æŸ¥
    if let Some(temp) = args.whisper_temperature {
        if !(0.0..=1.0).contains(&temp) {
            return Err(SubXError::cli(
                "Whisper temperature must be between 0.0 and 1.0"
            ));
        }
    }

    // VAD sensitivity æª¢æŸ¥
    if let Some(sensitivity) = args.vad_sensitivity {
        if !(0.0..=1.0).contains(&sensitivity) {
            return Err(SubXError::cli(
                "VAD sensitivity must be between 0.0 and 1.0"
            ));
        }
    }

    // VAD chunk size æª¢æŸ¥
    if let Some(chunk_size) = args.vad_chunk_size {
        if chunk_size < 256 || chunk_size > 2048 || !chunk_size.is_power_of_two() {
            return Err(SubXError::cli(
                "VAD chunk size must be a power of 2 between 256 and 2048"
            ));
        }
    }

    Ok(())
}

fn validate_configuration_dependencies(args: &SyncArgs) -> Result<()> {
    use crate::cli::SyncMethodArg;
    
    // æª¢æŸ¥ç‰¹å®šæ–¹æ³•çš„é…ç½®éœ€æ±‚ï¼ˆé€™äº›åœ¨å¯¦éš›åŸ·è¡Œæ™‚æœƒå†æ¬¡æª¢æŸ¥ï¼Œä½†å¯ä»¥æå‰è­¦å‘Šï¼‰
    match &args.method {
        Some(SyncMethodArg::Whisper) => {
            // æª¢æŸ¥æ˜¯å¦å¯èƒ½æœ‰ API é‡‘é‘°ï¼ˆä½†ä¸å¼·åˆ¶è¦æ±‚ï¼Œå› ç‚ºå¯èƒ½åœ¨ç’°å¢ƒè®Šæ•¸ä¸­ï¼‰
            if std::env::var("OPENAI_API_KEY").is_err() {
                eprintln!("âš ï¸  Warning: OPENAI_API_KEY environment variable not set.");
                eprintln!("   Make sure you have configured your OpenAI API key.");
            }
        },
        _ => {}
    }

    Ok(())
}

/// æä¾›åƒæ•¸å»ºè­°å’Œæç¤º
pub fn suggest_parameter_improvements(args: &SyncArgs) {
    let mut suggestions = Vec::new();

    // æ ¹æ“šä¸åŒæƒ…æ³æä¾›å»ºè­°
    if args.method.is_none() && args.offset.is_none() {
        suggestions.push("ğŸ’¡ Tip: Use --method to explicitly choose synchronization method");
    }

    if args.window == 30 && args.method.is_some() {
        suggestions.push("ğŸ’¡ Tip: Try --window 45 or 60 for better accuracy with longer audio");
    }

    if matches!(args.method, Some(crate::cli::SyncMethodArg::Vad)) && args.vad_sensitivity.is_none() {
        suggestions.push("ğŸ’¡ Tip: Adjust --vad-sensitivity (0.6-0.9) if detection is too sensitive/insensitive");
    }

    if !args.verbose && args.method != Some(crate::cli::SyncMethodArg::Manual) {
        suggestions.push("ğŸ’¡ Tip: Use --verbose for detailed analysis information");
    }

    if !suggestions.is_empty() {
        println!();
        for suggestion in suggestions {
            println!("{}", suggestion);
        }
        println!();
    }
}
```

## æ¸¬è©¦ç­–ç•¥

### å–®å…ƒæ¸¬è©¦

**æª”æ¡ˆ**: `src/cli/sync_args.rs`

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use clap::Parser;

    #[test]
    fn test_basic_sync_args_parsing() {
        let args = SyncArgs::try_parse_from([
            "sync", "video.mp4", "subtitle.srt"
        ]).unwrap();
        
        assert_eq!(args.video, PathBuf::from("video.mp4"));
        assert_eq!(args.subtitle, PathBuf::from("subtitle.srt"));
        assert_eq!(args.window, 30);
        assert!(args.method.is_none());
        assert!(args.offset.is_none());
    }

    #[test]
    fn test_method_selection() {
        let test_cases = vec![
            (vec!["sync", "--method", "auto", "video.mp4", "subtitle.srt"], SyncMethodArg::Auto),
            (vec!["sync", "--method", "whisper", "video.mp4", "subtitle.srt"], SyncMethodArg::Whisper),
            (vec!["sync", "--method", "vad", "video.mp4", "subtitle.srt"], SyncMethodArg::Vad),
            (vec!["sync", "--method", "manual", "--offset", "2.5", "video.mp4", "subtitle.srt"], SyncMethodArg::Manual),
        ];

        for (args, expected_method) in test_cases {
            let parsed = SyncArgs::try_parse_from(args).unwrap();
            assert_eq!(parsed.method.unwrap(), expected_method);
        }
    }

    #[test]
    fn test_whisper_options() {
        let args = SyncArgs::try_parse_from([
            "sync", 
            "--method", "whisper",
            "--whisper-model", "whisper-1",
            "--whisper-language", "en", 
            "--whisper-temperature", "0.2",
            "video.mp4", "subtitle.srt"
        ]).unwrap();

        assert_eq!(args.whisper_model, Some("whisper-1".to_string()));
        assert_eq!(args.whisper_language, Some("en".to_string()));
        assert_eq!(args.whisper_temperature, Some(0.2));
    }

    #[test]
    fn test_vad_options() {
        let args = SyncArgs::try_parse_from([
            "sync",
            "--method", "vad",
            "--vad-sensitivity", "0.8",
            "--vad-chunk-size", "1024",
            "video.mp4", "subtitle.srt"
        ]).unwrap();

        assert_eq!(args.vad_sensitivity, Some(0.8));
        assert_eq!(args.vad_chunk_size, Some(1024));
    }

    #[test]
    fn test_manual_offset() {
        let args = SyncArgs::try_parse_from([
            "sync", "--offset", "2.5", "video.mp4", "subtitle.srt"
        ]).unwrap();

        assert_eq!(args.offset, Some(2.5));
        assert!(args.is_manual_mode());
    }

    #[test]
    fn test_parameter_conflicts() {
        // offset èˆ‡ method è¡çª
        assert!(SyncArgs::try_parse_from([
            "sync", "--offset", "2.5", "--method", "whisper", "video.mp4", "subtitle.srt"
        ]).is_err());

        // offset èˆ‡ window è¡çª
        assert!(SyncArgs::try_parse_from([
            "sync", "--offset", "2.5", "--window", "45", "video.mp4", "subtitle.srt"  
        ]).is_err());
    }

    #[test]
    fn test_validation() {
        use std::fs::File;
        use tempfile::TempDir;

        let temp_dir = TempDir::new().unwrap();
        let video_path = temp_dir.path().join("video.mp4");
        let subtitle_path = temp_dir.path().join("subtitle.srt");

        // å»ºç«‹æ¸¬è©¦æª”æ¡ˆ
        File::create(&video_path).unwrap();
        File::create(&subtitle_path).unwrap();

        let args = SyncArgs {
            video: video_path,
            subtitle: subtitle_path,
            offset: None,
            method: Some(SyncMethodArg::Auto),
            window: 30,
            whisper_model: None,
            whisper_language: None,
            whisper_temperature: None,
            vad_sensitivity: None,
            vad_chunk_size: None,
            output: None,
            batch: false,
            verbose: false,
            dry_run: false,
            force: false,
            range: None,
            threshold: None,
        };

        assert!(args.validate().is_ok());
    }

    #[test]
    fn test_chunk_size_validation() {
        // æœ‰æ•ˆçš„ chunk sizes
        assert!(validate_chunk_size("256").is_ok());
        assert!(validate_chunk_size("512").is_ok());
        assert!(validate_chunk_size("1024").is_ok());

        // ç„¡æ•ˆçš„ chunk sizes
        assert!(validate_chunk_size("255").is_err()); // ä¸æ˜¯ 2 çš„å†ªæ¬¡
        assert!(validate_chunk_size("100").is_err()); // å¤ªå°
        assert!(validate_chunk_size("4096").is_err()); // å¤ªå¤§
    }

    #[test]
    fn test_default_output_path() {
        let input = PathBuf::from("test.srt");
        let output = create_default_output_path(&input);
        assert_eq!(output, PathBuf::from("test_synced.srt"));

        let input = PathBuf::from("/path/to/subtitle.vtt");
        let output = create_default_output_path(&input);
        assert_eq!(output, PathBuf::from("/path/to/subtitle_synced.vtt"));
    }
}
```

### æ•´åˆæ¸¬è©¦

**æª”æ¡ˆ**: `tests/sync_cli_integration_tests.rs`

```rust
use subx_cli::cli::SyncArgs;
use clap::Parser;
use std::process::Command;
use tempfile::TempDir;
use std::fs;

#[test]
fn test_sync_command_help() {
    let output = Command::new("cargo")
        .args(["run", "--", "sync", "--help"])
        .output()
        .expect("Failed to execute command");

    let help_text = String::from_utf8(output.stdout).unwrap();
    assert!(help_text.contains("Synchronize subtitles with video audio"));
    assert!(help_text.contains("--method"));
    assert!(help_text.contains("--whisper-model"));
    assert!(help_text.contains("--vad-sensitivity"));
}

#[test]
fn test_sync_command_examples() {
    let test_cases = vec![
        // åŸºæœ¬è‡ªå‹•åŒæ­¥
        "subx sync video.mp4 subtitle.srt",
        
        // æŒ‡å®šæ–¹æ³•
        "subx sync --method whisper video.mp4 subtitle.srt",
        "subx sync --method vad video.mp4 subtitle.srt",
        
        // æ‰‹å‹•åç§»
        "subx sync --offset 2.5 video.mp4 subtitle.srt",
        
        // Whisper é¸é …
        "subx sync --method whisper --whisper-model whisper-1 video.mp4 subtitle.srt",
        
        // VAD é¸é …
        "subx sync --method vad --vad-sensitivity 0.8 video.mp4 subtitle.srt",
        
        // è¼¸å‡ºé¸é …
        "subx sync --output synced.srt video.mp4 subtitle.srt",
        "subx sync --dry-run --verbose video.mp4 subtitle.srt",
    ];

    for cmd_line in test_cases {
        let parts: Vec<&str> = cmd_line.split_whitespace().collect();
        let args = &parts[2..]; // è·³é "subx sync"
        
        let result = SyncArgs::try_parse_from(std::iter::once("sync").chain(args.iter().copied()));
        assert!(result.is_ok(), "Failed to parse: {}", cmd_line);
    }
}

#[tokio::test]
async fn test_sync_command_with_real_files() {
    let temp_dir = TempDir::new().unwrap();
    
    // å»ºç«‹æ¸¬è©¦æª”æ¡ˆ
    let video_path = temp_dir.path().join("test.mp4");
    let subtitle_path = temp_dir.path().join("test.srt");
    
    fs::write(&video_path, b"fake video content").unwrap();
    fs::write(&subtitle_path, r#"1
00:00:01,000 --> 00:00:03,000
Test subtitle
"#).unwrap();

    // æ¸¬è©¦ dry run æ¨¡å¼
    let args = SyncArgs::try_parse_from([
        "sync",
        "--dry-run",
        "--method", "vad",
        video_path.to_str().unwrap(),
        subtitle_path.to_str().unwrap(),
    ]).unwrap();

    assert!(args.validate().is_ok());
    assert!(args.dry_run);
}
```

## å®Œæˆæ¨™æº–

1. âœ… æ–°çš„ CLI åƒæ•¸çµæ§‹æ­£ç¢ºå®šç¾©ä¸”æ”¯æ´æ‰€æœ‰å¿…è¦é¸é …
2. âœ… åƒæ•¸é©—è­‰é‚è¼¯å®Œæ•´ä¸”æä¾›æ¸…æ™°çš„éŒ¯èª¤è¨Šæ¯
3. âœ… æ–¹æ³•é¸æ“‡åƒæ•¸ (`--method`) æ­£å¸¸é‹ä½œ
4. âœ… Whisper å’Œ VAD ç‰¹å®šåƒæ•¸æ­£ç¢ºå¯¦ä½œ
5. âœ… åƒæ•¸è¡çªæª¢æ¸¬å’Œè™•ç†æ©Ÿåˆ¶æ­£å¸¸
6. âœ… å¹«åŠ©æ–‡æœ¬å’Œä½¿ç”¨ç¯„ä¾‹å®Œæ•´ä¸”æº–ç¢º
7. âœ… å‘å¾Œå…¼å®¹æ€§é©ç•¶è™•ç†ï¼ˆdeprecated åƒæ•¸ï¼‰
8. âœ… æ‰€æœ‰å–®å…ƒæ¸¬è©¦å’Œæ•´åˆæ¸¬è©¦é€šé
9. âœ… CLI åƒæ•¸èˆ‡é…ç½®æª”æ¡ˆæ­£ç¢ºæ•´åˆ
10. âœ… éŒ¯èª¤è™•ç†å’Œä½¿ç”¨è€…é«”é©—å‹å¥½

## ä½¿ç”¨ç¯„ä¾‹

### åŸºæœ¬ä½¿ç”¨
```bash
# è‡ªå‹•åŒæ­¥ï¼ˆé è¨­æ–¹æ³•ï¼‰
subx sync video.mp4 subtitle.srt

# æŒ‡å®šæ–¹æ³•
subx sync --method whisper video.mp4 subtitle.srt
subx sync --method vad video.mp4 subtitle.srt

# æ‰‹å‹•åç§»
subx sync --offset 2.5 video.mp4 subtitle.srt
```

### é€²éšé¸é …
```bash
# Whisper API è‡ªè¨‚è¨­å®š
subx sync --method whisper \
          --whisper-model whisper-1 \
          --whisper-language zh \
          --whisper-temperature 0.0 \
          video.mp4 subtitle.srt

# æœ¬åœ° VAD è‡ªè¨‚è¨­å®š
subx sync --method vad \
          --vad-sensitivity 0.8 \
          --vad-chunk-size 1024 \
          --window 45 \
          video.mp4 subtitle.srt
```

### å¯¦ç”¨åŠŸèƒ½
```bash
# è©³ç´°è¼¸å‡ºå’Œä¹¾è·‘
subx sync --dry-run --verbose video.mp4 subtitle.srt

# è‡ªè¨‚è¼¸å‡ºæª”æ¡ˆ
subx sync --output synced_subtitle.srt video.mp4 subtitle.srt

# æ‰¹æ¬¡è™•ç†
subx sync --batch --method vad videos/ subtitles/
```

---

**é ä¼°å·¥æ™‚**: 4 å°æ™‚  
**ä¾è³´é …ç›®**: Backlog 32.1, 32.4 (é…ç½®çµæ§‹å’Œå¼•æ“)  
**å¾ŒçºŒé …ç›®**: Backlog 32.6 (æ–‡æª”å’Œæ¸¬è©¦æ›´æ–°)
