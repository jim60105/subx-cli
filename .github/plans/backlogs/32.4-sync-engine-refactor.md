# Backlog 32.4: 同步引擎重構

## 概覽

重構現有的同步引擎，移除基於包絡頻譜分析的舊邏輯，整合新的 OpenAI Whisper API 和本地 VAD 方法。建立統一的同步引擎介面，支援方法選擇、自動回退和結果整合。這是 [Backlog 32](./32-redesign-sync-command-architecture.md) 的第四個子任務。

## 目標

1. 重構 `SyncEngine` 以支援多種同步方法
2. 移除舊的包絡頻譜分析程式碼
3. 整合 Whisper API 和本地 VAD 檢測器
4. 實作自動方法選擇和回退機制
5. 建立統一的結果評估和選擇邏輯
6. 更新所有相關的測試和文檔

## 技術規格

### 新的同步引擎架構

```rust
/// 統一的同步引擎，支援多種同步方法
pub struct SyncEngine {
    config: SyncConfig,
    whisper_detector: Option<WhisperSyncDetector>,
    vad_detector: Option<VadSyncDetector>,
    audio_extractor: AudioSegmentExtractor,
}

/// 同步方法枚舉
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum SyncMethod {
    /// 使用 OpenAI Whisper API（含智能回退到 VAD）
    WhisperApi,
    /// 使用本地 VAD
    LocalVad,
    /// 手動偏移（現有功能保持不變）
    Manual,
}

/// 同步結果結構（擴展版）
#[derive(Debug, Clone)]
pub struct SyncResult {
    /// 檢測到的時間偏移（秒）
    pub offset_seconds: f32,
    /// 檢測信心度 (0.0-1.0)
    pub confidence: f32,
    /// 使用的檢測方法
    pub method_used: SyncMethod,
    /// 相關性峰值（保持向後兼容）
    pub correlation_peak: f32,
    /// 額外資訊（JSON 格式）
    pub additional_info: Option<serde_json::Value>,
    /// 處理時間
    pub processing_duration: Duration,
    /// 錯誤或警告訊息
    pub warnings: Vec<String>,
}

/// 方法選擇策略
#[derive(Debug, Clone)]
pub struct MethodSelectionStrategy {
    /// 優先方法順序
    pub preferred_methods: Vec<SyncMethod>,
    /// 最低可接受信心度
    pub min_confidence_threshold: f32,
    /// 是否允許回退到較低精度方法
    pub allow_fallback: bool,
    /// 最大嘗試時間（秒）
    pub max_attempt_duration: u32,
}
```

### 核心引擎邏輯

```rust
impl SyncEngine {
    /// 建立新的同步引擎實例
    pub async fn new(config: SyncConfig, config_service: &dyn ConfigService) -> Result<Self> {
        // 根據配置建立檢測器
        let whisper_detector = if config.whisper.enabled {
            Some(Self::create_whisper_detector(&config, config_service).await?)
        } else {
            None
        };

        let vad_detector = if config.vad.enabled {
            Some(VadSyncDetector::new(config.vad.clone())?)
        } else {
            None
        };

        Ok(Self {
            config,
            whisper_detector,
            vad_detector,
            audio_extractor: AudioSegmentExtractor::new()?,
        })
    }

    /// 主要同步檢測方法
    pub async fn detect_sync_offset(
        &self,
        audio_path: &Path,
        subtitle: &Subtitle,
        method: Option<SyncMethod>,
    ) -> Result<SyncResult> {
        let start_time = Instant::now();
        let method = method.unwrap_or_else(|| self.determine_default_method());
        
        match method {
            SyncMethod::WhisperApi => self.whisper_detect_sync_offset(audio_path, subtitle).await,
            SyncMethod::LocalVad => self.vad_detect_sync_offset(audio_path, subtitle).await,
            SyncMethod::Manual => Err(SubXError::sync("Manual method requires explicit offset")),
        }
        .map(|mut result| {
            result.processing_duration = start_time.elapsed();
            result
        })
    }

        for method in strategy.preferred_methods {
            match method {
                SyncMethod::WhisperApi => {
                    if let Some(ref detector) = self.whisper_detector {
                        match detector.detect_sync_offset(
                            audio_path,
                            subtitle,
                            self.config.analysis_window_seconds,
                        ).await {
                            Ok(result) => {
                                if result.confidence >= strategy.min_confidence_threshold {
                                    return Ok(result);
                                }
                                if best_result.is_none() || 
                                   result.confidence > best_result.as_ref().unwrap().confidence {
                                    best_result = Some(result);
                                }
                            },
                            Err(e) => {
                                all_warnings.push(format!("Whisper API failed: {}", e));
                                if !strategy.allow_fallback {
                                    return Err(e);
                                }
                            }
                        }
                    }
                },
                SyncMethod::LocalVad => {
                    if let Some(ref detector) = self.vad_detector {
                        match detector.detect_sync_offset(
                            audio_path,
                            subtitle,
                            self.config.analysis_window_seconds,
                        ).await {
                            Ok(result) => {
                                if result.confidence >= strategy.min_confidence_threshold {
                                    let mut final_result = result;
                                    final_result.warnings.extend(all_warnings);
                                    return Ok(final_result);
                                }
                                if best_result.is_none() || 
                                   result.confidence > best_result.as_ref().unwrap().confidence {
                                    best_result = Some(result);
                                }
                            },
                            Err(e) => {
                                all_warnings.push(format!("Local VAD failed: {}", e));
                                if !strategy.allow_fallback {
                                    return Err(e);
                                }
                            }
                        }
                    }
                },
                _ => continue,
            }
        }

        // 回傳最佳結果（即使信心度不理想）
        if let Some(mut result) = best_result {
            result.warnings.extend(all_warnings);
            result.warnings.push(format!(
                "No method achieved minimum confidence threshold of {:.1}%",
                strategy.min_confidence_threshold * 100.0
            ));
            Ok(result)
        } else {
            Err(SubXError::sync("All synchronization methods failed"))
        }
    }
}
```

## 實作步驟

### 步驟 1: 更新同步引擎核心

**檔案**: `src/core/sync/engine.rs`

```rust
//! 重構後的同步引擎，支援多種檢測方法
//!
//! 此模組提供統一的字幕同步功能，整合 OpenAI Whisper API 和本地 VAD
//! 等多種語音檢測方法，並提供自動方法選擇和回退機制。

use std::path::Path;
use std::time::{Duration, Instant};
use serde::{Deserialize, Serialize};
use serde_json::json;

use crate::config::{SyncConfig, ConfigService};
use crate::core::formats::{Subtitle, SubtitleEntry};
use crate::services::whisper::{WhisperSyncDetector, AudioSegmentExtractor};
use crate::services::vad::VadSyncDetector;
use crate::{Result, error::SubXError};

/// 統一的同步引擎
pub struct SyncEngine {
    config: SyncConfig,
    whisper_detector: Option<WhisperSyncDetector>,
    vad_detector: Option<VadSyncDetector>,
    audio_extractor: AudioSegmentExtractor,
}

impl SyncEngine {
    /// 建立新的同步引擎實例
    pub async fn new(config: SyncConfig, config_service: &dyn ConfigService) -> Result<Self> {
        // 建立 Whisper 檢測器（如果啟用）
        let whisper_detector = if config.whisper.enabled {
            match Self::create_whisper_detector(&config, config_service).await {
                Ok(detector) => Some(detector),
                Err(e) => {
                    log::warn!("Failed to create Whisper detector: {}", e);
                    None
                }
            }
        } else {
            None
        };

        // 建立 VAD 檢測器（如果啟用）
        let vad_detector = if config.vad.enabled {
            match VadSyncDetector::new(config.vad.clone()) {
                Ok(detector) => Some(detector),
                Err(e) => {
                    log::warn!("Failed to create VAD detector: {}", e);
                    None
                }
            }
        } else {
            None
        };

        // 檢查至少有一種方法可用
        if whisper_detector.is_none() && vad_detector.is_none() {
            return Err(SubXError::config("No synchronization methods are available"));
        }

        Ok(Self {
            config,
            whisper_detector,
            vad_detector,
            audio_extractor: AudioSegmentExtractor::new()?,
        })
    }

    async fn create_whisper_detector(
        config: &SyncConfig,
        config_service: &dyn ConfigService,
    ) -> Result<WhisperSyncDetector> {
        let full_config = config_service.get_config()?;
        
        // 獲取 API 金鑰
        let api_key = full_config.ai.api_key
            .or_else(|| std::env::var("OPENAI_API_KEY").ok())
            .ok_or_else(|| SubXError::config("OpenAI API key not found"))?;

        WhisperSyncDetector::new(
            api_key,
            full_config.ai.base_url,
            config.whisper.clone(),
        )
    }

    /// 檢測同步偏移量
    pub async fn detect_sync_offset(
        &self,
        audio_path: &Path,
        subtitle: &Subtitle,
        method: Option<SyncMethod>,
    ) -> Result<SyncResult> {
        let start_time = Instant::now();
        let method = method.unwrap_or_else(|| self.determine_default_method());
        
        let mut result = match method {
            SyncMethod::Auto => self.auto_detect_sync_offset(audio_path, subtitle).await?,
            SyncMethod::WhisperApi => self.whisper_detect_sync_offset(audio_path, subtitle).await?,
            SyncMethod::LocalVad => self.vad_detect_sync_offset(audio_path, subtitle).await?,
            SyncMethod::Manual => {
                return Err(SubXError::sync("Manual method requires explicit offset"));
            }
        };

        result.processing_duration = start_time.elapsed();
        Ok(result)
    }

    /// 應用手動偏移量
    pub fn apply_manual_offset(
        &self,
        subtitle: &mut Subtitle,
        offset_seconds: f32,
    ) -> Result<SyncResult> {
        let start_time = Instant::now();
        
        // 應用偏移到所有字幕條目
        for entry in &mut subtitle.entries {
            entry.start_time = entry.start_time
                .checked_add(Duration::from_secs_f32(offset_seconds.abs()))
                .or_else(|| {
                    if offset_seconds < 0.0 {
                        entry.start_time.checked_sub(Duration::from_secs_f32(-offset_seconds))
                    } else {
                        None
                    }
                })
                .ok_or_else(|| SubXError::sync("Invalid offset would result in negative time"))?;
            
            entry.end_time = entry.end_time
                .checked_add(Duration::from_secs_f32(offset_seconds.abs()))
                .or_else(|| {
                    if offset_seconds < 0.0 {
                        entry.end_time.checked_sub(Duration::from_secs_f32(-offset_seconds))
                    } else {
                        None
                    }
                })
                .ok_or_else(|| SubXError::sync("Invalid offset would result in negative time"))?;
        }

        Ok(SyncResult {
            offset_seconds,
            confidence: 1.0, // 手動偏移總是 100% 信心度
            method_used: SyncMethod::Manual,
            correlation_peak: 1.0,
            additional_info: Some(json!({
                "applied_offset": offset_seconds,
                "entries_modified": subtitle.entries.len(),
            })),
            processing_duration: start_time.elapsed(),
            warnings: vec![],
        })
    }

    fn determine_default_method(&self) -> SyncMethod {
        match self.config.default_method.as_str() {
            "whisper" => SyncMethod::WhisperApi,
            "vad" => SyncMethod::LocalVad,
            _ => SyncMethod::WhisperApi, // 預設使用 Whisper
        }
    }

    async fn whisper_detect_sync_offset(
        &self,
        audio_path: &Path,
        subtitle: &Subtitle,
    ) -> Result<SyncResult> {
        let whisper_detector = self.whisper_detector.as_ref()
            .ok_or_else(|| SubXError::sync("Whisper API detector not available"))?;
        
        // 嘗試使用 Whisper API
        let whisper_result = whisper_detector.detect_sync_offset(
            audio_path,
            subtitle,
            self.config.analysis_window_seconds,
        ).await;
        
        match whisper_result {
            Ok(mut result) => {
                // 檢查信心度是否滿足閾值
                if result.confidence >= self.config.whisper.min_confidence_threshold {
                    return Ok(result);
                }
                
                // 信心度不足，如果啟用回退則嘗試 VAD
                if self.config.whisper.fallback_to_vad {
                    if let Some(vad_detector) = &self.vad_detector {
                        match vad_detector.detect_sync_offset(
                            audio_path,
                            subtitle,
                            self.config.analysis_window_seconds,
                        ).await {
                            Ok(vad_result) => {
                                result.warnings.push(format!(
                                    "Whisper confidence ({:.1}%) below threshold ({:.1}%), fallback to VAD", 
                                    result.confidence * 100.0,
                                    self.config.whisper.min_confidence_threshold * 100.0
                                ));
                                return Ok(vad_result);
                            },
                            Err(_) => {
                                result.warnings.push(
                                    "Whisper confidence below threshold and VAD fallback failed".to_string()
                                );
                                return Ok(result); // 仍回傳 Whisper 結果，但標記警告
                            }
                        }
                    } else {
                        result.warnings.push(
                            "Whisper confidence below threshold but VAD not available".to_string()
                        );
                        return Ok(result);
                    }
                } else {
                    result.warnings.push(format!(
                        "Whisper confidence ({:.1}%) below threshold ({:.1}%) and fallback disabled", 
                        result.confidence * 100.0,
                        self.config.whisper.min_confidence_threshold * 100.0
                    ));
                    return Ok(result);
                }
            },
            Err(e) => {
                // Whisper API 調用失敗，如果啟用回退則嘗試 VAD
                if self.config.whisper.fallback_to_vad {
                    if let Some(vad_detector) = &self.vad_detector {
                        match vad_detector.detect_sync_offset(
                            audio_path,
                            subtitle,
                            self.config.analysis_window_seconds,
                        ).await {
                            Ok(mut vad_result) => {
                                vad_result.warnings.push(format!(
                                    "Whisper API failed ({}), fallback to VAD", e
                                ));
                                return Ok(vad_result);
                            },
                            Err(vad_error) => {
                                return Err(SubXError::sync(format!(
                                    "Whisper API failed: {}, VAD fallback also failed: {}", 
                                    e, vad_error
                                )));
                            }
                        }
                    } else {
                        return Err(SubXError::sync(format!(
                            "Whisper API failed: {}, VAD not available for fallback", e
                        )));
                    }
                } else {
                    return Err(e); // 不啟用回退，直接返回錯誤
                }
            }
        }
    }

    async fn vad_detect_sync_offset(
        &self,
        audio_path: &Path,
        subtitle: &Subtitle,
    ) -> Result<SyncResult> {
        let detector = self.vad_detector.as_ref()
            .ok_or_else(|| SubXError::sync("Local VAD detector not available"))?;
        
        detector.detect_sync_offset(
            audio_path,
            subtitle,
            self.config.analysis_window_seconds,
        ).await
    }

    }
}

// 資料結構定義
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum SyncMethod {
    WhisperApi,
    LocalVad,
    Manual,
}

#[derive(Debug, Clone)]
pub struct SyncResult {
    pub offset_seconds: f32,
    pub confidence: f32,
    pub method_used: SyncMethod,
    pub correlation_peak: f32,
    pub additional_info: Option<serde_json::Value>,
    pub processing_duration: Duration,
    pub warnings: Vec<String>,
}

// 向後兼容性 - 保留舊的 SyncConfig 結構但標記為 deprecated
#[deprecated(note = "Use new SyncConfig with Whisper and VAD support")]
pub struct OldSyncConfig {
    pub max_offset_seconds: f32,
    pub correlation_threshold: f32,
    pub dialogue_threshold: f32,
    pub min_dialogue_length: f32,
}
```

### 步驟 2: 移除舊程式碼

需要移除或重構的檔案：

1. **`src/core/sync/dialogue/`** - 移除整個目錄（包絡頻譜分析相關）
2. **`src/services/audio/analyzer.rs`** - 移除相關的包絡頻譜分析方法
3. **測試檔案** - 移除相關的測試

**檔案清理列表**:
```bash
# 需要移除的檔案和目錄
rm -rf src/core/sync/dialogue/
rm -f src/core/sync/dialogue.rs

# 需要更新的檔案（移除舊功能）
# src/services/audio/analyzer.rs - 移除包絡頻譜相關方法
# src/core/sync/engine.rs - 已完全重寫
# tests/ - 移除相關測試檔案
```

### 步驟 3: 更新同步命令整合

**檔案**: `src/commands/sync_command.rs`

```rust
//! 重構後的同步命令，支援新的多方法同步引擎

use std::path::Path;
use crate::cli::SyncArgs;
use crate::config::ConfigService;
use crate::core::formats::manager::FormatManager;
use crate::core::sync::{SyncEngine, SyncMethod, SyncResult};
use crate::{Result, error::SubXError};

/// 執行同步命令
pub async fn execute(args: SyncArgs, config_service: &dyn ConfigService) -> Result<()> {
    let config = config_service.get_config()?;
    
    // 建立同步引擎
    let sync_engine = SyncEngine::new(config.sync.clone(), config_service).await?;
    
    // 載入字幕檔案
    let format_manager = FormatManager::new();
    let mut subtitle = format_manager.load_subtitle(&args.subtitle)?;
    
    let sync_result = if let Some(manual_offset) = args.offset {
        // 手動偏移模式
        sync_engine.apply_manual_offset(&mut subtitle, manual_offset)?
    } else {
        // 自動同步模式
        let method = determine_sync_method(&args, &config.sync.default_method)?;
        sync_engine.detect_sync_offset(&args.video, &subtitle, Some(method)).await?
    };

    // 顯示結果
    display_sync_result(&sync_result);

    // 如果不是手動模式，應用檢測到的偏移
    if args.offset.is_none() {
        sync_engine.apply_manual_offset(&mut subtitle, sync_result.offset_seconds)?;
    }

    // 儲存同步後的字幕
    let output_path = determine_output_path(&args.subtitle)?;
    format_manager.save_subtitle(&subtitle, &output_path)?;
    
    println!("Synchronized subtitle saved to: {}", output_path.display());
    Ok(())
}

fn determine_sync_method(args: &SyncArgs, default_method: &str) -> Result<SyncMethod> {
    // 從命令列參數或配置中確定同步方法
    // 注意：這需要對應的 CLI 參數更新（在後續 backlog 中）
    match default_method {
        "whisper" => Ok(SyncMethod::WhisperApi),
        "vad" => Ok(SyncMethod::LocalVad),
        "auto" => Ok(SyncMethod::Auto),
        _ => Ok(SyncMethod::Auto),
    }
}

fn display_sync_result(result: &SyncResult) {
    println!("=== Synchronization Result ===");
    println!("Method used: {:?}", result.method_used);
    println!("Detected offset: {:.3} seconds", result.offset_seconds);
    println!("Confidence: {:.1}%", result.confidence * 100.0);
    println!("Processing time: {:?}", result.processing_duration);
    
    if !result.warnings.is_empty() {
        println!("\nWarnings:");
        for warning in &result.warnings {
            println!("  ⚠️  {}", warning);
        }
    }
    
    if let Some(info) = &result.additional_info {
        if let Ok(pretty_info) = serde_json::to_string_pretty(info) {
            println!("\nAdditional information:");
            println!("{}", pretty_info);
        }
    }
}

fn determine_output_path(input_path: &Path) -> Result<std::path::PathBuf> {
    // 建立同步後檔案的輸出路徑
    let mut output_path = input_path.to_path_buf();
    
    if let Some(stem) = input_path.file_stem().and_then(|s| s.to_str()) {
        if let Some(extension) = input_path.extension().and_then(|s| s.to_str()) {
            let new_filename = format!("{}_synced.{}", stem, extension);
            output_path.set_file_name(new_filename);
        }
    }
    
    Ok(output_path)
}
```

### 步驟 4: 更新模組結構

**檔案**: `src/core/sync/mod.rs`

```rust
//! 重構後的同步模組
//!
//! 提供多種語音檢測方法的統一字幕同步功能，包括：
//! - OpenAI Whisper API 雲端轉錄
//! - 本地 Voice Activity Detection (VAD)
//! - 自動方法選擇和回退機制

pub mod engine;

// 重新匯出主要類型
pub use engine::{SyncEngine, SyncMethod, SyncResult, MethodSelectionStrategy};

// 向後兼容性匯出（但標記為 deprecated）
#[deprecated(note = "Use new SyncEngine with multi-method support")]
pub use engine::OldSyncConfig;
```

## 測試策略

### 單元測試

**檔案**: `src/core/sync/engine.rs`

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use crate::config::{TestConfigBuilder, TestConfigService};
    use crate::core::formats::{Subtitle, SubtitleEntry, SubtitleMetadata, SubtitleFormatType};
    use std::time::Duration;
    use tempfile::TempDir;
    use tokio_test;

    #[tokio::test]
    async fn test_sync_engine_creation() {
        let config = TestConfigBuilder::new()
            .with_whisper_enabled(false) // 避免需要 API 金鑰
            .with_vad_enabled(true)
            .build_config();
            
        let config_service = TestConfigService::new(config);
        
        let result = SyncEngine::new(config_service.get_config().unwrap().sync, &config_service).await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_manual_offset_application() {
        let config = TestConfigBuilder::new().build_config();
        let config_service = TestConfigService::new(config);
        let engine = SyncEngine::new(config_service.get_config().unwrap().sync, &config_service).await.unwrap();

        let mut subtitle = create_test_subtitle();
        let original_start = subtitle.entries[0].start_time;
        
        let result = engine.apply_manual_offset(&mut subtitle, 2.5).unwrap();
        
        assert_eq!(result.offset_seconds, 2.5);
        assert_eq!(result.method_used, SyncMethod::Manual);
        assert_eq!(result.confidence, 1.0);
        
        // 驗證偏移已應用
        let expected_start = original_start + Duration::from_secs_f32(2.5);
        assert_eq!(subtitle.entries[0].start_time, expected_start);
    }

    #[tokio::test]
    async fn test_method_selection_strategy() {
        let config = TestConfigBuilder::new()
            .with_whisper_enabled(true)
            .with_vad_enabled(true)
            .build_config();
            
    #[tokio::test]
    async fn test_determine_default_method() {
        let test_cases = vec![
            ("whisper", SyncMethod::WhisperApi),
            ("vad", SyncMethod::LocalVad),
            ("unknown", SyncMethod::WhisperApi), // 未知值預設到 Whisper
        ];

        for (config_value, expected_method) in test_cases {
            let config = TestConfigBuilder::new()
                .with_sync_method(config_value)
                .build_config();
                
            let config_service = TestConfigService::new(config);
            let engine = SyncEngine::new(config_service.get_config().unwrap().sync, &config_service).await.unwrap();
            
            assert_eq!(engine.determine_default_method(), expected_method);
        }
    }

    fn create_test_subtitle() -> Subtitle {
        Subtitle {
            entries: vec![
                SubtitleEntry::new(
                    1,
                    Duration::from_secs(10),
                    Duration::from_secs(12),
                    "Test subtitle".to_string(),
                ),
            ],
            metadata: SubtitleMetadata::default(),
            format: SubtitleFormatType::Srt,
        }
    }
}
```

### 整合測試

**檔案**: `tests/sync_engine_integration_tests.rs`

```rust
use subx_cli::core::sync::{SyncEngine, SyncMethod};
use subx_cli::config::{TestConfigBuilder, TestConfigService};
use subx_cli::core::formats::{Subtitle, SubtitleEntry, SubtitleMetadata, SubtitleFormatType};
use std::time::Duration;
use tempfile::TempDir;

#[tokio::test]
async fn test_sync_engine_with_vad_only() {
    let temp_dir = TempDir::new().unwrap();
    
    // 建立測試音訊和字幕
    let audio_path = temp_dir.path().join("test.wav");
    let subtitle = create_test_subtitle_with_offset();
    create_test_audio(&audio_path);
    
    // 配置只啟用 VAD
    let config = TestConfigBuilder::new()
        .with_whisper_enabled(false)
        .with_vad_enabled(true)
        .build_config();
        
    let config_service = TestConfigService::new(config);
    let engine = SyncEngine::new(config_service.get_config().unwrap().sync, &config_service).await.unwrap();
    
    // 執行同步檢測
    let result = engine.detect_sync_offset(
        &audio_path,
        &subtitle,
        Some(SyncMethod::LocalVad),
    ).await.unwrap();
    
    assert_eq!(result.method_used, SyncMethod::LocalVad);
    assert!(result.confidence > 0.0);
}

#[tokio::test] 
async fn test_auto_method_selection_fallback() {
    let temp_dir = TempDir::new().unwrap();
    let audio_path = temp_dir.path().join("test.wav");
    let subtitle = create_test_subtitle_with_offset();
    create_test_audio(&audio_path);
    
    // 配置 Whisper 未啟用，但 VAD 啟用
    let config = TestConfigBuilder::new()
        .with_whisper_enabled(false)
        .with_vad_enabled(true)
        .build_config();
        
    let config_service = TestConfigService::new(config);
    let engine = SyncEngine::new(config_service.get_config().unwrap().sync, &config_service).await.unwrap();
    
    // 使用自動模式應該回退到 VAD
    let result = engine.detect_sync_offset(
        &audio_path,
        &subtitle,
        Some(SyncMethod::Auto),
    ).await.unwrap();
    
    assert_eq!(result.method_used, SyncMethod::LocalVad);
}

#[tokio::test]
async fn test_no_methods_available_error() {
    let config = TestConfigBuilder::new()
        .with_whisper_enabled(false)
        .with_vad_enabled(false)  // 兩種方法都禁用
        .build_config();
        
    let config_service = TestConfigService::new(config);
    let result = SyncEngine::new(config_service.get_config().unwrap().sync, &config_service).await;
    
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("No synchronization methods"));
}

// 輔助函式
fn create_test_subtitle_with_offset() -> Subtitle {
    Subtitle {
        entries: vec![
            SubtitleEntry::new(
                1,
                Duration::from_secs(30),
                Duration::from_secs(32),
                "Test dialogue".to_string(),
            ),
        ],
        metadata: SubtitleMetadata::default(),
        format: SubtitleFormatType::Srt,
    }
}

fn create_test_audio(path: &std::path::Path) {
    // 簡化的測試音訊建立
    use hound::{WavSpec, WavWriter, SampleFormat};
    
    let spec = WavSpec {
        channels: 1,
        sample_rate: 16000,
        bits_per_sample: 16,
        sample_format: SampleFormat::Int,
    };

    let mut writer = WavWriter::create(path, spec).unwrap();
    let duration_seconds = 60;
    let total_samples = 16000 * duration_seconds;

    for i in 0..total_samples {
        let t = i as f32 / 16000.0;
        
        // 在第 30 秒附近建立語音信號
        let sample = if t >= 29.5 && t <= 32.0 {
            (0.3 * (2.0 * std::f32::consts::PI * 440.0 * t).sin()) * 32767.0
        } else {
            0.0 // 靜音
        };
        
        writer.write_sample(sample as i16).unwrap();
    }
    
    writer.finalize().unwrap();
}
```

### 性能測試

**檔案**: `tests/sync_engine_performance_tests.rs`

```rust
use subx_cli::core::sync::{SyncEngine, SyncMethod};
use subx_cli::config::{TestConfigBuilder, TestConfigService};
use std::time::Instant;
use tempfile::TempDir;

#[tokio::test]
#[ignore] // 性能測試，平時不執行
async fn test_sync_engine_performance_comparison() {
    let temp_dir = TempDir::new().unwrap();
    let audio_path = temp_dir.path().join("large_test.wav");
    let subtitle = create_large_test_subtitle();
    
    // 建立較大的測試音訊檔案（5 分鐘）
    create_large_test_audio(&audio_path, 300);
    
    let config = TestConfigBuilder::new()
        .with_whisper_enabled(false) // 避免 API 呼叫
        .with_vad_enabled(true)
        .build_config();
        
    let config_service = TestConfigService::new(config);
    let engine = SyncEngine::new(config_service.get_config().unwrap().sync, &config_service).await.unwrap();
    
    // 測試 VAD 性能
    let start_time = Instant::now();
    let result = engine.detect_sync_offset(
        &audio_path,
        &subtitle,
        Some(SyncMethod::LocalVad),
    ).await.unwrap();
    let vad_duration = start_time.elapsed();
    
    println!("VAD processing time: {:?}", vad_duration);
    println!("VAD confidence: {:.2}%", result.confidence * 100.0);
    
    // 驗證性能要求
    assert!(vad_duration.as_secs() < 30, "VAD processing took too long");
    assert!(result.confidence > 0.0);
}

// 輔助函式省略...
```

## 完成標準

1. ✅ 新的 `SyncEngine` 正確整合 Whisper API 和本地 VAD
2. ✅ 自動方法選擇和回退機制正常運作
3. ✅ 手動偏移功能保持完整
4. ✅ 移除所有舊的包絡頻譜分析程式碼
5. ✅ 所有單元測試和整合測試通過
6. ✅ 錯誤處理和警告機制完整
7. ✅ 性能測試證實新引擎效率可接受
8. ✅ 向後兼容性適當處理（deprecation warnings）
9. ✅ 配置整合正常運作
10. ✅ 日誌記錄和調試資訊完整

## 風險評估

### 高風險
- **功能回歸**: 移除舊程式碼可能影響現有功能
  - *緩解*: 完整的測試覆蓋和逐步遷移

### 中風險
- **API 依賴**: Whisper API 可能不穩定
  - *緩解*: 實作本地 VAD 作為回退選項
- **性能影響**: 新方法可能比舊方法慢
  - *緩解*: 性能測試和最佳化

### 低風險
- **配置複雜性**: 新配置可能困惑用戶
  - *緩解*: 智能預設值和自動模式

## 使用範例

```rust
use subx_cli::core::sync::{SyncEngine, SyncMethod};
use subx_cli::config::{TestConfigBuilder, TestConfigService};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 建立配置
    let config = TestConfigBuilder::new()
        .with_whisper_enabled(true)
        .with_vad_enabled(true)
        .with_sync_method("auto")
        .build_config();
        
    let config_service = TestConfigService::new(config);
    
    // 建立同步引擎
    let engine = SyncEngine::new(
        config_service.get_config()?.sync,
        &config_service
    ).await?;

    // 載入字幕
    let subtitle = load_subtitle("subtitle.srt")?;

    // 自動同步檢測
    let result = engine.detect_sync_offset(
        Path::new("video.mp4"),
        &subtitle,
        Some(SyncMethod::Auto), // 或 None 使用預設方法
    ).await?;

    println!("Method: {:?}", result.method_used);
    println!("Offset: {:.2}s", result.offset_seconds);
    println!("Confidence: {:.1}%", result.confidence * 100.0);

    // 手動偏移
    let mut subtitle_copy = subtitle.clone();
    let manual_result = engine.apply_manual_offset(&mut subtitle_copy, 1.5)?;
    println!("Applied manual offset: {:.2}s", manual_result.offset_seconds);

    Ok(())
}
```

---

**預估工時**: 12 小時  
**依賴項目**: Backlog 32.1, 32.2, 32.3  
**後續項目**: Backlog 32.5 (CLI 參數更新)
