# Product Backlog #16.4: æª”æ¡ˆç·¨ç¢¼è‡ªå‹•æª¢æ¸¬å¯¦ä½œ

## é ˜åŸŸç¯„åœ
æª”æ¡ˆç·¨ç¢¼æª¢æ¸¬ã€å­—ç¬¦ç·¨ç¢¼è½‰æ›ã€æ–‡å­—è§£ææœ€ä½³åŒ–ã€å¤šèªè¨€æ”¯æ´

## èƒŒæ™¯æè¿°

**æ›´æ–°æ—¥æœŸ**: 2025-06-08  
**æ¶æ§‹ç‹€æ³**: åŸºæ–¼çµ±ä¸€é…ç½®ç®¡ç†ç³»çµ± (Backlog #14 å·²å®Œæˆ)  
**å‰ç½®æ¢ä»¶**: çµ±ä¸€é…ç½®ç®¡ç†ç³»çµ±ã€ç¾æœ‰æ ¼å¼å¼•æ“æ¶æ§‹

éš¨è‘— SubX åœ¨å…¨çƒç¯„åœå…§çš„ä½¿ç”¨å¢åŠ ï¼Œè™•ç†ä¸åŒå­—ç¬¦ç·¨ç¢¼çš„å­—å¹•æª”æ¡ˆæˆç‚ºé‡è¦éœ€æ±‚ã€‚ç›®å‰çš„æ ¼å¼å¼•æ“é›–ç„¶æ”¯æ´å¤šç¨®å­—å¹•æ ¼å¼ï¼Œä½†ç¼ºä¹è‡ªå‹•ç·¨ç¢¼æª¢æ¸¬åŠŸèƒ½ï¼Œå°è‡´ä½¿ç”¨è€…åœ¨è™•ç†é UTF-8 ç·¨ç¢¼çš„æª”æ¡ˆæ™‚ç¶“å¸¸é‡åˆ°äº‚ç¢¼å•é¡Œã€‚

å¯¦ä½œæª”æ¡ˆç·¨ç¢¼è‡ªå‹•æª¢æ¸¬ç³»çµ±å¯ä»¥é¡¯è‘—æå‡ä½¿ç”¨è€…é«”é©—ï¼Œè‡ªå‹•è™•ç†ä¸åŒåœ°å€å’Œèªè¨€çš„å­—å¹•æª”æ¡ˆï¼Œæ¸›å°‘æ‰‹å‹•é…ç½®çš„éœ€æ±‚ã€‚

## åŠŸèƒ½æ¦‚è¿°

### æª”æ¡ˆç·¨ç¢¼è‡ªå‹•æª¢æ¸¬ç³»çµ± (Automatic Encoding Detection)
**ç›¸é—œé…ç½®**: `formats.default_encoding`, `formats.encoding_detection_confidence`  
**ç›®æ¨™æ¨¡çµ„**: `src/core/formats/encoding/` (æ–°å¢ç›®éŒ„)

#### æ ¸å¿ƒåŠŸèƒ½æè¿°
- **è‡ªå‹•ç·¨ç¢¼æª¢æ¸¬**: æ™ºæ…§è­˜åˆ¥å­—å¹•æª”æ¡ˆçš„å­—ç¬¦ç·¨ç¢¼
- **å¤šç·¨ç¢¼æ”¯æ´**: æ”¯æ´å¸¸è¦‹çš„å­—ç¬¦ç·¨ç¢¼æ ¼å¼ (UTF-8, UTF-16, GBK, Shift-JIS ç­‰)
- **ç·¨ç¢¼è½‰æ›**: è‡ªå‹•å°‡æª”æ¡ˆè½‰æ›ç‚ºçµ±ä¸€çš„å…§éƒ¨ç·¨ç¢¼æ ¼å¼
- **éŒ¯èª¤ä¿®å¾©**: è™•ç†ç·¨ç¢¼éŒ¯èª¤å’Œæå£çš„å­—ç¬¦
- **çµ±ä¸€é…ç½®æ•´åˆ**: é€é `load_config()` è¼‰å…¥ç·¨ç¢¼è™•ç†åƒæ•¸

#### æŠ€è¡“éœ€æ±‚èˆ‡æŒ‘æˆ°
- **ç·¨ç¢¼æª¢æ¸¬æ¼”ç®—æ³•**: åŸºæ–¼å­—ç¯€æ¨¡å¼å’Œçµ±è¨ˆåˆ†æçš„æª¢æ¸¬æ–¹æ³•
- **å­—ç¬¦ç·¨ç¢¼è½‰æ›**: é«˜æ•ˆä¸”æº–ç¢ºçš„ç·¨ç¢¼è½‰æ›è™•ç†
- **éŒ¯èª¤è™•ç†**: å„ªé›…è™•ç†ç·¨ç¢¼éŒ¯èª¤å’Œä¸å®Œæ•´çš„å­—ç¬¦åºåˆ—
- **æ•ˆèƒ½æœ€ä½³åŒ–**: å¿«é€Ÿè™•ç†å¤§å‹å­—å¹•æª”æ¡ˆ

## è©³ç´°å¯¦ä½œè¨ˆåŠƒ

### éšæ®µ 1: ç·¨ç¢¼æª¢æ¸¬å¼•æ“å»ºç«‹ (é ä¼°å·¥æ™‚: 14 å°æ™‚)

#### 1.1 å»ºç«‹ç·¨ç¢¼æª¢æ¸¬ç³»çµ±æ¶æ§‹
```rust
// src/core/formats/encoding/mod.rs
pub mod detector;
pub mod converter;
pub mod analyzer;
pub mod charset;

pub use detector::EncodingDetector;
pub use converter::{EncodingConverter, ConversionResult};
pub use analyzer::{ByteAnalyzer, StatisticalAnalyzer};
pub use charset::{Charset, EncodingInfo};
```

**æ¶æ§‹è¨­è¨ˆé‡é»**:
- **æ¨¡çµ„åŒ–è¨­è¨ˆ**: åˆ†é›¢æª¢æ¸¬ã€è½‰æ›å’Œåˆ†æåŠŸèƒ½
- **å¯æ“´å±•æ€§**: æ”¯æ´æ–°å¢æ›´å¤šç·¨ç¢¼æ ¼å¼
- **çµ±ä¸€ä»‹é¢**: ç‚ºæ ¼å¼å¼•æ“æä¾›ä¸€è‡´çš„ç·¨ç¢¼è™•ç†ä»‹é¢

#### 1.2 å¯¦ä½œç·¨ç¢¼æª¢æ¸¬å™¨æ ¸å¿ƒ
```rust
// src/core/formats/encoding/detector.rs
use std::collections::HashMap;
use std::fs::File;
use std::io::{BufReader, Read};
use crate::config::load_config;
use crate::Result;

#[derive(Debug, Clone, PartialEq)]
pub enum Charset {
    Utf8,
    Utf16Le,
    Utf16Be,
    Utf32Le,
    Utf32Be,
    Gbk,
    ShiftJis,
    Iso88591,
    Windows1252,
    Big5,
    Euckr,
    Unknown,
}

#[derive(Debug, Clone)]
pub struct EncodingInfo {
    pub charset: Charset,
    pub confidence: f32,        // æª¢æ¸¬ä¿¡å¿ƒåº¦ (0.0-1.0)
    pub bom_detected: bool,     // æ˜¯å¦æª¢æ¸¬åˆ° BOM
    pub sample_text: String,    // è§£ç¢¼å¾Œçš„æ¨£æœ¬æ–‡å­—
}

pub struct EncodingDetector {
    confidence_threshold: f32,
    max_sample_size: usize,
    supported_charsets: Vec<Charset>,
}

impl EncodingDetector {
    pub fn new() -> Result<Self> {
        let config = load_config()?;
        Ok(Self {
            confidence_threshold: config.formats.encoding_detection_confidence,
            max_sample_size: 8192, // 8KB æ¨£æœ¬
            supported_charsets: Self::default_charsets(),
        })
    }

    pub fn detect_file_encoding(&self, file_path: &str) -> Result<EncodingInfo> {
        let mut file = File::open(file_path)?;
        let mut buffer = vec![0; self.max_sample_size];
        let bytes_read = file.read(&mut buffer)?;
        buffer.truncate(bytes_read);
        
        self.detect_encoding(&buffer)
    }

    pub fn detect_encoding(&self, data: &[u8]) -> Result<EncodingInfo> {
        // 1. æª¢æŸ¥ BOM (Byte Order Mark)
        if let Some(encoding) = self.detect_bom(data) {
            return Ok(encoding);
        }

        // 2. çµ±è¨ˆåˆ†ææª¢æ¸¬
        let candidates = self.analyze_byte_patterns(data)?;
        
        // 3. é¸æ“‡æœ€ä½³å€™é¸
        self.select_best_encoding(candidates, data)
    }

    fn detect_bom(&self, data: &[u8]) -> Option<EncodingInfo> {
        if data.len() < 3 {
            return None;
        }

        match &data[0..3] {
            [0xEF, 0xBB, 0xBF] => Some(EncodingInfo {
                charset: Charset::Utf8,
                confidence: 1.0,
                bom_detected: true,
                sample_text: String::from("UTF-8 with BOM"),
            }),
            [0xFF, 0xFE, ..] => Some(EncodingInfo {
                charset: Charset::Utf16Le,
                confidence: 1.0,
                bom_detected: true,
                sample_text: String::from("UTF-16 LE with BOM"),
            }),
            [0xFE, 0xFF, ..] => Some(EncodingInfo {
                charset: Charset::Utf16Be,
                confidence: 1.0,
                bom_detected: true,
                sample_text: String::from("UTF-16 BE with BOM"),
            }),
            _ => {
                // æª¢æŸ¥ UTF-32 BOM
                if data.len() >= 4 {
                    match &data[0..4] {
                        [0xFF, 0xFE, 0x00, 0x00] => Some(EncodingInfo {
                            charset: Charset::Utf32Le,
                            confidence: 1.0,
                            bom_detected: true,
                            sample_text: String::from("UTF-32 LE with BOM"),
                        }),
                        [0x00, 0x00, 0xFE, 0xFF] => Some(EncodingInfo {
                            charset: Charset::Utf32Be,
                            confidence: 1.0,
                            bom_detected: true,
                            sample_text: String::from("UTF-32 BE with BOM"),
                        }),
                        _ => None,
                    }
                } else {
                    None
                }
            }
        }
    }

    fn analyze_byte_patterns(&self, data: &[u8]) -> Result<Vec<EncodingCandidate>> {
        let mut candidates = Vec::new();

        for charset in &self.supported_charsets {
            let confidence = self.calculate_encoding_confidence(data, charset)?;
            if confidence > 0.1 { // åªä¿ç•™æœ‰ä¸€å®šä¿¡å¿ƒåº¦çš„å€™é¸
                candidates.push(EncodingCandidate {
                    charset: charset.clone(),
                    confidence,
                });
            }
        }

        // æŒ‰ä¿¡å¿ƒåº¦æ’åº
        candidates.sort_by(|a, b| b.confidence.partial_cmp(&a.confidence).unwrap());
        Ok(candidates)
    }

    fn calculate_encoding_confidence(&self, data: &[u8], charset: &Charset) -> Result<f32> {
        match charset {
            Charset::Utf8 => self.check_utf8_validity(data),
            Charset::Gbk => self.check_gbk_patterns(data),
            Charset::ShiftJis => self.check_shift_jis_patterns(data),
            Charset::Big5 => self.check_big5_patterns(data),
            Charset::Iso88591 => self.check_iso88591_patterns(data),
            Charset::Windows1252 => self.check_windows1252_patterns(data),
            _ => Ok(0.0),
        }
    }

    fn check_utf8_validity(&self, data: &[u8]) -> Result<f32> {
        let mut valid_chars = 0;
        let mut total_chars = 0;
        let mut i = 0;

        while i < data.len() {
            total_chars += 1;
            
            if data[i] & 0x80 == 0 {
                // ASCII å­—ç¬¦
                valid_chars += 1;
                i += 1;
            } else if data[i] & 0xE0 == 0xC0 {
                // 2 å­—ç¯€ UTF-8
                if i + 1 < data.len() && data[i + 1] & 0xC0 == 0x80 {
                    valid_chars += 1;
                }
                i += 2;
            } else if data[i] & 0xF0 == 0xE0 {
                // 3 å­—ç¯€ UTF-8
                if i + 2 < data.len() 
                    && data[i + 1] & 0xC0 == 0x80 
                    && data[i + 2] & 0xC0 == 0x80 {
                    valid_chars += 1;
                }
                i += 3;
            } else if data[i] & 0xF8 == 0xF0 {
                // 4 å­—ç¯€ UTF-8
                if i + 3 < data.len() 
                    && data[i + 1] & 0xC0 == 0x80 
                    && data[i + 2] & 0xC0 == 0x80 
                    && data[i + 3] & 0xC0 == 0x80 {
                    valid_chars += 1;
                }
                i += 4;
            } else {
                i += 1;
            }
        }

        Ok(if total_chars > 0 {
            valid_chars as f32 / total_chars as f32
        } else {
            0.0
        })
    }

    fn check_gbk_patterns(&self, data: &[u8]) -> Result<f32> {
        let mut valid_chars = 0;
        let mut total_chars = 0;
        let mut i = 0;

        while i < data.len() {
            if data[i] < 0x80 {
                // ASCII å­—ç¬¦
                valid_chars += 1;
                total_chars += 1;
                i += 1;
            } else if i + 1 < data.len() {
                let byte1 = data[i];
                let byte2 = data[i + 1];
                
                // GBK é«˜å­—ç¯€ç¯„åœ: 0x81-0xFE, ä½å­—ç¯€ç¯„åœ: 0x40-0xFE (æ’é™¤ 0x7F)
                if (0x81..=0xFE).contains(&byte1) 
                    && ((0x40..=0x7E).contains(&byte2) || (0x80..=0xFE).contains(&byte2)) {
                    valid_chars += 1;
                }
                total_chars += 1;
                i += 2;
            } else {
                total_chars += 1;
                i += 1;
            }
        }

        Ok(if total_chars > 0 {
            valid_chars as f32 / total_chars as f32
        } else {
            0.0
        })
    }

    fn check_shift_jis_patterns(&self, data: &[u8]) -> Result<f32> {
        let mut valid_chars = 0;
        let mut total_chars = 0;
        let mut i = 0;

        while i < data.len() {
            if data[i] < 0x80 {
                // ASCII å­—ç¬¦
                valid_chars += 1;
                total_chars += 1;
                i += 1;
            } else if i + 1 < data.len() {
                let byte1 = data[i];
                let byte2 = data[i + 1];
                
                // Shift-JIS é«˜å­—ç¯€ç¯„åœ
                if ((0x81..=0x9F).contains(&byte1) || (0xE0..=0xEF).contains(&byte1))
                    && (0x40..=0xFC).contains(&byte2) && byte2 != 0x7F {
                    valid_chars += 1;
                }
                total_chars += 1;
                i += 2;
            } else {
                total_chars += 1;
                i += 1;
            }
        }

        Ok(if total_chars > 0 {
            valid_chars as f32 / total_chars as f32
        } else {
            0.0
        })
    }

    fn check_big5_patterns(&self, data: &[u8]) -> Result<f32> {
        let mut valid_chars = 0;
        let mut total_chars = 0;
        let mut i = 0;

        while i < data.len() {
            if data[i] < 0x80 {
                // ASCII å­—ç¬¦
                valid_chars += 1;
                total_chars += 1;
                i += 1;
            } else if i + 1 < data.len() {
                let byte1 = data[i];
                let byte2 = data[i + 1];
                
                // Big5 é«˜å­—ç¯€ç¯„åœ: 0xA1-0xFE, ä½å­—ç¯€ç¯„åœ: 0x40-0x7E, 0xA1-0xFE
                if (0xA1..=0xFE).contains(&byte1) 
                    && ((0x40..=0x7E).contains(&byte2) || (0xA1..=0xFE).contains(&byte2)) {
                    valid_chars += 1;
                }
                total_chars += 1;
                i += 2;
            } else {
                total_chars += 1;
                i += 1;
            }
        }

        Ok(if total_chars > 0 {
            valid_chars as f32 / total_chars as f32
        } else {
            0.0
        })
    }

    fn check_iso88591_patterns(&self, data: &[u8]) -> Result<f32> {
        // ISO-8859-1 æ‰€æœ‰å­—ç¯€éƒ½æ˜¯æœ‰æ•ˆçš„ï¼Œæ‰€ä»¥éœ€è¦åŸºæ–¼å…§å®¹ç‰¹å¾µåˆ¤æ–·
        let ascii_count = data.iter().filter(|&&b| b < 0x80).count();
        let extended_count = data.iter().filter(|&&b| b >= 0x80).count();
        
        // å¦‚æœæœ‰æ“´å±•å­—ç¬¦ä¸”æ²’æœ‰ç„¡æ•ˆçš„ UTF-8 åºåˆ—ï¼Œå¯èƒ½æ˜¯ ISO-8859-1
        if extended_count > 0 {
            let utf8_confidence = self.check_utf8_validity(data)?;
            Ok(if utf8_confidence < 0.5 { 0.7 } else { 0.2 })
        } else {
            Ok(0.5) // ç´” ASCII ä¹Ÿç¬¦åˆ ISO-8859-1
        }
    }

    fn check_windows1252_patterns(&self, data: &[u8]) -> Result<f32> {
        // Windows-1252 åœ¨ 0x80-0x9F ç¯„åœæœ‰ç‰¹å®šå­—ç¬¦
        let control_chars = data.iter()
            .filter(|&&b| (0x80..=0x9F).contains(&b))
            .count();
        
        let extended_chars = data.iter()
            .filter(|&&b| b >= 0xA0)
            .count();

        if control_chars > 0 || extended_chars > 0 {
            let utf8_confidence = self.check_utf8_validity(data)?;
            Ok(if utf8_confidence < 0.5 { 0.6 } else { 0.1 })
        } else {
            Ok(0.3) // å¯èƒ½æ˜¯ Windows-1252
        }
    }

    fn select_best_encoding(
        &self,
        candidates: Vec<EncodingCandidate>,
        data: &[u8],
    ) -> Result<EncodingInfo> {
        if candidates.is_empty() {
            return Ok(EncodingInfo {
                charset: Charset::Unknown,
                confidence: 0.0,
                bom_detected: false,
                sample_text: String::from("Unable to detect encoding"),
            });
        }

        let best_candidate = &candidates[0];
        
        // å¦‚æœä¿¡å¿ƒåº¦ä½æ–¼é–¾å€¼ï¼Œä½¿ç”¨é è¨­ç·¨ç¢¼
        if best_candidate.confidence < self.confidence_threshold {
            let config = load_config()?;
            let default_charset = self.parse_charset(&config.formats.default_encoding)?;
            return Ok(EncodingInfo {
                charset: default_charset,
                confidence: 0.5,
                bom_detected: false,
                sample_text: format!("Using default encoding: {}", config.formats.default_encoding),
            });
        }

        // å˜—è©¦è§£ç¢¼æ¨£æœ¬æ–‡å­—
        let sample_text = self.decode_sample(data, &best_candidate.charset)?;

        Ok(EncodingInfo {
            charset: best_candidate.charset.clone(),
            confidence: best_candidate.confidence,
            bom_detected: false,
            sample_text,
        })
    }

    fn decode_sample(&self, data: &[u8], charset: &Charset) -> Result<String> {
        let sample_size = std::cmp::min(data.len(), 200); // å–å‰ 200 å­—ç¯€ä½œç‚ºæ¨£æœ¬
        let sample_data = &data[0..sample_size];

        match charset {
            Charset::Utf8 => {
                String::from_utf8(sample_data.to_vec())
                    .or_else(|_| String::from_utf8_lossy(sample_data).into_owned().into())
            }
            Charset::Gbk => {
                // é€™è£¡éœ€è¦å¯¦ä½œ GBK è§£ç¢¼ï¼Œæš«æ™‚ä½¿ç”¨ UTF-8 lossy
                Ok(String::from_utf8_lossy(sample_data).into_owned())
            }
            Charset::ShiftJis => {
                // é€™è£¡éœ€è¦å¯¦ä½œ Shift-JIS è§£ç¢¼ï¼Œæš«æ™‚ä½¿ç”¨ UTF-8 lossy
                Ok(String::from_utf8_lossy(sample_data).into_owned())
            }
            _ => Ok(String::from_utf8_lossy(sample_data).into_owned()),
        }
    }

    fn parse_charset(&self, encoding_name: &str) -> Result<Charset> {
        match encoding_name.to_lowercase().as_str() {
            "utf-8" | "utf8" => Ok(Charset::Utf8),
            "utf-16le" | "utf16le" => Ok(Charset::Utf16Le),
            "utf-16be" | "utf16be" => Ok(Charset::Utf16Be),
            "gbk" => Ok(Charset::Gbk),
            "shift-jis" | "shift_jis" | "sjis" => Ok(Charset::ShiftJis),
            "big5" => Ok(Charset::Big5),
            "iso-8859-1" | "iso88591" => Ok(Charset::Iso88591),
            "windows-1252" | "cp1252" => Ok(Charset::Windows1252),
            _ => Ok(Charset::Utf8), // é è¨­ç‚º UTF-8
        }
    }

    fn default_charsets() -> Vec<Charset> {
        vec![
            Charset::Utf8,
            Charset::Gbk,
            Charset::ShiftJis,
            Charset::Big5,
            Charset::Iso88591,
            Charset::Windows1252,
        ]
    }
}

#[derive(Debug, Clone)]
struct EncodingCandidate {
    charset: Charset,
    confidence: f32,
}

impl Default for EncodingDetector {
    fn default() -> Self {
        Self::new().unwrap_or_else(|_| Self {
            confidence_threshold: 0.7,
            max_sample_size: 8192,
            supported_charsets: Self::default_charsets(),
        })
    }
}
```

#### 1.3 å¯¦ä½œç·¨ç¢¼è½‰æ›å™¨
```rust
// src/core/formats/encoding/converter.rs
use std::collections::HashMap;
use encoding_rs::{Encoding, UTF_8, GBK, SHIFT_JIS, BIG5, WINDOWS_1252, ISO_8859_2};
use crate::core::formats::encoding::{Charset, EncodingInfo};
use crate::Result;

#[derive(Debug, Clone)]
pub struct ConversionResult {
    pub converted_text: String,
    pub original_encoding: Charset,
    pub target_encoding: Charset,
    pub bytes_processed: usize,
    pub had_errors: bool,
    pub error_count: usize,
}

pub struct EncodingConverter {
    encoding_map: HashMap<Charset, &'static Encoding>,
}

impl EncodingConverter {
    pub fn new() -> Self {
        let mut encoding_map = HashMap::new();
        encoding_map.insert(Charset::Utf8, UTF_8);
        encoding_map.insert(Charset::Gbk, GBK);
        encoding_map.insert(Charset::ShiftJis, SHIFT_JIS);
        encoding_map.insert(Charset::Big5, BIG5);
        encoding_map.insert(Charset::Windows1252, WINDOWS_1252);
        encoding_map.insert(Charset::Iso88591, ISO_8859_2); // è¿‘ä¼¼æ›¿ä»£

        Self { encoding_map }
    }

    pub fn convert_to_utf8(
        &self,
        data: &[u8],
        source_encoding: &Charset,
    ) -> Result<ConversionResult> {
        if *source_encoding == Charset::Utf8 {
            // å·²ç¶“æ˜¯ UTF-8ï¼Œç›´æ¥è¿”å›
            return Ok(ConversionResult {
                converted_text: String::from_utf8_lossy(data).into_owned(),
                original_encoding: Charset::Utf8,
                target_encoding: Charset::Utf8,
                bytes_processed: data.len(),
                had_errors: false,
                error_count: 0,
            });
        }

        let encoding = self.encoding_map.get(source_encoding)
            .ok_or_else(|| crate::SubXError::EncodingError(
                format!("Unsupported encoding: {:?}", source_encoding)
            ))?;

        let (converted_text, _, had_errors) = encoding.decode(data);
        
        // çµ±è¨ˆéŒ¯èª¤æ•¸é‡
        let error_count = if had_errors {
            self.count_replacement_chars(&converted_text)
        } else {
            0
        };

        Ok(ConversionResult {
            converted_text: converted_text.into_owned(),
            original_encoding: source_encoding.clone(),
            target_encoding: Charset::Utf8,
            bytes_processed: data.len(),
            had_errors,
            error_count,
        })
    }

    pub fn convert_file_to_utf8(
        &self,
        file_path: &str,
        encoding_info: &EncodingInfo,
    ) -> Result<ConversionResult> {
        use std::fs;
        let data = fs::read(file_path)?;
        
        // å¦‚æœæª¢æ¸¬åˆ° BOMï¼Œè·³é BOM å­—ç¯€
        let data_without_bom = if encoding_info.bom_detected {
            self.skip_bom(&data, &encoding_info.charset)
        } else {
            data.as_slice()
        };

        self.convert_to_utf8(data_without_bom, &encoding_info.charset)
    }

    fn skip_bom(&self, data: &[u8], charset: &Charset) -> &[u8] {
        match charset {
            Charset::Utf8 if data.len() >= 3 && &data[0..3] == [0xEF, 0xBB, 0xBF] => &data[3..],
            Charset::Utf16Le if data.len() >= 2 && &data[0..2] == [0xFF, 0xFE] => &data[2..],
            Charset::Utf16Be if data.len() >= 2 && &data[0..2] == [0xFE, 0xFF] => &data[2..],
            Charset::Utf32Le if data.len() >= 4 && &data[0..4] == [0xFF, 0xFE, 0x00, 0x00] => &data[4..],
            Charset::Utf32Be if data.len() >= 4 && &data[0..4] == [0x00, 0x00, 0xFE, 0xFF] => &data[4..],
            _ => data,
        }
    }

    fn count_replacement_chars(&self, text: &str) -> usize {
        text.chars().filter(|&c| c == '\u{FFFD}').count()
    }

    pub fn validate_conversion(&self, result: &ConversionResult) -> ValidationResult {
        ValidationResult {
            is_valid: !result.had_errors || result.error_count == 0,
            confidence: if result.had_errors {
                1.0 - (result.error_count as f32 / result.converted_text.len() as f32)
            } else {
                1.0
            },
            warnings: self.generate_warnings(result),
        }
    }

    fn generate_warnings(&self, result: &ConversionResult) -> Vec<String> {
        let mut warnings = Vec::new();

        if result.had_errors {
            warnings.push(format!(
                "Encoding conversion had {} replacement characters",
                result.error_count
            ));
        }

        if result.error_count > result.bytes_processed / 10 {
            warnings.push("High error rate detected - encoding may be incorrect".to_string());
        }

        warnings
    }
}

#[derive(Debug, Clone)]
pub struct ValidationResult {
    pub is_valid: bool,
    pub confidence: f32,
    pub warnings: Vec<String>,
}

impl Default for EncodingConverter {
    fn default() -> Self {
        Self::new()
    }
}
```

### éšæ®µ 2: çµ±è¨ˆåˆ†æå™¨å¯¦ä½œ (é ä¼°å·¥æ™‚: 8 å°æ™‚)

#### 2.1 å¯¦ä½œå­—ç¯€æ¨¡å¼åˆ†æå™¨
```rust
// src/core/formats/encoding/analyzer.rs
use std::collections::HashMap;
use crate::core::formats::encoding::Charset;
use crate::Result;

pub struct ByteAnalyzer {
    byte_frequency: HashMap<u8, usize>,
    bigram_frequency: HashMap<(u8, u8), usize>,
    total_bytes: usize,
}

impl ByteAnalyzer {
    pub fn new() -> Self {
        Self {
            byte_frequency: HashMap::new(),
            bigram_frequency: HashMap::new(),
            total_bytes: 0,
        }
    }

    pub fn analyze(&mut self, data: &[u8]) -> Result<AnalysisResult> {
        self.collect_statistics(data);
        self.calculate_metrics()
    }

    fn collect_statistics(&mut self, data: &[u8]) {
        self.total_bytes = data.len();

        // æ”¶é›†å–®å­—ç¯€é »ç‡
        for &byte in data {
            *self.byte_frequency.entry(byte).or_insert(0) += 1;
        }

        // æ”¶é›†é›™å­—ç¯€é »ç‡
        for window in data.windows(2) {
            if let [b1, b2] = window {
                *self.bigram_frequency.entry((*b1, *b2)).or_insert(0) += 1;
            }
        }
    }

    fn calculate_metrics(&self) -> Result<AnalysisResult> {
        let ascii_ratio = self.calculate_ascii_ratio();
        let entropy = self.calculate_entropy();
        let control_char_ratio = self.calculate_control_char_ratio();

        Ok(AnalysisResult {
            ascii_ratio,
            entropy,
            control_char_ratio,
            byte_distribution: self.byte_frequency.clone(),
            likely_encodings: self.suggest_encodings(ascii_ratio, entropy, control_char_ratio),
        })
    }

    fn calculate_ascii_ratio(&self) -> f32 {
        let ascii_count = self.byte_frequency.iter()
            .filter(|(&byte, _)| byte < 0x80)
            .map(|(_, &count)| count)
            .sum::<usize>();

        if self.total_bytes > 0 {
            ascii_count as f32 / self.total_bytes as f32
        } else {
            0.0
        }
    }

    fn calculate_entropy(&self) -> f32 {
        let mut entropy = 0.0;
        for &count in self.byte_frequency.values() {
            if count > 0 {
                let probability = count as f32 / self.total_bytes as f32;
                entropy -= probability * probability.log2();
            }
        }
        entropy
    }

    fn calculate_control_char_ratio(&self) -> f32 {
        let control_count = self.byte_frequency.iter()
            .filter(|(&byte, _)| byte < 0x20 && byte != 0x09 && byte != 0x0A && byte != 0x0D)
            .map(|(_, &count)| count)
            .sum::<usize>();

        if self.total_bytes > 0 {
            control_count as f32 / self.total_bytes as f32
        } else {
            0.0
        }
    }

    fn suggest_encodings(&self, ascii_ratio: f32, entropy: f32, control_ratio: f32) -> Vec<Charset> {
        let mut suggestions = Vec::new();

        // åŸºæ–¼çµ±è¨ˆç‰¹å¾µå»ºè­°ç·¨ç¢¼
        if ascii_ratio > 0.9 {
            suggestions.push(Charset::Utf8);
        }

        if entropy > 6.0 && ascii_ratio < 0.8 {
            suggestions.extend_from_slice(&[Charset::Gbk, Charset::Big5, Charset::ShiftJis]);
        }

        if control_ratio > 0.01 {
            suggestions.push(Charset::Windows1252);
        }

        if suggestions.is_empty() {
            suggestions.push(Charset::Utf8); // é è¨­å»ºè­°
        }

        suggestions
    }
}

#[derive(Debug, Clone)]
pub struct AnalysisResult {
    pub ascii_ratio: f32,
    pub entropy: f32,
    pub control_char_ratio: f32,
    pub byte_distribution: HashMap<u8, usize>,
    pub likely_encodings: Vec<Charset>,
}

pub struct StatisticalAnalyzer {
    language_models: HashMap<Charset, LanguageModel>,
}

impl StatisticalAnalyzer {
    pub fn new() -> Self {
        Self {
            language_models: Self::build_language_models(),
        }
    }

    fn build_language_models() -> HashMap<Charset, LanguageModel> {
        let mut models = HashMap::new();

        // UTF-8 èªè¨€æ¨¡å‹ï¼ˆåŸºæ–¼å¸¸è¦‹å­—ç¬¦é »ç‡ï¼‰
        models.insert(Charset::Utf8, LanguageModel {
            charset: Charset::Utf8,
            common_patterns: vec![
                // å¸¸è¦‹ UTF-8 å¤šå­—ç¯€åºåˆ—é–‹å§‹å­—ç¯€
                (0xC2, 0.05), (0xC3, 0.08), (0xE2, 0.12),
                (0xE3, 0.15), (0xE4, 0.18), (0xE5, 0.20),
            ],
            invalid_patterns: vec![
                // ç„¡æ•ˆçš„ UTF-8 çºŒæ¥å­—ç¯€
                (0x80, 0.0), (0xBF, 0.0),
            ],
        });

        // GBK èªè¨€æ¨¡å‹
        models.insert(Charset::Gbk, LanguageModel {
            charset: Charset::Gbk,
            common_patterns: vec![
                // å¸¸è¦‹ GBK é«˜å­—ç¯€
                (0xB0, 0.15), (0xC4, 0.12), (0xD6, 0.10),
                (0xB8, 0.08), (0xBF, 0.06), (0xCE, 0.05),
            ],
            invalid_patterns: vec![
                (0x7F, 0.0), // GBK ä¸ä½¿ç”¨ 0x7F
            ],
        });

        models
    }

    pub fn analyze_with_models(&self, data: &[u8]) -> Result<HashMap<Charset, f32>> {
        let mut scores = HashMap::new();

        for (charset, model) in &self.language_models {
            let score = self.calculate_model_score(data, model)?;
            scores.insert(charset.clone(), score);
        }

        Ok(scores)
    }

    fn calculate_model_score(&self, data: &[u8], model: &LanguageModel) -> Result<f32> {
        let mut score = 0.0;
        let mut pattern_matches = 0;

        for &byte in data {
            // æª¢æŸ¥å¸¸è¦‹æ¨¡å¼
            for &(pattern_byte, weight) in &model.common_patterns {
                if byte == pattern_byte {
                    score += weight;
                    pattern_matches += 1;
                }
            }

            // æª¢æŸ¥ç„¡æ•ˆæ¨¡å¼ï¼ˆé™ä½åˆ†æ•¸ï¼‰
            for &(invalid_byte, penalty) in &model.invalid_patterns {
                if byte == invalid_byte {
                    score -= 0.1; // æ‡²ç½°ç„¡æ•ˆæ¨¡å¼
                }
            }
        }

        // æ­£è¦åŒ–åˆ†æ•¸
        Ok(if data.len() > 0 {
            score / data.len() as f32
        } else {
            0.0
        })
    }
}

#[derive(Debug, Clone)]
struct LanguageModel {
    charset: Charset,
    common_patterns: Vec<(u8, f32)>, // (å­—ç¯€, æ¬Šé‡)
    invalid_patterns: Vec<(u8, f32)>, // (å­—ç¯€, æ‡²ç½°)
}

impl Default for ByteAnalyzer {
    fn default() -> Self {
        Self::new()
    }
}

impl Default for StatisticalAnalyzer {
    fn default() -> Self {
        Self::new()
    }
}
```

### éšæ®µ 3: æ ¼å¼å¼•æ“æ•´åˆ (é ä¼°å·¥æ™‚: 6 å°æ™‚)

#### 3.1 æ›´æ–°æ ¼å¼ç®¡ç†å™¨ä»¥æ”¯æ´ç·¨ç¢¼æª¢æ¸¬
```rust
// src/core/formats/mod.rs ä¸­çš„æ“´å±•
use crate::core::formats::encoding::{EncodingDetector, EncodingConverter, EncodingInfo};

impl FormatManager {
    // ...existing code...

    pub fn read_subtitle_with_encoding_detection(&self, file_path: &str) -> Result<String> {
        // 1. æª¢æ¸¬æª”æ¡ˆç·¨ç¢¼
        let detector = EncodingDetector::new()?;
        let encoding_info = detector.detect_file_encoding(file_path)?;

        // 2. è½‰æ›ç‚º UTF-8
        let converter = EncodingConverter::new();
        let conversion_result = converter.convert_file_to_utf8(file_path, &encoding_info)?;

        // 3. é©—è­‰è½‰æ›çµæœ
        let validation = converter.validate_conversion(&conversion_result);
        if !validation.is_valid {
            tracing::warn!(
                "Encoding conversion had issues: {:?}",
                validation.warnings
            );
        }

        // 4. è¨˜éŒ„ç·¨ç¢¼æª¢æ¸¬çµæœ
        tracing::info!(
            "Detected encoding: {:?} (confidence: {:.2})",
            encoding_info.charset,
            encoding_info.confidence
        );

        Ok(conversion_result.converted_text)
    }

    pub fn get_encoding_info(&self, file_path: &str) -> Result<EncodingInfo> {
        let detector = EncodingDetector::new()?;
        detector.detect_file_encoding(file_path)
    }
}
```

#### 3.2 å¯¦ä½œç·¨ç¢¼æª¢æ¸¬ CLI å‘½ä»¤
```rust
// src/commands/detect_encoding_command.rs (æ–°å¢æª”æ¡ˆ)
use std::path::Path;
use crate::core::formats::encoding::EncodingDetector;
use crate::cli::ui::print_table;
use crate::Result;

pub fn detect_encoding_command(file_paths: &[String], verbose: bool) -> Result<()> {
    let detector = EncodingDetector::new()?;
    let mut results = Vec::new();

    for file_path in file_paths {
        if !Path::new(file_path).exists() {
            tracing::error!("File not found: {}", file_path);
            continue;
        }

        match detector.detect_file_encoding(file_path) {
            Ok(encoding_info) => {
                results.push((file_path.clone(), encoding_info));
            }
            Err(e) => {
                tracing::error!("Failed to detect encoding for {}: {}", file_path, e);
            }
        }
    }

    // é¡¯ç¤ºçµæœ
    display_encoding_results(&results, verbose)?;

    Ok(())
}

fn display_encoding_results(
    results: &[(String, crate::core::formats::encoding::EncodingInfo)],
    verbose: bool,
) -> Result<()> {
    use crate::cli::table::Table;

    let mut table = Table::new();
    table.set_header(vec!["æª”æ¡ˆ", "ç·¨ç¢¼", "ä¿¡å¿ƒåº¦", "BOM", "æ¨£æœ¬æ–‡å­—"]);

    for (file_path, encoding_info) in results {
        let file_name = Path::new(file_path)
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or(file_path);

        let confidence_str = format!("{:.1}%", encoding_info.confidence * 100.0);
        let bom_str = if encoding_info.bom_detected { "æ˜¯" } else { "å¦" };
        
        let sample_text = if verbose {
            &encoding_info.sample_text
        } else {
            // æˆªæ–·æ¨£æœ¬æ–‡å­—
            let truncated = if encoding_info.sample_text.len() > 50 {
                format!("{}...", &encoding_info.sample_text[..47])
            } else {
                encoding_info.sample_text.clone()
            };
            &truncated
        };

        table.add_row(vec![
            file_name.to_string(),
            format!("{:?}", encoding_info.charset),
            confidence_str,
            bom_str.to_string(),
            sample_text.to_string(),
        ]);
    }

    print_table(&table);
    Ok(())
}
```

### éšæ®µ 4: æ¸¬è©¦å’Œé©—è­‰ (é ä¼°å·¥æ™‚: 8 å°æ™‚)

#### 4.1 å–®å…ƒæ¸¬è©¦å¯¦ä½œ
```rust
// src/core/formats/encoding/tests.rs
#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::tempdir;

    #[test]
    fn test_utf8_detection() {
        let detector = EncodingDetector::new().unwrap();
        let utf8_text = "Hello, ä¸–ç•Œ! ğŸŒ";
        let result = detector.detect_encoding(utf8_text.as_bytes()).unwrap();
        
        assert_eq!(result.charset, Charset::Utf8);
        assert!(result.confidence > 0.8);
    }

    #[test]
    fn test_utf8_with_bom_detection() {
        let detector = EncodingDetector::new().unwrap();
        let mut data = vec![0xEF, 0xBB, 0xBF]; // UTF-8 BOM
        data.extend_from_slice("Hello, World!".as_bytes());
        
        let result = detector.detect_encoding(&data).unwrap();
        
        assert_eq!(result.charset, Charset::Utf8);
        assert_eq!(result.confidence, 1.0);
        assert!(result.bom_detected);
    }

    #[test]
    fn test_gbk_pattern_detection() {
        let detector = EncodingDetector::new().unwrap();
        // æ¨¡æ“¬ GBK ç·¨ç¢¼çš„å­—ç¯€åºåˆ—
        let gbk_data = vec![
            0xC4, 0xE3, 0xBA, 0xC3, // "ä½ å¥½" çš„ GBK ç·¨ç¢¼
            0xA3, 0xA1, 0xCA, 0xC0, // æ›´å¤š GBK å­—ç¬¦
        ];
        
        let result = detector.detect_encoding(&gbk_data).unwrap();
        
        // æ‡‰è©²æª¢æ¸¬ç‚º GBK æˆ–è€…è‡³å°‘ä¸æ˜¯ UTF-8
        assert_ne!(result.charset, Charset::Utf8);
    }

    #[test]
    fn test_encoding_conversion() {
        let converter = EncodingConverter::new();
        let utf8_text = "æ¸¬è©¦æ–‡å­—";
        
        let result = converter.convert_to_utf8(
            utf8_text.as_bytes(),
            &Charset::Utf8,
        ).unwrap();
        
        assert_eq!(result.converted_text, utf8_text);
        assert!(!result.had_errors);
        assert_eq!(result.error_count, 0);
    }

    #[test]
    fn test_file_encoding_detection() {
        let detector = EncodingDetector::new().unwrap();
        let temp_dir = tempdir().unwrap();
        let file_path = temp_dir.path().join("test.txt");
        
        // å»ºç«‹æ¸¬è©¦æª”æ¡ˆ
        fs::write(&file_path, "Hello, ä¸–ç•Œ!").unwrap();
        
        let result = detector.detect_file_encoding(
            file_path.to_str().unwrap()
        ).unwrap();
        
        assert_eq!(result.charset, Charset::Utf8);
    }

    #[test]
    fn test_byte_analyzer() {
        let mut analyzer = ByteAnalyzer::new();
        let test_data = "Hello, World! 123".as_bytes();
        
        let result = analyzer.analyze(test_data).unwrap();
        
        assert!(result.ascii_ratio > 0.9);
        assert!(result.entropy > 0.0);
        assert!(result.control_char_ratio < 0.1);
    }

    #[test]
    fn test_unknown_encoding_fallback() {
        let detector = EncodingDetector::new().unwrap();
        let random_data: Vec<u8> = (0..100).map(|i| (i * 7) as u8).collect();
        
        let result = detector.detect_encoding(&random_data).unwrap();
        
        // æ‡‰è©²å›é€€åˆ°é è¨­ç·¨ç¢¼æˆ–æ¨™è¨˜ç‚ºæœªçŸ¥
        assert!(result.confidence < 0.9);
    }
}
```

#### 4.2 æ•´åˆæ¸¬è©¦
```rust
// tests/encoding_integration_tests.rs
use subx_cli::core::formats::encoding::{EncodingDetector, EncodingConverter};
use std::fs;
use tempfile::tempdir;

#[test]
fn test_subtitle_file_encoding_detection() {
    let temp_dir = tempdir().unwrap();
    
    // å»ºç«‹ä¸åŒç·¨ç¢¼çš„æ¸¬è©¦å­—å¹•æª”æ¡ˆ
    let srt_content = r#"1
00:00:01,000 --> 00:00:03,000
Hello, World!

2
00:00:04,000 --> 00:00:06,000
æ¸¬è©¦å­—å¹•
"#;

    let utf8_file = temp_dir.path().join("test_utf8.srt");
    fs::write(&utf8_file, srt_content).unwrap();
    
    let detector = EncodingDetector::new().unwrap();
    let result = detector.detect_file_encoding(
        utf8_file.to_str().unwrap()
    ).unwrap();
    
    assert_eq!(result.charset, subx_cli::core::formats::encoding::Charset::Utf8);
    assert!(result.confidence > 0.7);
}

#[test]
fn test_end_to_end_encoding_conversion() {
    let temp_dir = tempdir().unwrap();
    let input_file = temp_dir.path().join("input.srt");
    
    // å»ºç«‹åŒ…å«å¤šèªè¨€å…§å®¹çš„æ¸¬è©¦æª”æ¡ˆ
    let content = "Hello, ä¸–ç•Œ! Bonjour, monde!";
    fs::write(&input_file, content).unwrap();
    
    // æª¢æ¸¬ç·¨ç¢¼
    let detector = EncodingDetector::new().unwrap();
    let encoding_info = detector.detect_file_encoding(
        input_file.to_str().unwrap()
    ).unwrap();
    
    // è½‰æ›ç‚º UTF-8
    let converter = EncodingConverter::new();
    let conversion_result = converter.convert_file_to_utf8(
        input_file.to_str().unwrap(),
        &encoding_info,
    ).unwrap();
    
    assert_eq!(conversion_result.converted_text, content);
    assert!(!conversion_result.had_errors);
}
```

## é æœŸæ•ˆç›Š

### åŠŸèƒ½æ•ˆç›Š
1. **è‡ªå‹•ç·¨ç¢¼æª¢æ¸¬**: ä½¿ç”¨è€…ç„¡éœ€æ‰‹å‹•æŒ‡å®šæª”æ¡ˆç·¨ç¢¼
2. **å¤šèªè¨€æ”¯æ´**: æ”¯æ´å…¨çƒä¸»è¦å­—ç¬¦ç·¨ç¢¼æ ¼å¼
3. **éŒ¯èª¤ä¿®å¾©**: è‡ªå‹•è™•ç†ç·¨ç¢¼éŒ¯èª¤å’Œæå£å­—ç¬¦
4. **æ•ˆèƒ½æœ€ä½³åŒ–**: å¿«é€Ÿæº–ç¢ºçš„ç·¨ç¢¼æª¢æ¸¬å’Œè½‰æ›

### æŠ€è¡“æ•ˆç›Š
1. **çµ±ä¸€é…ç½®æ•´åˆ**: å®Œå…¨æ•´åˆåˆ°ç¾æœ‰é…ç½®ç®¡ç†ç³»çµ±
2. **æ¨¡çµ„åŒ–è¨­è¨ˆ**: æ˜“æ–¼ç¶­è­·å’Œæ“´å±•çš„æ¶æ§‹
3. **å…¨é¢æ¸¬è©¦**: å®Œæ•´çš„å–®å…ƒæ¸¬è©¦å’Œæ•´åˆæ¸¬è©¦è¦†è“‹
4. **æ•ˆèƒ½ç›£æ§**: è©³ç´°çš„æª¢æ¸¬å’Œè½‰æ›æ•ˆèƒ½æŒ‡æ¨™

### ä½¿ç”¨è€…é«”é©—æ•ˆç›Š
1. **é›¶é…ç½®ä½¿ç”¨**: é–‹ç®±å³ç”¨çš„ç·¨ç¢¼è™•ç†
2. **æ™ºæ…§æç¤º**: æ¸…æ™°çš„ç·¨ç¢¼æª¢æ¸¬çµæœå’Œå»ºè­°
3. **éŒ¯èª¤è™•ç†**: å„ªé›…çš„éŒ¯èª¤è™•ç†å’Œæ¢å¾©æ©Ÿåˆ¶
4. **é€²åº¦é€æ˜**: è©³ç´°çš„è™•ç†é€²åº¦å’Œç‹€æ…‹è³‡è¨Š

## å¯¦ä½œå„ªå…ˆç´š

### é«˜å„ªå…ˆç´š (å¿…é ˆå¯¦ä½œ)
- æ ¸å¿ƒç·¨ç¢¼æª¢æ¸¬å¼•æ“
- UTF-8, GBK, Shift-JIS æ”¯æ´
- BOM æª¢æ¸¬å’Œè™•ç†
- åŸºç¤è½‰æ›åŠŸèƒ½

### ä¸­å„ªå…ˆç´š (é‡è¦åŠŸèƒ½)
- çµ±è¨ˆåˆ†æå™¨
- æ›´å¤šç·¨ç¢¼æ ¼å¼æ”¯æ´
- éŒ¯èª¤ä¿®å¾©æ©Ÿåˆ¶
- CLI å‘½ä»¤æ•´åˆ

### ä½å„ªå…ˆç´š (å¢å¼·åŠŸèƒ½)
- é€²éšèªè¨€æ¨¡å‹
- è‡ªè¨‚ç·¨ç¢¼è¦å‰‡
- æ‰¹æ¬¡è™•ç†æœ€ä½³åŒ–
- è©³ç´°æ•ˆèƒ½å ±å‘Š

## é¢¨éšªè©•ä¼°

### æŠ€è¡“é¢¨éšª
- **ç·¨ç¢¼æª¢æ¸¬æº–ç¢ºåº¦**: å¯èƒ½å‡ºç¾èª¤åˆ¤ï¼Œç‰¹åˆ¥æ˜¯ç›¸ä¼¼ç·¨ç¢¼
- **æ•ˆèƒ½å•é¡Œ**: å¤§æª”æ¡ˆè™•ç†å¯èƒ½è¼ƒæ…¢
- **è¨˜æ†¶é«”ä½¿ç”¨**: çµ±è¨ˆåˆ†æå¯èƒ½æ¶ˆè€—è¼ƒå¤šè¨˜æ†¶é«”

### ç·©è§£ç­–ç•¥
- å¯¦ä½œå¤šå±¤æª¢æ¸¬æ©Ÿåˆ¶æé«˜æº–ç¢ºåº¦
- ä½¿ç”¨ä¸²æµè™•ç†è™•ç†å¤§æª”æ¡ˆ
- æœ€ä½³åŒ–è¨˜æ†¶é«”ä½¿ç”¨å’Œå¿«å–ç­–ç•¥
- æä¾›æ‰‹å‹•è¦†è“‹é¸é …ä½œç‚ºå¾Œå‚™æ–¹æ¡ˆ

---

**é ä¼°ç¸½å·¥æ™‚**: 36 å°æ™‚  
**å»ºè­°å¯¦ä½œæ™‚ç¨‹**: 5-6 é€±  
**å‰ç½®éœ€æ±‚**: Backlog #14 (çµ±ä¸€é…ç½®ç®¡ç†ç³»çµ±)  
**å¾ŒçºŒä¾è³´**: ç„¡ç›´æ¥ä¾è³´ï¼Œä½†æœƒå¢å¼·æ‰€æœ‰æª”æ¡ˆè™•ç†åŠŸèƒ½çš„ç©©å®šæ€§
