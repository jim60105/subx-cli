# Product Backlog #19.2: ä¸­æœŸå„ªå…ˆç´šæ¸¬è©¦å¯¦ä½œ

## é ˜åŸŸç¯„åœ
ä¸­æœŸå„ªå…ˆç´šæ¸¬è©¦ç¼ºå£è§£æ±º (3-5 å¤©) - éŸ³è¨Šæœå‹™æ¸¬è©¦é‡å»ºã€ç·¨ç¢¼æª¢æ¸¬åŠŸèƒ½æ¸¬è©¦å»ºç«‹ã€AI é‡è©¦æ©Ÿåˆ¶æ¸¬è©¦å®Œå–„

## èƒŒæ™¯è„ˆçµ¡

æœ¬ backlog æ˜¯ [Product Backlog #19: é—œéµæ¸¬è©¦ç¼ºå£è§£æ±ºæ–¹æ¡ˆ](19-critical-test-gaps-resolution.md) çš„ç¬¬äºŒéšæ®µå¯¦ä½œï¼Œå°ˆæ³¨æ–¼ä¸­æœŸå„ªå…ˆç´šæ¨¡çµ„çš„æ¸¬è©¦è¦†è“‹ç‡æå‡ï¼Œé æœŸå¯æå‡æ•´é«”è¦†è“‹ç‡ +2%ã€‚

### ç•¶å‰è¦†è“‹ç‡ç‹€æ…‹
- **audio/analyzer.rs**: 6.93% â†’ ç›®æ¨™ 60%
- **encoding/analyzer.rs**: 0% â†’ ç›®æ¨™ 70%
- **encoding/detector.rs**: 0% â†’ ç›®æ¨™ 70%
- **ai/retry.rs**: 0% â†’ ç›®æ¨™ 80%

## ç¬¬äºŒéšæ®µå¯¦ä½œé …ç›®

### âš¡ 2.1 éŸ³è¨Šæœå‹™æ¸¬è©¦é‡å»º (ç›®æ¨™è¦†è“‹ç‡: 60%)

#### 2.1.1 audio/analyzer.rs æ¸¬è©¦å¯¦ä½œ (ç•¶å‰ 6.93% â†’ 60%)

åŸºæ–¼ç¾æœ‰çš„ `AusAudioAnalyzer` çµæ§‹ï¼Œå¯¦ä½œä»¥ä¸‹æ¸¬è©¦ï¼š

```rust
// tests/audio_analyzer_tests.rs

use subx_cli::services::audio::{AusAudioAnalyzer, AudioData, AudioEnvelope};
use tempfile::TempDir;
use std::fs;
use tokio_test;

#[cfg(test)]
mod audio_analyzer_tests {
    use super::*;

    /// æ¸¬è©¦éŸ³è¨Šæª”æ¡ˆè¼‰å…¥åŠŸèƒ½
    #[tokio::test]
    async fn test_load_audio_file_success() {
        let analyzer = AusAudioAnalyzer::new(44100);
        let temp_dir = TempDir::new().unwrap();
        
        // å»ºç«‹æ¨¡æ“¬ WAV æª”æ¡ˆ (æœ€å°æœ‰æ•ˆ WAV æª”é ­)
        let wav_data = create_minimal_wav_file(44100, 1, 1.0);
        let wav_path = temp_dir.path().join("test.wav");
        fs::write(&wav_path, wav_data).unwrap();
        
        let result = analyzer.load_audio_file(&wav_path).await;
        assert!(result.is_ok());
        
        let audio_file = result.unwrap();
        assert_eq!(audio_file.sample_rate, 44100);
        assert!(audio_file.duration > 0.0);
        assert_eq!(audio_file.num_channels, 1);
    }

    /// æ¸¬è©¦ä¸å­˜åœ¨æª”æ¡ˆçš„éŒ¯èª¤è™•ç†
    #[tokio::test]
    async fn test_load_audio_file_not_exists() {
        let analyzer = AusAudioAnalyzer::new(44100);
        let result = analyzer.load_audio_file("non_existent.wav").await;
        assert!(result.is_err());
    }

    /// æ¸¬è©¦éŸ³è¨Šè³‡æ–™æ ¼å¼è½‰æ›
    #[tokio::test]
    async fn test_load_audio_data_conversion() {
        let analyzer = AusAudioAnalyzer::new(16000);
        let temp_dir = TempDir::new().unwrap();
        
        let wav_data = create_minimal_wav_file(16000, 1, 2.0);
        let wav_path = temp_dir.path().join("test.wav");
        fs::write(&wav_path, wav_data).unwrap();
        
        let audio_data = analyzer.load_audio_data(&wav_path).await.unwrap();
        
        assert_eq!(audio_data.sample_rate, 16000);
        assert_eq!(audio_data.channels, 1);
        assert!(audio_data.duration > 1.9 && audio_data.duration < 2.1);
        assert!(!audio_data.samples.is_empty());
    }

    /// æ¸¬è©¦éŸ³è¨Šèƒ½é‡åŒ…çµ¡æå–
    #[tokio::test]
    async fn test_extract_envelope_features() {
        let analyzer = AusAudioAnalyzer::new(44100);
        let temp_dir = TempDir::new().unwrap();
        
        // å»ºç«‹åŒ…å«è®ŠåŒ–èƒ½é‡çš„éŸ³è¨Šæª”æ¡ˆ
        let wav_data = create_varying_energy_wav(44100, 2.0);
        let wav_path = temp_dir.path().join("varying.wav");
        fs::write(&wav_path, wav_data).unwrap();
        
        let envelope = analyzer.extract_envelope(&wav_path).await.unwrap();
        
        assert!(!envelope.samples.is_empty());
        assert_eq!(envelope.sample_rate, analyzer.sample_rate);
        assert!(envelope.duration > 1.9);
        
        // é©—è­‰èƒ½é‡å€¼åˆç†ç¯„åœ
        for &energy in &envelope.samples {
            assert!(energy >= 0.0);
            assert!(energy <= 1.0);
        }
    }

    /// æ¸¬è©¦å°è©±æª¢æ¸¬åŠŸèƒ½
    #[tokio::test]
    async fn test_detect_dialogue_segments() {
        let analyzer = AusAudioAnalyzer::new(16000);
        
        // å»ºç«‹æ¨¡æ“¬éŸ³è¨ŠåŒ…çµ¡ (åŒ…å«èªéŸ³å’ŒéœéŸ³æ®µ)
        let envelope = AudioEnvelope {
            samples: vec![
                0.1, 0.8, 0.9, 0.7, 0.2,  // èªéŸ³æ®µ
                0.05, 0.03, 0.02, 0.04,    // éœéŸ³æ®µ
                0.6, 0.8, 0.7, 0.9, 0.5,  // èªéŸ³æ®µ
            ],
            sample_rate: 16000,
            duration: 2.0,
        };
        
        let segments = analyzer.detect_dialogue(&envelope, 0.3);
        
        assert!(!segments.is_empty());
        
        // é©—è­‰æª¢æ¸¬åˆ°çš„èªéŸ³æ®µè½
        let speech_segments: Vec<_> = segments.iter()
            .filter(|s| s.intensity > 0.3)
            .collect();
        assert!(speech_segments.len() >= 2);
    }

    /// æ¸¬è©¦éŸ³è¨Šç‰¹å¾µåˆ†æ
    #[tokio::test]
    async fn test_audio_features_analysis() {
        let analyzer = AusAudioAnalyzer::new(44100);
        let temp_dir = TempDir::new().unwrap();
        
        let wav_data = create_spectral_rich_wav(44100, 1.0);
        let wav_path = temp_dir.path().join("rich.wav");
        fs::write(&wav_path, wav_data).unwrap();
        
        let audio_file = analyzer.load_audio_file(&wav_path).await.unwrap();
        let features = analyzer.analyze_audio_features(&audio_file).await.unwrap();
        
        assert!(!features.frames.is_empty());
        
        for frame in &features.frames {
            // é©—è­‰å…‰è­œé‡å¿ƒåœ¨åˆç†ç¯„åœå…§ (0 åˆ°å¥ˆå¥æ–¯ç‰¹é »ç‡)
            assert!(frame.spectral_centroid >= 0.0);
            assert!(frame.spectral_centroid <= 22050.0);
            
            // é©—è­‰å…‰è­œç†µ
            assert!(frame.spectral_entropy >= 0.0);
            assert!(frame.spectral_entropy <= 1.0);
            
            // é©—è­‰éé›¶ç‡
            assert!(frame.zero_crossing_rate >= 0.0);
            assert!(frame.zero_crossing_rate <= 1.0);
        }
    }

    /// æ¸¬è©¦ç„¡æ•ˆæª”æ¡ˆæ ¼å¼è™•ç†
    #[tokio::test]
    async fn test_invalid_audio_format() {
        let analyzer = AusAudioAnalyzer::new(44100);
        let temp_dir = TempDir::new().unwrap();
        
        // å»ºç«‹ç„¡æ•ˆçš„éŸ³è¨Šæª”æ¡ˆ
        let invalid_path = temp_dir.path().join("invalid.wav");
        fs::write(&invalid_path, b"This is not audio data").unwrap();
        
        let result = analyzer.load_audio_file(&invalid_path).await;
        assert!(result.is_err());
    }

    /// æ¸¬è©¦å¤§æª”æ¡ˆè™•ç†å’Œè¨˜æ†¶é«”ç®¡ç†
    #[tokio::test]
    async fn test_large_file_memory_management() {
        let analyzer = AusAudioAnalyzer::new(44100);
        let temp_dir = TempDir::new().unwrap();
        
        // å»ºç«‹è¼ƒå¤§çš„éŸ³è¨Šæª”æ¡ˆ (10 ç§’)
        let wav_data = create_minimal_wav_file(44100, 1, 10.0);
        let wav_path = temp_dir.path().join("large.wav");
        fs::write(&wav_path, wav_data).unwrap();
        
        let start_memory = get_memory_usage();
        let _audio_data = analyzer.load_audio_data(&wav_path).await.unwrap();
        let end_memory = get_memory_usage();
        
        // é©—è­‰è¨˜æ†¶é«”ä½¿ç”¨é‡åœ¨åˆç†ç¯„åœå…§ (< 100MB å¢é•·)
        assert!((end_memory - start_memory) < 100_000_000);
    }

    // è¼”åŠ©å‡½å¼ç”¨æ–¼å»ºç«‹æ¸¬è©¦éŸ³è¨Šæª”æ¡ˆ
    fn create_minimal_wav_file(sample_rate: u32, channels: u16, duration: f32) -> Vec<u8> {
        let samples_per_channel = (sample_rate as f32 * duration) as u32;
        let total_samples = samples_per_channel * channels as u32;
        let data_size = total_samples * 2; // 16-bit samples
        
        let mut wav_data = Vec::new();
        
        // WAV æª”é ­
        wav_data.extend_from_slice(b"RIFF");
        wav_data.extend_from_slice(&(36 + data_size).to_le_bytes());
        wav_data.extend_from_slice(b"WAVE");
        wav_data.extend_from_slice(b"fmt ");
        wav_data.extend_from_slice(&16u32.to_le_bytes());
        wav_data.extend_from_slice(&1u16.to_le_bytes()); // PCM
        wav_data.extend_from_slice(&channels.to_le_bytes());
        wav_data.extend_from_slice(&sample_rate.to_le_bytes());
        wav_data.extend_from_slice(&(sample_rate * channels as u32 * 2).to_le_bytes());
        wav_data.extend_from_slice(&(channels * 2).to_le_bytes());
        wav_data.extend_from_slice(&16u16.to_le_bytes());
        wav_data.extend_from_slice(b"data");
        wav_data.extend_from_slice(&data_size.to_le_bytes());
        
        // éŸ³è¨Šè³‡æ–™ (ç°¡å–®æ­£å¼¦æ³¢)
        for i in 0..total_samples {
            let t = i as f32 / sample_rate as f32;
            let amplitude = (2.0 * std::f32::consts::PI * 440.0 * t).sin();
            let sample = (amplitude * 32767.0) as i16;
            wav_data.extend_from_slice(&sample.to_le_bytes());
        }
        
        wav_data
    }

    fn create_varying_energy_wav(sample_rate: u32, duration: f32) -> Vec<u8> {
        // å¯¦ä½œå»ºç«‹è®ŠåŒ–èƒ½é‡çš„éŸ³è¨Šæª”æ¡ˆ
        create_minimal_wav_file(sample_rate, 1, duration)
    }

    fn create_spectral_rich_wav(sample_rate: u32, duration: f32) -> Vec<u8> {
        // å¯¦ä½œå»ºç«‹é »è­œè±å¯Œçš„éŸ³è¨Šæª”æ¡ˆ
        create_minimal_wav_file(sample_rate, 1, duration)
    }

    fn get_memory_usage() -> usize {
        // ç°¡åŒ–çš„è¨˜æ†¶é«”ä½¿ç”¨é‡æª¢æ¸¬
        0 // å¯¦éš›å¯¦ä½œå¯ä½¿ç”¨ procfs æˆ–å…¶ä»–ç³»çµ±å·¥å…·
    }
}
```

#### 2.1.2 audio/extractor.rs æ¸¬è©¦è£œå……

```rust
// æ“´å……ç¾æœ‰çš„ extractor æ¸¬è©¦
#[cfg(test)]
mod audio_extractor_tests {
    use super::*;
    
    /// æ¸¬è©¦éŸ³è¨Šè³‡æ–™æå–ç²¾ç¢ºåº¦
    #[tokio::test]
    async fn test_precise_audio_data_extraction() {
        // å¯¦ä½œç²¾ç¢ºçš„éŸ³è¨Šè³‡æ–™æå–æ¸¬è©¦
    }

    /// æ¸¬è©¦æ™‚é–“æˆ³è¨˜å°æ‡‰æ­£ç¢ºæ€§
    #[test]
    fn test_timestamp_mapping_accuracy() {
        // å¯¦ä½œæ™‚é–“æˆ³è¨˜æ˜ å°„æ¸¬è©¦
    }

    /// æ¸¬è©¦éŸ³è¨Šè½‰æ›å“è³ª
    #[test]
    fn test_audio_conversion_quality() {
        // å¯¦ä½œéŸ³è¨Šè½‰æ›å“è³ªæ¸¬è©¦
    }

    /// æ¸¬è©¦æ‰¹é‡è™•ç†æ•ˆèƒ½
    #[tokio::test]
    async fn test_batch_processing_performance() {
        // å¯¦ä½œæ‰¹é‡è™•ç†æ•ˆèƒ½æ¸¬è©¦
    }
}
```

### âš¡ 2.2 ç·¨ç¢¼æª¢æ¸¬åŠŸèƒ½æ¸¬è©¦å»ºç«‹ (ç›®æ¨™è¦†è“‹ç‡: 70%)

#### 2.2.1 encoding/analyzer.rs æ¸¬è©¦å¯¦ä½œ (ç•¶å‰ 0% â†’ 70%)

åŸºæ–¼ç¾æœ‰çš„ `ByteAnalyzer` å’Œ `StatisticalAnalyzer` çµæ§‹ï¼š

```rust
// tests/encoding_analyzer_tests.rs

use subx_cli::core::formats::encoding::{
    ByteAnalyzer, StatisticalAnalyzer, AnalysisResult, Charset
};
use std::collections::HashMap;

#[cfg(test)]
mod encoding_analyzer_tests {
    use super::*;

    /// æ¸¬è©¦ä½å…ƒçµ„åˆ†æå™¨åŸºæœ¬åŠŸèƒ½
    #[test]
    fn test_byte_analyzer_basic_analysis() {
        let mut analyzer = ByteAnalyzer::new();
        let test_data = b"Hello, World! 123";
        
        let result = analyzer.analyze(test_data).unwrap();
        
        // é©—è­‰ ASCII æ¯”ä¾‹
        assert!(result.ascii_ratio > 0.9);
        assert!(result.ascii_ratio <= 1.0);
        
        // é©—è­‰ç†µå€¼åˆç†ç¯„åœ
        assert!(result.entropy > 0.0);
        assert!(result.entropy < 8.0);
        
        // é©—è­‰æ§åˆ¶å­—å…ƒæ¯”ä¾‹
        assert!(result.control_char_ratio < 0.1);
        
        // é©—è­‰ç·¨ç¢¼å»ºè­°
        assert!(result.likely_encodings.contains(&Charset::Utf8));
    }

    /// æ¸¬è©¦ä¸­æ–‡æ–‡å­—ç·¨ç¢¼åˆ†æ
    #[test]
    fn test_chinese_text_analysis() {
        let mut analyzer = ByteAnalyzer::new();
        let chinese_text = "ä½ å¥½ï¼Œä¸–ç•Œï¼æ¸¬è©¦ä¸­æ–‡ç·¨ç¢¼æª¢æ¸¬ã€‚".as_bytes();
        
        let result = analyzer.analyze(chinese_text).unwrap();
        
        // ä¸­æ–‡æ–‡å­—æ‡‰è©²æœ‰è¼ƒä½çš„ ASCII æ¯”ä¾‹
        assert!(result.ascii_ratio < 0.5);
        
        // ç†µå€¼æ‡‰è©²è¼ƒé«˜
        assert!(result.entropy > 5.0);
        
        // æ‡‰è©²å»ºè­° UTF-8 æˆ–å…¶ä»–ä¸­æ–‡ç·¨ç¢¼
        let has_unicode_encoding = result.likely_encodings.iter()
            .any(|&charset| matches!(charset, Charset::Utf8 | Charset::Gbk | Charset::Big5));
        assert!(has_unicode_encoding);
    }

    /// æ¸¬è©¦äºŒé€²ä½è³‡æ–™åˆ†æ
    #[test]
    fn test_binary_data_analysis() {
        let mut analyzer = ByteAnalyzer::new();
        let binary_data: Vec<u8> = (0..=255).cycle().take(1000).collect();
        
        let result = analyzer.analyze(&binary_data).unwrap();
        
        // äºŒé€²ä½è³‡æ–™æ‡‰è©²æœ‰é«˜ç†µå€¼
        assert!(result.entropy > 7.0);
        
        // ASCII æ¯”ä¾‹æ‡‰è©²ç´„ç‚º 50%
        assert!(result.ascii_ratio > 0.4);
        assert!(result.ascii_ratio < 0.6);
    }

    /// æ¸¬è©¦ç†µå€¼è¨ˆç®—ç²¾ç¢ºåº¦
    #[test]
    fn test_entropy_calculation_accuracy() {
        let mut analyzer = ByteAnalyzer::new();
        
        // å®Œå…¨å‡å‹»åˆ†å¸ƒæ‡‰è©²æœ‰æœ€å¤§ç†µå€¼
        let uniform_data: Vec<u8> = (0..=255).collect();
        let uniform_result = analyzer.analyze(&uniform_data).unwrap();
        
        // é‡ç½®åˆ†æå™¨
        analyzer = ByteAnalyzer::new();
        
        // å–®ä¸€å­—å…ƒæ‡‰è©²æœ‰æœ€å°ç†µå€¼
        let single_char_data = vec![b'A'; 100];
        let single_result = analyzer.analyze(&single_char_data).unwrap();
        
        assert!(uniform_result.entropy > single_result.entropy);
        assert!(single_result.entropy < 1.0);
    }

    /// æ¸¬è©¦æ§åˆ¶å­—å…ƒæª¢æ¸¬
    #[test]
    fn test_control_character_detection() {
        let mut analyzer = ByteAnalyzer::new();
        
        // å»ºç«‹åŒ…å«æ§åˆ¶å­—å…ƒçš„è³‡æ–™
        let mut data_with_control = Vec::new();
        data_with_control.extend_from_slice(b"Normal text ");
        data_with_control.push(0x01); // SOH
        data_with_control.push(0x02); // STX
        data_with_control.push(0x1F); // US
        data_with_control.extend_from_slice(b" more text");
        
        let result = analyzer.analyze(&data_with_control).unwrap();
        
        // æ‡‰è©²æª¢æ¸¬åˆ°æ§åˆ¶å­—å…ƒ
        assert!(result.control_char_ratio > 0.0);
        assert!(result.control_char_ratio < 0.5);
        
        // å¯èƒ½å»ºè­° Windows-1252 ç·¨ç¢¼
        assert!(result.likely_encodings.contains(&Charset::Windows1252));
    }

    /// æ¸¬è©¦çµ±è¨ˆåˆ†æå™¨èªè¨€æ¨¡å‹
    #[test]
    fn test_statistical_analyzer_language_models() {
        let analyzer = StatisticalAnalyzer::new();
        
        // æ¸¬è©¦ UTF-8 ä¸­æ–‡æ–‡å­—
        let utf8_chinese = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚".as_bytes();
        let utf8_scores = analyzer.analyze_with_models(utf8_chinese).unwrap();
        
        // UTF-8 æ‡‰è©²æœ‰è¼ƒé«˜åˆ†æ•¸
        assert!(utf8_scores.get(&Charset::Utf8).unwrap_or(&0.0) > &0.5);
        
        // æ¸¬è©¦ GBK æ¨¡å¼æ–‡å­—
        let gbk_pattern = vec![0xB0, 0xA1, 0xC4, 0xE3, 0xBA, 0xC3]; // æ¨¡æ“¬ GBK ç·¨ç¢¼
        let gbk_scores = analyzer.analyze_with_models(&gbk_pattern).unwrap();
        
        // GBK æ‡‰è©²æœ‰åˆç†åˆ†æ•¸
        assert!(gbk_scores.get(&Charset::Gbk).unwrap_or(&0.0) > &0.0);
    }

    /// æ¸¬è©¦ä½å…ƒçµ„é »ç‡åˆ†å¸ƒåˆ†æ
    #[test]
    fn test_byte_frequency_distribution() {
        let mut analyzer = ByteAnalyzer::new();
        let repeated_data = b"aaabbbccc";
        
        let result = analyzer.analyze(repeated_data).unwrap();
        
        // é©—è­‰ä½å…ƒçµ„åˆ†å¸ƒè¢«æ­£ç¢ºè¨˜éŒ„
        assert!(result.byte_distribution.len() > 0);
        assert_eq!(*result.byte_distribution.get(&b'a').unwrap(), 3);
        assert_eq!(*result.byte_distribution.get(&b'b').unwrap(), 3);
        assert_eq!(*result.byte_distribution.get(&b'c').unwrap(), 3);
    }

    /// æ¸¬è©¦ç©ºè³‡æ–™è™•ç†
    #[test]
    fn test_empty_data_handling() {
        let mut analyzer = ByteAnalyzer::new();
        let empty_data = b"";
        
        let result = analyzer.analyze(empty_data).unwrap();
        
        // ç©ºè³‡æ–™æ‡‰è©²å›å‚³é è¨­å€¼
        assert_eq!(result.ascii_ratio, 0.0);
        assert_eq!(result.entropy, 0.0);
        assert_eq!(result.control_char_ratio, 0.0);
        assert!(!result.likely_encodings.is_empty());
    }

    /// æ¸¬è©¦ç·¨ç¢¼å»ºè­°é‚è¼¯
    #[test]
    fn test_encoding_suggestion_logic() {
        let mut analyzer = ByteAnalyzer::new();
        
        // é«˜ ASCII æ¯”ä¾‹æ‡‰è©²å»ºè­° UTF-8
        let ascii_heavy = b"Hello World! 123 ABC";
        let ascii_result = analyzer.analyze(ascii_heavy).unwrap();
        assert!(ascii_result.likely_encodings.contains(&Charset::Utf8));
        
        // é‡è¨­åˆ†æå™¨
        analyzer = ByteAnalyzer::new();
        
        // é«˜ç†µå€¼å’Œä½ ASCII æ¯”ä¾‹æ‡‰è©²å»ºè­°å¤šä½å…ƒçµ„ç·¨ç¢¼
        let multibyte_pattern: Vec<u8> = (0x80..=0xFF).cycle().take(100).collect();
        let multibyte_result = analyzer.analyze(&multibyte_pattern).unwrap();
        
        let has_multibyte_encoding = multibyte_result.likely_encodings.iter()
            .any(|&charset| matches!(charset, Charset::Gbk | Charset::Big5 | Charset::ShiftJis));
        assert!(has_multibyte_encoding);
    }

    /// æ¸¬è©¦é›™å­—å…ƒçµ„æ¨¡å¼åˆ†æ
    #[test]
    fn test_bigram_pattern_analysis() {
        let mut analyzer = ByteAnalyzer::new();
        
        // å»ºç«‹å…·æœ‰æ˜é¡¯é›™å­—å…ƒçµ„æ¨¡å¼çš„è³‡æ–™
        let pattern_data = b"abcabcabcabc";
        let _result = analyzer.analyze(pattern_data).unwrap();
        
        // æ³¨æ„ï¼šç›®å‰çš„å¯¦ä½œæ”¶é›†é›™å­—å…ƒçµ„é »ç‡ä½†æœªåœ¨çµæœä¸­ä½¿ç”¨
        // é€™è£¡å¯ä»¥æ“´å±•æ¸¬è©¦ä»¥é©—è­‰é›™å­—å…ƒçµ„åˆ†æé‚è¼¯
    }
}
```

#### 2.2.2 encoding/detector.rs æ¸¬è©¦å¯¦ä½œ

```rust
// tests/encoding_detector_tests.rs

use subx_cli::core::formats::encoding::{EncodingDetector, Charset, EncodingInfo};
use tempfile::TempDir;
use std::fs;

#[cfg(test)]
mod encoding_detector_tests {
    use super::*;

    /// æ¸¬è©¦ UTF-8 ç·¨ç¢¼æª¢æ¸¬
    #[test]
    fn test_utf8_detection_accuracy() {
        let detector = EncodingDetector::new().unwrap();
        let utf8_text = "Hello, ä¸–ç•Œ! Bonjour, monde! ğŸŒ";
        
        let result = detector.detect_encoding(utf8_text.as_bytes()).unwrap();
        
        assert_eq!(result.charset, Charset::Utf8);
        assert!(result.confidence > 0.8);
        assert!(!result.bom_detected);
        assert!(result.sample_text.contains("Hello"));
    }

    /// æ¸¬è©¦ UTF-8 BOM æª¢æ¸¬
    #[test]
    fn test_utf8_bom_detection() {
        let detector = EncodingDetector::new().unwrap();
        let mut bom_data = vec![0xEF, 0xBB, 0xBF]; // UTF-8 BOM
        bom_data.extend_from_slice("Hello, World!".as_bytes());
        
        let result = detector.detect_encoding(&bom_data).unwrap();
        
        assert_eq!(result.charset, Charset::Utf8);
        assert_eq!(result.confidence, 1.0);
        assert!(result.bom_detected);
        assert_eq!(result.sample_text, "UTF-8 with BOM");
    }

    /// æ¸¬è©¦ UTF-16 BOM æª¢æ¸¬
    #[test]
    fn test_utf16_bom_detection() {
        let detector = EncodingDetector::new().unwrap();
        
        // UTF-16 LE BOM
        let utf16le_data = vec![0xFF, 0xFE, 0x48, 0x00, 0x65, 0x00]; // "He" in UTF-16 LE
        let result = detector.detect_encoding(&utf16le_data).unwrap();
        assert_eq!(result.charset, Charset::Utf16Le);
        assert!(result.bom_detected);
        
        // UTF-16 BE BOM
        let utf16be_data = vec![0xFE, 0xFF, 0x00, 0x48, 0x00, 0x65]; // "He" in UTF-16 BE
        let result = detector.detect_encoding(&utf16be_data).unwrap();
        assert_eq!(result.charset, Charset::Utf16Be);
        assert!(result.bom_detected);
    }

    /// æ¸¬è©¦æª”æ¡ˆç·¨ç¢¼æª¢æ¸¬
    #[test]
    fn test_file_encoding_detection() {
        let detector = EncodingDetector::new().unwrap();
        let temp_dir = TempDir::new().unwrap();
        
        // å»ºç«‹ UTF-8 æª”æ¡ˆ
        let utf8_path = temp_dir.path().join("utf8.txt");
        fs::write(&utf8_path, "æ¸¬è©¦æª”æ¡ˆç·¨ç¢¼æª¢æ¸¬åŠŸèƒ½ã€‚").unwrap();
        
        let result = detector.detect_file_encoding(utf8_path.to_str().unwrap()).unwrap();
        
        assert_eq!(result.charset, Charset::Utf8);
        assert!(result.confidence > 0.7);
    }

    /// æ¸¬è©¦ä¸å­˜åœ¨æª”æ¡ˆéŒ¯èª¤è™•ç†
    #[test]
    fn test_nonexistent_file_error() {
        let detector = EncodingDetector::new().unwrap();
        let result = detector.detect_file_encoding("nonexistent.txt");
        
        assert!(result.is_err());
    }

    /// æ¸¬è©¦ GBK ç·¨ç¢¼æ¨¡å¼æª¢æ¸¬
    #[test]
    fn test_gbk_pattern_detection() {
        let detector = EncodingDetector::new().unwrap();
        
        // æ¨¡æ“¬ GBK ç·¨ç¢¼æ¨¡å¼ (é«˜ä½å…ƒçµ„ç¯„åœ)
        let gbk_pattern = vec![
            0xC4, 0xE3, 0xBA, 0xC3, // ä½ å¥½ (GBK)
            0xCA, 0xC0, 0xBD, 0xE7, // ä¸–ç•Œ (GBK)
        ];
        
        let result = detector.detect_encoding(&gbk_pattern).unwrap();
        
        // æ‡‰è©²æª¢æ¸¬ç‚º GBK æˆ–è‡³å°‘ä¸æ˜¯ UTF-8
        assert!(result.confidence > 0.3);
        if result.charset == Charset::Gbk {
            assert!(result.confidence > 0.5);
        }
    }

    /// æ¸¬è©¦ Shift-JIS ç·¨ç¢¼æª¢æ¸¬
    #[test]
    fn test_shift_jis_detection() {
        let detector = EncodingDetector::new().unwrap();
        
        // æ¨¡æ“¬ Shift-JIS ç·¨ç¢¼æ¨¡å¼
        let shift_jis_pattern = vec![
            0x82, 0xB1, 0x82, 0xF1, // ã“ã‚“ (Shift-JIS)
            0x82, 0xC9, 0x82, 0xBF, // ã«ã¡ (Shift-JIS)
        ];
        
        let result = detector.detect_encoding(&shift_jis_pattern).unwrap();
        
        // æ‡‰è©²æª¢æ¸¬ç‚º Shift-JIS æˆ–ç›¸é—œç·¨ç¢¼
        assert!(result.confidence > 0.2);
    }

    /// æ¸¬è©¦ç·¨ç¢¼ä¿¡å¿ƒå€¼æ’åº
    #[test]
    fn test_encoding_confidence_ranking() {
        let detector = EncodingDetector::new().unwrap();
        
        // æ˜ç¢ºçš„ UTF-8 æ–‡å­—æ‡‰è©²æœ‰æœ€é«˜ä¿¡å¿ƒå€¼
        let clear_utf8 = "Clear English text with numbers 123.";
        let utf8_result = detector.detect_encoding(clear_utf8.as_bytes()).unwrap();
        
        // æ¨¡ç³Šçš„è³‡æ–™æ‡‰è©²æœ‰è¼ƒä½ä¿¡å¿ƒå€¼
        let ambiguous_data: Vec<u8> = (0x80..=0xFF).cycle().take(50).collect();
        let ambiguous_result = detector.detect_encoding(&ambiguous_data).unwrap();
        
        assert!(utf8_result.confidence > ambiguous_result.confidence);
    }

    /// æ¸¬è©¦æœ€å¤§å–æ¨£å¤§å°é™åˆ¶
    #[test]
    fn test_max_sample_size_limit() {
        let detector = EncodingDetector::new().unwrap();
        
        // å»ºç«‹è¶…éå–æ¨£å¤§å°é™åˆ¶çš„è³‡æ–™
        let large_data = vec![b'A'; 10000]; // å‡è¨­é™åˆ¶æ˜¯ 8192
        let result = detector.detect_encoding(&large_data).unwrap();
        
        // æ‡‰è©²æˆåŠŸæª¢æ¸¬ä¸”ä¸æœƒå› è³‡æ–™å¤ªå¤§è€Œå¤±æ•—
        assert_eq!(result.charset, Charset::Utf8);
        assert!(result.confidence > 0.9);
    }

    /// æ¸¬è©¦ç·¨ç¢¼å€™é¸è€…é¸æ“‡é‚è¼¯
    #[test]
    fn test_encoding_candidate_selection() {
        let detector = EncodingDetector::new().unwrap();
        
        // å»ºç«‹æ··åˆç·¨ç¢¼ç‰¹å¾µçš„è³‡æ–™
        let mixed_data = [
            b"English text ",
            &[0xC3, 0xA9], // Ã© in UTF-8
            b" and more text"
        ].concat();
        
        let result = detector.detect_encoding(&mixed_data).unwrap();
        
        // æ‡‰è©²æ­£ç¢ºé¸æ“‡ UTF-8
        assert_eq!(result.charset, Charset::Utf8);
        assert!(result.confidence > 0.7);
    }

    /// æ¸¬è©¦æœªçŸ¥ç·¨ç¢¼çš„å¾Œå‚™æ©Ÿåˆ¶
    #[test]
    fn test_unknown_encoding_fallback() {
        let detector = EncodingDetector::new().unwrap();
        
        // å»ºç«‹å®Œå…¨éš¨æ©Ÿçš„è³‡æ–™
        let random_data: Vec<u8> = (0..100).map(|i| (i * 7 + 13) as u8).collect();
        let result = detector.detect_encoding(&random_data).unwrap();
        
        // æ‡‰è©²æœ‰ä¸€å€‹å¾Œå‚™ç·¨ç¢¼é¸æ“‡
        assert!(result.confidence >= 0.0);
        assert!(result.confidence <= 1.0);
    }

    /// æ¸¬è©¦ç·¨ç¢¼æª¢æ¸¬æ•ˆèƒ½
    #[test]
    fn test_detection_performance() {
        let detector = EncodingDetector::new().unwrap();
        
        // å»ºç«‹ä¸­ç­‰å¤§å°çš„æ–‡å­—æª”æ¡ˆ
        let large_text = "Hello, World! ".repeat(500);
        
        let start = std::time::Instant::now();
        let _result = detector.detect_encoding(large_text.as_bytes()).unwrap();
        let duration = start.elapsed();
        
        // æª¢æ¸¬æ‡‰è©²åœ¨åˆç†æ™‚é–“å…§å®Œæˆ (< 100ms)
        assert!(duration.as_millis() < 100);
    }
}
```

### âš¡ 2.3 AI é‡è©¦æ©Ÿåˆ¶æ¸¬è©¦å®Œå–„ (ç›®æ¨™è¦†è“‹ç‡: 80%)

#### 2.3.1 ai/retry.rs æ¸¬è©¦å¯¦ä½œ (ç•¶å‰ 0% â†’ 80%)

åŸºæ–¼ç¾æœ‰çš„ `retry_with_backoff` å‡½å¼å’Œ `RetryConfig` çµæ§‹ï¼Œå¯¦ä½œä»¥ä¸‹æ¸¬è©¦ï¼š

```rust
// tests/ai_retry_tests.rs

use subx_cli::services::ai::retry::{retry_with_backoff, RetryConfig, RetryError};
use std::time::{Duration, Instant};
use tokio::time::sleep;
use std::sync::{Arc, Mutex};

#[cfg(test)]
mod ai_retry_tests {
    use super::*;

    /// æ¸¬è©¦åŸºæœ¬é‡è©¦æ©Ÿåˆ¶
    #[tokio::test]
    async fn test_retry_success_on_second_attempt() {
        let config = RetryConfig {
            max_attempts: 3,
            initial_delay: Duration::from_millis(10),
            max_delay: Duration::from_secs(1),
            backoff_multiplier: 2.0,
        };

        let attempt_count = Arc::new(Mutex::new(0));
        let attempt_count_clone = attempt_count.clone();

        let operation = || async {
            let mut count = attempt_count_clone.lock().unwrap();
            *count += 1;
            if *count == 1 {
                Err(RetryError::Temporary("First attempt fails".to_string()))
            } else {
                Ok("Success on second attempt".to_string())
            }
        };

        let result = retry_with_backoff(&config, operation).await;
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), "Success on second attempt");
        assert_eq!(*attempt_count.lock().unwrap(), 2);
    }

    /// æ¸¬è©¦æœ€å¤§é‡è©¦æ¬¡æ•¸é™åˆ¶
    #[tokio::test]
    async fn test_retry_exhaust_max_attempts() {
        let config = RetryConfig {
            max_attempts: 2,
            initial_delay: Duration::from_millis(10),
            max_delay: Duration::from_secs(1),
            backoff_multiplier: 2.0,
        };

        let attempt_count = Arc::new(Mutex::new(0));
        let attempt_count_clone = attempt_count.clone();

        let operation = || async {
            let mut count = attempt_count_clone.lock().unwrap();
            *count += 1;
            Err(RetryError::Temporary("Always fails".to_string()))
        };

        let result = retry_with_backoff(&config, operation).await;
        assert!(result.is_err());
        assert_eq!(*attempt_count.lock().unwrap(), 2);
    }

    /// æ¸¬è©¦æŒ‡æ•¸é€€é¿å»¶é²
    #[tokio::test]
    async fn test_exponential_backoff_timing() {
        let config = RetryConfig {
            max_attempts: 3,
            initial_delay: Duration::from_millis(50),
            max_delay: Duration::from_millis(200),
            backoff_multiplier: 2.0,
        };

        let attempt_times = Arc::new(Mutex::new(Vec::new()));
        let attempt_times_clone = attempt_times.clone();

        let operation = || async {
            let start_time = Instant::now();
            attempt_times_clone.lock().unwrap().push(start_time);
            Err(RetryError::Temporary("Always fails for timing test".to_string()))
        };

        let overall_start = Instant::now();
        let _result = retry_with_backoff(&config, operation).await;
        
        let times = attempt_times.lock().unwrap();
        assert_eq!(times.len(), 3);
        
        // é©—è­‰å»¶é²æ™‚é–“éå¢ (è€ƒæ…®åŸ·è¡Œæ™‚é–“èª¤å·®)
        if times.len() >= 2 {
            let delay1 = times[1].duration_since(times[0]);
            // ç¬¬ä¸€æ¬¡å»¶é²æ‡‰è©²ç´„ç‚º 50ms (Â±20ms èª¤å·®)
            assert!(delay1 >= Duration::from_millis(30));
            assert!(delay1 <= Duration::from_millis(100));
        }
    }

    /// æ¸¬è©¦æ°¸ä¹…éŒ¯èª¤ç«‹å³å¤±æ•—
    #[tokio::test]
    async fn test_permanent_error_no_retry() {
        let config = RetryConfig {
            max_attempts: 3,
            initial_delay: Duration::from_millis(10),
            max_delay: Duration::from_secs(1),
            backoff_multiplier: 2.0,
        };

        let attempt_count = Arc::new(Mutex::new(0));
        let attempt_count_clone = attempt_count.clone();

        let operation = || async {
            let mut count = attempt_count_clone.lock().unwrap();
            *count += 1;
            Err(RetryError::Permanent("Permanent failure".to_string()))
        };

        let result = retry_with_backoff(&config, operation).await;
        assert!(result.is_err());
        assert_eq!(*attempt_count.lock().unwrap(), 1); // åªæ‡‰å˜—è©¦ä¸€æ¬¡
    }

    /// æ¸¬è©¦å»¶é²ä¸Šé™é™åˆ¶
    #[tokio::test]
    async fn test_max_delay_cap() {
        let config = RetryConfig {
            max_attempts: 5,
            initial_delay: Duration::from_millis(100),
            max_delay: Duration::from_millis(200), // ä½ä¸Šé™
            backoff_multiplier: 3.0, // é«˜å€æ•¸
        };

        let attempt_times = Arc::new(Mutex::new(Vec::new()));
        let attempt_times_clone = attempt_times.clone();

        let operation = || async {
            attempt_times_clone.lock().unwrap().push(Instant::now());
            Err(RetryError::Temporary("Always fails".to_string()))
        };

        let _result = retry_with_backoff(&config, operation).await;
        
        let times = attempt_times.lock().unwrap();
        
        // é©—è­‰å¾ŒçºŒå»¶é²ä¸æœƒè¶…é max_delay
        if times.len() >= 3 {
            let delay2 = times[2].duration_since(times[1]);
            // ç¬¬äºŒæ¬¡å»¶é²æ‡‰è©²è¢«é™åˆ¶åœ¨ max_delay ç¯„åœå…§ (Â±50ms èª¤å·®)
            assert!(delay2 <= Duration::from_millis(250));
        }
    }

    /// æ¸¬è©¦é…ç½®æœ‰æ•ˆæ€§é©—è­‰
    #[test]
    fn test_retry_config_validation() {
        // æœ‰æ•ˆé…ç½®
        let valid_config = RetryConfig {
            max_attempts: 3,
            initial_delay: Duration::from_millis(100),
            max_delay: Duration::from_secs(1),
            backoff_multiplier: 2.0,
        };
        assert!(valid_config.initial_delay <= valid_config.max_delay);
        assert!(valid_config.max_attempts > 0);
        assert!(valid_config.backoff_multiplier > 1.0);
    }

    /// æ¸¬è©¦èˆ‡ AI æœå‹™æ•´åˆçš„æ¨¡æ“¬å ´æ™¯
    #[tokio::test]
    async fn test_ai_service_integration_simulation() {
        let config = RetryConfig {
            max_attempts: 3,
            initial_delay: Duration::from_millis(10),
            max_delay: Duration::from_secs(1),
            backoff_multiplier: 2.0,
        };

        // æ¨¡æ“¬ AI æœå‹™å‘¼å«
        let request_count = Arc::new(Mutex::new(0));
        let request_count_clone = request_count.clone();

        let mock_ai_request = || async {
            let mut count = request_count_clone.lock().unwrap();
            *count += 1;
            
            match *count {
                1 => Err(RetryError::Temporary("Network timeout".to_string())),
                2 => Err(RetryError::Temporary("Rate limit exceeded".to_string())),
                3 => Ok("AI analysis complete".to_string()),
                _ => unreachable!(),
            }
        };

        let result = retry_with_backoff(&config, mock_ai_request).await;
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), "AI analysis complete");
        assert_eq!(*request_count.lock().unwrap(), 3);
    }
}
```

#### 2.3.2 é‡è©¦æ©Ÿåˆ¶æ•ˆèƒ½åŸºæº–æ¸¬è©¦

```rust
// benches/retry_performance.rs

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use subx_cli::services::ai::retry::{retry_with_backoff, RetryConfig, RetryError};
use std::time::Duration;
use tokio::runtime::Runtime;

fn bench_retry_immediate_success(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    
    c.bench_function("retry_immediate_success", |b| {
        b.iter(|| {
            rt.block_on(async {
                let config = RetryConfig {
                    max_attempts: 3,
                    initial_delay: Duration::from_millis(1),
                    max_delay: Duration::from_secs(1),
                    backoff_multiplier: 2.0,
                };
                
                let operation = || async { Ok::<String, RetryError>("Success".to_string()) };
                let result = retry_with_backoff(&config, operation).await;
                black_box(result)
            })
        })
    });
}

fn bench_retry_with_failures(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    
    c.bench_function("retry_with_two_failures", |b| {
        b.iter(|| {
            rt.block_on(async {
                let config = RetryConfig {
                    max_attempts: 3,
                    initial_delay: Duration::from_millis(1),
                    max_delay: Duration::from_secs(1),
                    backoff_multiplier: 2.0,
                };
                
                let mut attempt = 0;
                let operation = || async {
                    attempt += 1;
                    if attempt <= 2 {
                        Err(RetryError::Temporary("Failure".to_string()))
                    } else {
                        Ok("Success".to_string())
                    }
                };
                
                let result = retry_with_backoff(&config, operation).await;
                black_box(result)
            })
        })
    });
}

criterion_group!(benches, bench_retry_immediate_success, bench_retry_with_failures);
criterion_main!(benches);
```

### âš¡ 2.4 Semantic Search å¯¦ä½œåƒè€ƒ (æ–°å¢ï¼šå…·é«”ç¨‹å¼ç¢¼ç¯„ä¾‹)

åŸºæ–¼å°ˆæ¡ˆä¸­ç¾æœ‰çš„èªç¾©æœå°‹å’Œç›¸ä¼¼åº¦è¨ˆç®—æ¨¡å¼ï¼Œæä¾›å…·é«”å¯¦ä½œåƒè€ƒï¼š

#### 2.4.1 ç¾æœ‰ç›¸ä¼¼åº¦è¨ˆç®—æ¨¡å¼

**èªè¨€æª¢æ¸¬ç›¸ä¼¼åº¦** (åƒè€ƒ `src/core/language.rs`):
```rust
#[derive(Debug, Clone)]
pub struct LanguageInfo {
    pub code: String,
    pub source: LanguageSource,
    pub confidence: f32,  // 0.0-1.0 ç›¸ä¼¼åº¦åˆ†æ•¸
}

impl LanguageDetector {
    fn detect_from_filename(&self, path: &Path) -> Option<LanguageInfo> {
        // åŸºæ–¼æª”åæ¨¡å¼åŒ¹é…çš„ç›¸ä¼¼åº¦è¨ˆç®—
        for re in &self.filename_patterns {
            if let Some(cap) = re.captures(name) {
                return Some(LanguageInfo {
                    code: code.clone(),
                    source: LanguageSource::Filename,
                    confidence: 0.8,  // éœæ…‹ä¿¡å¿ƒåº¦
                });
            }
        }
        None
    }
}
```

**éŸ³è¨Šç‰¹å¾µç›¸ä¼¼åº¦** (åƒè€ƒ `src/services/audio/analyzer.rs`):
```rust
use spectrum::{rstft, complex_to_polar_rfft, rfftfreq};
use analysis::{spectral_centroid, spectral_entropy, zero_crossing_rate};

impl AusAudioAnalyzer {
    pub async fn analyze_audio_features(&self, audio_file: &AudioFile) -> Result<AudioFeatures> {
        let samples = &audio_file.samples[0];
        let stft_result = spectrum::rstft(samples, self.window_size, self.hop_size, WindowType::Hanning);

        for frame in stft_result.iter() {
            let (magnitude_spectrum, _) = spectrum::complex_to_polar_rfft(frame);
            let frequencies = spectrum::rfftfreq(self.window_size, audio_file.sample_rate);

            // è¨ˆç®—ç‰¹å¾µå‘é‡ - å¯ç”¨æ–¼èªç¾©ç›¸ä¼¼åº¦
            let spectral_centroid = analysis::spectral_centroid(&magnitude_spectrum, &frequencies);
            let spectral_entropy = analysis::spectral_entropy(&magnitude_spectrum);
            let zero_crossing_rate = analysis::zero_crossing_rate(samples, audio_file.sample_rate);

            features.push(FrameFeatures {
                spectral_centroid: spectral_centroid as f32,
                spectral_entropy: spectral_entropy as f32,
                zero_crossing_rate: zero_crossing_rate as f32,
            });
        }
        Ok(AudioFeatures { frames: features })
    }
}
```

**ç›¸é—œæ€§è¨ˆç®—æ¨¡å¼** (åƒè€ƒ `src/core/sync/engine.rs`):
```rust
impl SyncEngine {
    fn calculate_cross_correlation(&self, audio_envelope: &AudioEnvelope, subtitle_signal: &[f32]) -> Result<SyncResult> {
        let max_offset_samples = (self.config.max_offset_seconds * audio_envelope.sample_rate as f32) as i32;
        let mut best_correlation = 0.0;

        for offset in -max_offset_samples..=max_offset_samples {
            let corr = self.calculate_correlation_at_offset(&audio_envelope.samples, subtitle_signal, offset);
            if corr > best_correlation {
                best_correlation = corr;
            }
        }

        // æ­£è¦åŒ–ç›¸é—œæ€§åˆ†æ•¸
        let confidence = if best_correlation > self.config.correlation_threshold {
            best_correlation
        } else {
            0.0
        };

        Ok(SyncResult { confidence, /* ... */ })
    }

    fn calculate_correlation_at_offset(&self, audio_signal: &[f32], subtitle_signal: &[f32], offset: i32) -> f32 {
        let mut sum_product = 0.0;
        let mut sum_audio_sq = 0.0;
        let mut sum_sub_sq = 0.0;
        let mut count = 0;

        for i in 0..audio_len {
            let j = i + offset;
            if j >= 0 && j < subtitle_len {
                let a = audio_signal[i as usize];
                let s = subtitle_signal[j as usize];
                sum_product += a * s;
                sum_audio_sq += a * a;
                sum_sub_sq += s * s;
                count += 1;
            }
        }

        if count == 0 || sum_audio_sq == 0.0 || sum_sub_sq == 0.0 {
            return 0.0;
        }

        // çš®çˆ¾éœç›¸é—œä¿‚æ•¸è¨ˆç®—
        sum_product / (sum_audio_sq.sqrt() * sum_sub_sq.sqrt())
    }
}
```

#### 2.4.2 é›œæ¹Šèˆ‡å¿«å–æ¨¡å¼ (åƒè€ƒ `src/services/ai/cache.rs`)

```rust
use std::collections::hash_map::DefaultHasher;
use std::hash::{Hash, Hasher};

impl AICache {
    pub fn generate_key(request: &AnalysisRequest) -> String {
        let mut hasher = DefaultHasher::new();
        request.video_files.hash(&mut hasher);
        request.subtitle_files.hash(&mut hasher);
        format!("{:x}", hasher.finish())
    }

    pub async fn get(&self, key: &str) -> Option<MatchResult> {
        let cache = self.cache.read().await;
        if let Some(entry) = cache.get(key) {
            if SystemTime::now().duration_since(entry.created_at).unwrap_or_default() < self.ttl {
                return Some(entry.result.clone());
            }
        }
        None
    }
}
```

#### 2.4.3 ç·¨ç¢¼æª¢æ¸¬èªç¾©åˆ†æ (åƒè€ƒ `src/core/formats/encoding/analyzer.rs`)

```rust
impl StatisticalAnalyzer {
    pub fn analyze_with_models(&self, data: &[u8]) -> Result<HashMap<Charset, f32>> {
        let mut scores = HashMap::new();
        for (cs, model) in &self.language_models {
            let score = self.calculate_model_score(data, model)?;
            scores.insert(cs.clone(), score);
        }
        Ok(scores)
    }

    fn calculate_model_score(&self, data: &[u8], model: &LanguageModel) -> Result<f32> {
        let mut score = 0.0;
        for &b in data {
            // æ­£å‘åŒ¹é…æ¨¡å¼
            for &(pb, w) in &model.common_patterns {
                if b == pb {
                    score += w;
                }
            }
            // è² å‘åŒ¹é…æ¨¡å¼
            for &(ib, _) in &model.invalid_patterns {
                if b == ib {
                    score -= 0.1;
                }
            }
        }
        Ok(if !data.is_empty() {
            score / data.len() as f32
        } else {
            0.0
        })
    }
}
```

#### 2.4.4 åŒ¹é…å¼•æ“æ•´åˆæ¸¬è©¦å»ºè­°

åŸºæ–¼ `src/core/matcher/engine.rs` çš„å¯¦ä½œæ¨¡å¼ï¼Œå»ºè­°æ¸¬è©¦ï¼š

```rust
#[cfg(test)]
mod semantic_search_tests {
    use super::*;

    #[tokio::test]
    async fn test_content_similarity_analysis() {
        let engine = MatchEngine::new(Box::new(MockAI), test_config());
        
        // æ¸¬è©¦å…§å®¹æ¡æ¨£å’Œç›¸ä¼¼åº¦è¨ˆç®—
        let subtitles = vec![create_test_subtitle("test.srt", "test content")];
        let samples = engine.extract_content_samples(&subtitles).await.unwrap();
        
        assert!(!samples.is_empty());
        assert_eq!(samples[0].filename, "test");
        
        // é©—è­‰å…§å®¹é è¦½ç”Ÿæˆ
        let preview = engine.create_content_preview("long content...");
        assert!(preview.len() <= engine.config.max_sample_length);
    }

    #[test]
    fn test_filename_language_detection() {
        let detector = LanguageDetector::new();
        
        // æ¸¬è©¦èªè¨€æª¢æ¸¬ç›¸ä¼¼åº¦
        let result = detector.detect_from_filename(Path::new("movie.tc.srt"));
        assert!(result.is_some());
        assert_eq!(result.unwrap().confidence, 0.8);
    }

    #[test]
    fn test_cache_key_generation() {
        let request = AnalysisRequest {
            video_files: vec!["video1.mp4".to_string()],
            subtitle_files: vec!["sub1.srt".to_string()],
            content_samples: vec![],
        };
        
        let key1 = AICache::generate_key(&request);
        let key2 = AICache::generate_key(&request);
        assert_eq!(key1, key2); // åŒæ¨£è¼¸å…¥æ‡‰ç”¢ç”Ÿç›¸åŒéµå€¼
        
        let mut different_request = request.clone();
        different_request.video_files.push("video2.mp4".to_string());
        let key3 = AICache::generate_key(&different_request);
        assert_ne!(key1, key3); // ä¸åŒè¼¸å…¥æ‡‰ç”¢ç”Ÿä¸åŒéµå€¼
    }
}
```

#### 2.4.5 å¯¦ä½œæŒ‡å°åŸå‰‡

1. **ç›¸ä¼¼åº¦è¨ˆç®—æ¨™æº–åŒ–**: æ‰€æœ‰ç›¸ä¼¼åº¦åˆ†æ•¸æ‡‰æ¨™æº–åŒ–ç‚º 0.0-1.0 ç¯„åœ
2. **å¿«å–ç­–ç•¥**: ä½¿ç”¨ç©©å®šçš„é›œæ¹Šç®—æ³•ç¢ºä¿ç›¸åŒè¼¸å…¥ç”¢ç”Ÿç›¸åŒéµå€¼
3. **é–¾å€¼è¨­å®š**: åŸºæ–¼å°ˆæ¡ˆç¾æœ‰æ¨¡å¼ï¼Œå»ºè­°ç›¸ä¼¼åº¦é–¾å€¼ >0.8 ç‚ºé«˜ä¿¡å¿ƒåº¦
4. **æ•ˆèƒ½è€ƒé‡**: å¤§å‹è³‡æ–™é›†ä½¿ç”¨åˆ†å¡Šè™•ç†ï¼Œé¿å…è¨˜æ†¶é«”æº¢å‡º

é€™äº›ç¨‹å¼ç¢¼ç¯„ä¾‹ç‚ºå“¡å·¥æä¾›äº†å…·é«”çš„å¯¦ä½œåƒè€ƒï¼Œç¢ºä¿èªç¾©æœå°‹åŠŸèƒ½èˆ‡å°ˆæ¡ˆç¾æœ‰æ¶æ§‹ä¿æŒä¸€è‡´ã€‚
